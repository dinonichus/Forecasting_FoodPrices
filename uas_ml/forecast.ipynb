{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORT DATASET**\n",
    "\n",
    "Pada tahap ini juga dilakukan pengaturan format penulisan untuk kolom 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Beras</th>\n",
       "      <th>Beras Kualitas Bawah I</th>\n",
       "      <th>Beras Kualitas Bawah II</th>\n",
       "      <th>Beras Kualitas Medium I</th>\n",
       "      <th>Beras Kualitas Medium II</th>\n",
       "      <th>Beras Kualitas Super I</th>\n",
       "      <th>Beras Kualitas Super II</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-01-2022</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.6</td>\n",
       "      <td>10.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-01-2022</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-01-2022</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06-01-2022</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07-01-2022</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Beras  Beras Kualitas Bawah I  Beras Kualitas Bawah II  \\\n",
       "0  03-01-2022    9.6                     9.5                      9.0   \n",
       "1  04-01-2022    9.7                     9.5                      9.0   \n",
       "2  05-01-2022    9.7                     9.5                      9.0   \n",
       "3  06-01-2022    9.7                     9.5                      9.0   \n",
       "4  07-01-2022    9.7                     9.5                      9.0   \n",
       "\n",
       "   Beras Kualitas Medium I  Beras Kualitas Medium II  Beras Kualitas Super I  \\\n",
       "0                      8.6                      8.25                    10.6   \n",
       "1                      8.6                      8.25                    10.8   \n",
       "2                      8.6                      8.25                    10.8   \n",
       "3                      8.6                      8.25                    10.8   \n",
       "4                      8.6                      8.25                    10.8   \n",
       "\n",
       "   Beras Kualitas Super II  \n",
       "0                    10.05  \n",
       "1                    10.25  \n",
       "2                    10.25  \n",
       "3                    10.25  \n",
       "4                    10.25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './hargaBerdasarkanDaerah.csv'\n",
    "df = pd.read_csv(path, delimiter=';')\n",
    "\n",
    "# mengubah format penulisan pada kolom 'Date' menjadi 'dd-mm-yyyy'\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object' and column != 'Date':\n",
    "        df[column] = df[column].str.replace(',', '.')\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "df['Date'] = df['Date'].str.split(' ').str.join('')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISUALISASI DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Beras', 'Beras Kualitas Bawah I', 'Beras Kualitas Bawah II',\n",
       "       'Beras Kualitas Medium I', 'Beras Kualitas Medium II',\n",
       "       'Beras Kualitas Super I', 'Beras Kualitas Super II'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menghapus kolom 'Date' dari kolom target\n",
    "target_cols = df.columns.drop('Date')\n",
    "num_cols = len(target_cols)\n",
    "target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah dilakukan pemeriksaan tipe data pada tiap kolomnya, diketahui bahwa tipe data pada kolom 'Date' adalah string. Untuk melakukan eksperimen, tipe data pada kolom 'Date' harus float sehingga perlu diubah terlebih dahulu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                         object\n",
       "Beras                       float64\n",
       "Beras Kualitas Bawah I      float64\n",
       "Beras Kualitas Bawah II     float64\n",
       "Beras Kualitas Medium I     float64\n",
       "Beras Kualitas Medium II    float64\n",
       "Beras Kualitas Super I      float64\n",
       "Beras Kualitas Super II     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with Date as Float:\n",
      "          Date  Beras  Beras Kualitas Bawah I  Beras Kualitas Bawah II  \\\n",
      "0   2022-01-03    9.6                     9.5                      9.0   \n",
      "1   2022-01-04    9.7                     9.5                      9.0   \n",
      "2   2022-01-05    9.7                     9.5                      9.0   \n",
      "3   2022-01-06    9.7                     9.5                      9.0   \n",
      "4   2022-01-07    9.7                     9.5                      9.0   \n",
      "..         ...    ...                     ...                      ...   \n",
      "639 2024-06-14   13.5                    14.5                     13.5   \n",
      "640 2024-06-17   13.5                    14.5                     13.5   \n",
      "641 2024-06-18   13.5                    14.5                     13.5   \n",
      "642 2024-06-19   13.5                    14.5                     13.5   \n",
      "643 2024-06-20   13.5                    14.5                     13.5   \n",
      "\n",
      "     Beras Kualitas Medium I  Beras Kualitas Medium II  \\\n",
      "0                        8.6                      8.25   \n",
      "1                        8.6                      8.25   \n",
      "2                        8.6                      8.25   \n",
      "3                        8.6                      8.25   \n",
      "4                        8.6                      8.25   \n",
      "..                       ...                       ...   \n",
      "639                     12.1                     11.15   \n",
      "640                     12.1                     11.15   \n",
      "641                     12.1                     11.15   \n",
      "642                     12.1                     11.15   \n",
      "643                     12.1                     11.15   \n",
      "\n",
      "     Beras Kualitas Super I  Beras Kualitas Super II  Date_Float  \n",
      "0                     10.60                    10.05       44563  \n",
      "1                     10.80                    10.25       44564  \n",
      "2                     10.80                    10.25       44565  \n",
      "3                     10.80                    10.25       44566  \n",
      "4                     10.80                    10.25       44567  \n",
      "..                      ...                      ...         ...  \n",
      "639                   14.55                    13.80       45456  \n",
      "640                   14.55                    13.80       45459  \n",
      "641                   14.55                    13.80       45460  \n",
      "642                   14.55                    13.80       45461  \n",
      "643                   14.55                    13.80       45462  \n",
      "\n",
      "[644 rows x 9 columns]\n",
      "\n",
      "Updated Data Types:\n",
      "Date                        datetime64[ns]\n",
      "Beras                              float64\n",
      "Beras Kualitas Bawah I             float64\n",
      "Beras Kualitas Bawah II            float64\n",
      "Beras Kualitas Medium I            float64\n",
      "Beras Kualitas Medium II           float64\n",
      "Beras Kualitas Super I             float64\n",
      "Beras Kualitas Super II            float64\n",
      "Date_Float                           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Mengubah data pada kolom 'Date' menjadi format datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
    "\n",
    "# Mengubah datetime menajdi float\n",
    "reference_date = pd.Timestamp('1900-01-01') \n",
    "df['Date_Float'] = (df['Date'] - reference_date).dt.days + 1\n",
    "\n",
    "print(\"\\nDataFrame with Date as Float:\")\n",
    "print(df)\n",
    "print(\"\\nUpdated Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABc8AAAPdCAYAAABcIJAQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVxU9foH8M8MwoDsmygCbuB6Fc2LqahheUVTyixNKwPFNW+b1S1vubXZbt5bGSoJWdn2U1NuV6+37EpIBZpZ5gJuOO6g7III398fpxkYGIaZYWbODPN5v17zmjPnnDnzzJmRx3nmO89XIYQQICIiIiIiIiIiIiIiLaXcARARERERERERERER2RsWz4mIiIiIiIiIiIiIGmHxnIiIiIiIiIiIiIioERbPiYiIiIiIiIiIiIgaYfGciIiIiIiIiIiIiKgRFs+JiIiIiIiIiIiIiBph8ZyIiIiIiIiIiIiIqBEWz4mIiIiIiIiIiIiIGmHxnIiIiIiIiIiIiIioERbPiWxgx44dGDhwINzd3aFQKFBcXIykpCR07dpVu8+pU6egUCjwxhtvyBcoERE5FeYnsheN33cAoFAosHz5clniaQuSkpLg5eUldxhEZCHM2WQvmLMtjznbvrF4Tk7n5MmT+Otf/4qePXuiffv2aN++Pfr27YuFCxfi4MGDFn+8oqIiTJ06FR4eHnj33XexceNGeHp6WvxxFAoF/vrXv+rdlpaWBoVCgdzcXIs/ri107doVCoVCe3F3d0dUVBSeeuopXLlyRe7wiIgsgvnJ8bS1/PTdd99BoVDgyy+/1Fl//fp1TJw4EUqlEh988IFM0QF79+7F8uXLUVxcbPPHjouL03mt3dzc0K1bN8ydOxdnzpyxeTy2EBcXhz/96U9yh0Fkl5izHQ9ztm0xZ9uWvpzdtWtXTJw4UaaI2pZ2cgdAZEsZGRm499570a5dO9x///2Ijo6GUqnEkSNHsHnzZqxZswYnT55Ely5dLPaYOTk5KCsrwwsvvIAxY8Zo169btw51dXUWe5y2buDAgXjiiScAAFVVVdi3bx/efvtt/O9//8NPP/0kc3RERK3D/OS42np+qqmpwT333IOvv/4a69atw6xZs2z22NeuXUO7dvUfV/bu3YsVK1YgKSkJfn5+NotDIywsDCtXrgQgFSd+//13vP/++9i5cycOHz6M9u3b2zwmIrI95mzHxZxtPczZ1JaxeE5O4/jx45g2bRq6dOmCb775Bp06ddLZ/uqrr+K9996DUmn4BxkVFRUmfct/6dIlAGiSMFxdXY0+hr0x9RxYQufOnfHAAw9ob8+ePRteXl544403kJeXh6ioqFY/hhzPi4iI+clymJ8sq6amBlOnTkVGRgZSUlKQnJxs08d3d3e36eO1xNfXV+e1BoBu3brhr3/9K7KysvCXv/xFpsiIyFaYsy2HOduymLN1MWeTJbFtCzmN1157DRUVFdiwYUOT/+QAQLt27fDII48gPDxcu07Td+r48eO4/fbb4e3tjfvvvx8AkJmZiSlTpiAiIgIqlQrh4eF4/PHHce3aNe394+LikJiYCACIiYmBQqFAUlKS9tiN+4Q1JoTA3Llz4ebmhs2bN7fyDOg6ePAgkpKS0L17d7i7u6Njx46YNWsWioqKdPZbvnw5FAoFfv/9d9x3333w9/fHiBEjAAB1dXVYvnw5QkND0b59e4wePRq///47unbtqn2eAHDlyhU8+eST6N+/P7y8vODj44Px48fjl19+adVz6NixIwDofMMNAEeOHME999yDgIAAuLu7489//jO2bdums4/mZ4f/+9//8NBDD6FDhw4ICwsDAJw+fRoPPfQQevXqBQ8PDwQGBmLKlCk4deqUzjFqamqwYsUKREVFwd3dHYGBgRgxYgR27drVqudFRM6F+UkX85N95KcbN25g2rRp+Oqrr7BmzRrMmTNHu01z7hvTxN4wnq+++goTJkxAaGgoVCoVevTogRdeeAG1tbUtxtCwf+ry5cvx1FNPAZA+/Gp+iq15rA0bNuDWW29Fhw4doFKp0LdvX6xZs6bJMXNzcxEfH4+goCB4eHigW7durRqZp++1NuZ1Ki4uhouLC/7xj39o1xUWFkKpVCIwMBBCCO36BQsWaB8HMO7feENnz57FpEmT4OXlheDgYDz55JNGnX8iaoo5WxdzNnO2BnO2hDm7beLIc3IaGRkZiIyMxM0332zS/W7cuIH4+HiMGDECb7zxhvbnPV988QUqKyuxYMECBAYG4qeffsI///lPqNVqfPHFFwCAZ599Fr169cLatWvx/PPPo1u3bujRo4dRj1tbW4tZs2bhs88+w5YtWzBhwoQW71NVVYXCwsIm68vLy5us27VrF06cOIGZM2eiY8eOOHToENauXYtDhw7hhx9+aJJgp0yZgqioKLz88sva5LB48WK89tprSEhIQHx8PH755RfEx8ejqqpK574nTpzA1q1bMWXKFHTr1g0XL15ESkoKbrnlFvz+++8IDQ1t8bnV1NRon1tVVRV+/vlnvPXWWxg1ahS6deum3e/QoUOIjY1F586d8cwzz8DT0xOff/45Jk2ahP/7v//DXXfdpXPchx56CMHBwVi6dCkqKioASD+L3Lt3L6ZNm4awsDCcOnUKa9asQVxcHH7//Xfte2D58uVYuXIlZs+ejSFDhqC0tBS5ubnYv38/v8kmIqMxP+lifpLImZ9u3LiB6dOnY8uWLXj33Xcxb968Fu/TnLS0NHh5eWHRokXw8vLCt99+i6VLl6K0tBSvv/660ceZPHkyjh07hk2bNmHVqlUICgoCAAQHBwMA1qxZg379+uGOO+5Au3btsH37djz00EOoq6vDwoULAUgjN8eOHYvg4GA888wz8PPzw6lTp4wuJtXW1mpf65qaGhw+fBjLli1DZGQkYmNjtfsZ8zr5+fnhT3/6E/bs2YNHHnkEAPD9999DoVDgypUr+P3339GvXz8A0gfvkSNHao9vzL/xhjHHx8fj5ptvxhtvvIH//ve/ePPNN9GjRw8sWLDA6PNPRBLmbF3M2RLmbF3M2czZbY4gcgIlJSUCgJg0aVKTbVevXhWXL1/WXiorK7XbEhMTBQDxzDPPNLlfw/00Vq5cKRQKhTh9+rR23YYNGwQAkZOTo7NvYmKi6NKli/b2yZMnBQDx+uuvi5qaGnHvvfcKDw8PsXPnTqOeI4AWLw1j0Bf/pk2bBACxZ88e7bply5YJAGL69Ok6+164cEG0a9euyTldvny5ACASExO166qqqkRtba3OfidPnhQqlUo8//zzLT63Ll266H0+sbGxorCwUGff2267TfTv319UVVVp19XV1Ynhw4eLqKgo7TrN6zJixAhx48YNnWPoOzfZ2dkCgPjwww+166Kjo8WECRNajJ+IqDnMT8xP9pSfdu/eLQBon9e7776rdz/NuW9ME/vJkycNxjxv3jzRvn17nXPR+H0nhPTeWbZsmfb266+/3uT4hh4nPj5edO/eXXt7y5Ytet/zxrjlllv0vtZ9+vQRJ06caDEWfa/TwoULRUhIiPb2okWLxKhRo0SHDh3EmjVrhBBCFBUVCYVCIVavXm3w+Pr+jWv+TjR+Lw8aNEgMHjzYqOfcr1+/FvcjchbM2czZzNkS5mzHyNldunRhvcJC2LaFnEJpaSkAwMvLq8m2uLg4BAcHay/vvvtuk330fcvn4eGhXa6oqEBhYSGGDx8OIQR+/vlns2O9fv06pkyZgoyMDHz99dcYO3as0fe98847sWvXriYXzU+mmotfM7pg6NChAID9+/c32X/+/Pk6t7/55hvcuHEDDz30kM76hx9+uMl9VSqVtu9fbW0tioqK4OXlhV69eul9LH1uvvlm7fPJyMjASy+9hEOHDuGOO+7Q/uTpypUr+PbbbzF16lSUlZWhsLAQhYWFKCoqQnx8PPLy8nD27Fmd486ZMwcuLi7NnpuamhoUFRUhMjISfn5+OvH6+fnh0KFDyMvLM+o5EBE1xvzE/GSP+enixYto166dzig8czWMWfPcR44cicrKShw5cqTVx9f3OCUlJSgsLMQtt9yCEydOoKSkBEB9r+CMjAzU1NSY/Bhdu3bVvtb//ve/8fbbb6OkpATjx4/H5cuX9cZi6HUaOXIkLl68iKNHjwKQRquNGjUKI0eORGZmJgBpZJsQQmcUm6n/xhv/Gxk5ciROnDhh8vMncnbM2czZzNmWwZzNnO1o2LaFnIK3tzcA/T81S0lJQVlZGS5evNhkQglA6oel6VvWUEFBAZYuXYpt27bh6tWrOts0f/DNsXLlSpSXl+Pf//434uLiTLpvWFiYzuzrGmq1usm6K1euYMWKFfj000+1E9Bo6Iu/cTI+ffo0ACAyMlJnfUBAAPz9/XXW1dXVYfXq1Xjvvfdw8uRJnZ5dgYGBLTwrSVBQkM5zmzBhAnr16oV77rkH69evx8MPP4z8/HwIIbBkyRIsWbJE73EuXbqEzp07N/u8AGmm8JUrV2LDhg04e/asTg+zhufm+eefx5133omePXviT3/6E8aNG4cZM2ZgwIABRj0nIiLmJ+YnDXvKT6+99hrefvtt3HPPPfjPf/6j8/NmUx06dAjPPfccvv32W23hSV/MrZWVlYVly5YhOzsblZWVTR7H19cXt9xyC+6++26sWLECq1atQlxcHCZNmoT77rsPKpWqxcfw9PTUea3HjRuHESNG4M9//jNeeeUVvPnmmwCMf500H64zMzMRFhaGn3/+GS+++CKCg4PxxhtvaLf5+PggOjpaez9T/o27u7trfyav4e/v3+R+RNQy5mzmbA3m7NZhzm56fIA5256xeE5OwdfXF506dcJvv/3WZJumX13jiTs0Gn7DrVFbW4u//OUvuHLlCp5++mn07t0bnp6eOHv2LJKSklBXV2d2rPHx8dixYwdee+01xMXFWW3W6qlTp2Lv3r146qmnMHDgQHh5eaGurg7jxo3TG3/Db0xN9fLLL2PJkiWYNWsWXnjhBQQEBECpVOKxxx5r1bm67bbbAAB79uzBww8/rD3Wk08+ifj4eL33afwfM33P6+GHH8aGDRvw2GOPYdiwYfD19YVCocC0adN04h01ahSOHz+Or776Cv/5z3+wfv16rFq1Cu+//z5mz55t9vMiIufB/NQU85NEzvzUqVMn7Nq1CyNGjMCECRPwv//9T+eDoL6JxwA0mdCquLgYt9xyC3x8fPD888+jR48ecHd3x/79+/H000+36hw3dPz4cdx2223o3bs33nrrLYSHh8PNzQ1ff/01Vq1apX0chUKBL7/8Ej/88AO2b9+OnTt3YtasWXjzzTfxww8/6B1N2pLBgwfD19cXe/bs0a4z9nUKDQ1Ft27dsGfPHnTt2hVCCAwbNgzBwcF49NFHcfr0aWRmZmL48OE6oy1N+TfeeCQkEZmPObsp5mwJc7bxmLOZsx0Ri+fkNCZMmID169fjp59+wpAhQ1p1rF9//RXHjh1Deno6HnzwQe16U2bEbs7QoUMxf/58TJw4EVOmTMGWLVuazPzdWlevXsU333yDFStWYOnSpdr1pvxUrEuXLgCA/Px8nW/ai4qKmnwz+uWXX2L06NFITU3VWV9cXKydPMQcN27cAFA/+qN79+4AAFdXV72jJYz15ZdfIjExUfttNCD9DLG4uLjJvgEBAZg5cyZmzpyJ8vJyjBo1CsuXL2fxnIiMxvxUj/nJMFvmp+7du2Pnzp245ZZbEB8fj8zMTERFRQGAdjRgcXGx9mfVQP0IQo3vvvsORUVF2Lx5M0aNGqVdf/LkSWOfso7mCgDbt29HdXU1tm3bhoiICO363bt3691/6NChGDp0KF566SV88sknuP/++/Hpp5+anbtra2t1RqKa8jqNHDkSe/bsQbdu3TBw4EB4e3sjOjoavr6+2LFjB/bv348VK1Zo97fmv3Eiahlzdj3mbMOYs5mzmbPbDvY8J6fxt7/9De3bt8esWbNw8eLFJtsb/jynJZpvBBveRwiB1atXtz5QAGPGjMGnn36KHTt2YMaMGRb7lldDX/wA8Pbbbxt9jNtuuw3t2rXDmjVrdNa/8847eh+v8WN98cUXTXrFmWr79u0AoP1mvUOHDoiLi0NKSgrOnz/fZP+Gvc0M0RfvP//5zybfzhcVFenc9vLyQmRkJKqrq41+DkREzE/1mJ8Ms3V+6t+/P/71r3+hvLwcf/nLX7TnpUePHgCgM3KroqIC6enpTeIFdF/P69ev47333jMpDg1PT08AaPKBVt/jlJSUYMOGDTr7Xb16tcn5GzhwIACYnbt3796N8vJynVF+xr5OgPRB/NSpU/jss8+0PwlXKpUYPnw43nrrLdTU1Oj0TrX2v3EiMow5ux5ztmHM2czZzNltB0eek9OIiorCJ598gunTp6NXr164//77ER0dDSEETp48iU8++QRKpVJvL7rGevfujR49euDJJ5/E2bNn4ePjg//7v/+zaC+qSZMmYcOGDXjwwQfh4+ODlJQUix3bx8cHo0aNwmuvvYaamhp07twZ//nPf0z6VjkkJASPPvoo3nzzTdxxxx0YN24cfvnlF/z73/9GUFCQzjfNEydOxPPPP4+ZM2di+PDh+PXXX/Hxxx9rv9U3xtmzZ/HRRx8BkJL4L7/8gpSUFAQFBelMKPPuu+9ixIgR6N+/P+bMmYPu3bvj4sWLyM7Ohlqtxi+//NLiY02cOBEbN26Er68v+vbti+zsbPz3v/9t0kuvb9++iIuLw+DBgxEQEIDc3Fx8+eWX+Otf/2r08yIiYn6qx/xkmBz5adiwYdi8eTMSEhLwl7/8BZmZmRg7diwiIiKQnJyMp556Ci4uLvjggw8QHByMgoIC7X2HDx8Of39/JCYm4pFHHoFCocDGjRtNKi41NHjwYADAs88+i2nTpsHV1RUJCQkYO3Ys3NzckJCQgHnz5qG8vBzr1q1Dhw4ddAof6enpeO+993DXXXehR48eKCsrw7p16+Dj44Pbb7+9xccvKSnRvtY3btzA0aNHsWbNGnh4eOCZZ57R7mfs6wTU91A9evQoXn75Ze36UaNG4d///jdUKhViYmK0623xb5yImsecXY852zDmbOZs5uw2RBA5mfz8fLFgwQIRGRkp3N3dhYeHh+jdu7eYP3++OHDggM6+iYmJwtPTU+9xfv/9dzFmzBjh5eUlgoKCxJw5c8Qvv/wiAIgNGzZo99uwYYMAIHJycpocu0uXLtrbJ0+eFADE66+/rrPfe++9JwCIJ5980uDzAiAWLlyod5u+GNRqtbjrrruEn5+f8PX1FVOmTBHnzp0TAMSyZcu0+y1btkwAEJcvX25y3Bs3boglS5aIjh07Cg8PD3HrrbeKw4cPi8DAQDF//nztflVVVeKJJ54QnTp1Eh4eHiI2NlZkZ2eLW265Rdxyyy0Gn5cQQnTp0kUA0F6USqXo0KGDmD59usjPz2+y//Hjx8WDDz4oOnbsKFxdXUXnzp3FxIkTxZdffmnwnGhcvXpVzJw5UwQFBQkvLy8RHx8vjhw5Irp06SISExO1+7344otiyJAhws/PT/s+eumll8T169dbfE5ERI0xP0mYn+TLT7t37xYAxBdffNFk22effSaUSqWIiYkRpaWlYt++feLmm28Wbm5uIiIiQrz11lva2E+ePKm9X1ZWlhg6dKjw8PAQoaGh4m9/+5vYuXOnACB2796t3a/x+04I0eQ1F0KIF154QXTu3FkolUqdx9q2bZsYMGCAcHd3F127dhWvvvqq+OCDD3T22b9/v5g+fbqIiIgQKpVKdOjQQUycOFHk5uYaPC9CCHHLLbfovNYKhUIEBASIO+64Q+zbt09nX2NfJ40OHToIAOLixYvadd9//70AIEaOHNlkf2P/jTf3d0Lzb8eY59yvX78W9yNyRszZEuZs5mwN5mz7y9ldunQREyZMaPG+1DKFEGZ+jUREpEdxcTH8/f3x4osv4tlnn5U7HCIiIgDMT0RERI6COZuI7Al7nhOR2a5du9ZknabHXVxcnG2DISIi+gPzExERkWNgziYie8ee50Rkts8++wxpaWm4/fbb4eXlhe+//x6bNm3C2LFjERsbK3d4RETkpJifiIiIHANzNhHZOxbPichsAwYMQLt27fDaa6+htLRUO+HLiy++KHdoRETkxJifiIiIHANzNhHZO/Y8JyIiIiIiImqj9uzZg9dffx379u3D+fPnsWXLFkyaNEnvvvPnz0dKSgpWrVqFxx57zKZxEhER2SP2PCciIiIiIiJqoyoqKhAdHY13333X4H5btmzBDz/8gNDQUBtFRkREZP/afNuWuro6nDt3Dt7e3lAoFHKHQ0RETkIIgbKyMoSGhkKp5HfVpmDuJiIiObTV3D1+/HiMHz/e4D5nz57Fww8/jJ07d2LChAkmPwZzNxERycEWuVvW4nlLPx9LSkpCenq6zn3i4+OxY8cOox/j3LlzCA8Pt1TIREREJjlz5gzCwsLkDsOhMHcTEZGcnC1319XVYcaMGXjqqafQr18/o+5TXV2N6upq7e2zZ8+ib9++1gqRiIjIIGvmblmL55qfj82aNQuTJ0/Wu8+4ceOwYcMG7W2VSmXSY3h7ewOQTqKPj4/5wRIREZmgtLQU4eHh2jxExmPuJiIiOThr7n711VfRrl07PPLII0bfZ+XKlVixYkWT9czdRERkS7bI3bIWz435+ZhKpULHjh3NfgzNT8Z8fHyYxImIyOb402XTMXcTEZGcnCl379u3D6tXr8b+/ftNet6LFy/GokWLtLc1xQvmbiIikoM1c7fdN3L77rvv0KFDB/Tq1QsLFixAUVGRwf2rq6tRWlqqcyEiIiIiIiIiXZmZmbh06RIiIiLQrl07tGvXDqdPn8YTTzyBrl27Nns/lUqlLZSzYE5ERG2ZXU8YOm7cOEyePBndunXD8ePH8fe//x3jx49HdnY2XFxc9N6nuZ+PEREREREREVG9GTNmYMyYMTrr4uPjMWPGDMycOVOmqIiIiOyHXRfPp02bpl3u378/BgwYgB49euC7777Dbbfdpvc+zf18jIiIiIiIiMjZlJeXIz8/X3v75MmTOHDgAAICAhAREYHAwECd/V1dXdGxY0f06tXL1qESERHZHbtv29JQ9+7dERQUpJP4G+PPx4iIiIiIiIgkubm5GDRoEAYNGgQAWLRoEQYNGoSlS5fKHBkREZH9s+uR542p1WoUFRWhU6dOcodCREREREREZPfi4uIghDB6/1OnTlkvGCIiIgcja/Hc0M/HAgICsGLFCtx9993o2LEjjh8/jr/97W+IjIxEfHy8jFETERERERERERERUVsna/E8NzcXo0eP1t7W9CpPTEzEmjVrcPDgQaSnp6O4uBihoaEYO3YsXnjhBahUKrlCJiIiI6nVQF4eEBUFhIXJHQ0RERG1SK0GPvwQOHIE6NoVOHQI8PcH+vYFsrJ0l93cgIgIoLBQum9QkGnLKhVw8SIQGSndzs/XXQ4JAaqrjTuetzdw//1ATIzVTg0REZE9Upeq8eHPH+LIlSPo6tcVhy4dgr+HP/oG98WBCwfQO6g3Hox+EGE+/FBuLlmL5y39fGznzp02jIaIiCwlNRWYOxeoqwOUSmDtWiA5We6oiIiIqFmpqcDs2XJHYb7Vq4HERCAtTe5IiIiIbCJ1fypmb285dz/77bNYn7AeyTfxQ7k5HGrCUCIisn9qdX3hHJCuZ88Gli4FcnLkjY2IiIj0UKsdu3CukZ7O/2wQEZFTUJeqjSqca8zNmAt1qdqKEbVdLJ4TEZFF5eXVF84beuEFYMgQICnJ5iERERGRIXl5ckdgOVlZckdARERkdXlFpuXuOlGH/Cv5Le9ITbB4TkREFlVRYXg7B4URERHZmagouSOwnNhYuSMgIiKyuqhA03K3UqFEZECklaJp21g8JyIii0lKAhISWt7vzTetHgoREREZKywMWL9e7ihaLzGRk4YSEZFTCPMJw/oE43P32olrOWmomRTC0IydbUBpaSl8fX1RUlICHx8fucMhImqzcnKktizGUCqB06elz+ptFfOP+XjuiIhkIISUoAFgyhSgd2/g8GHAzw/o0wfIztZddnUFIiKAoiLpPoGBpi27ugKXLwM9eki3jx/XXQ4OBmpqjDuetzcwfXqrC+fMP+bjuSMisj0hBJTPS7l7Sp8p6B3cG4cvH4afux8i/SPxzLfPAAAOP3QYvYN7yxmq1dgi/7SzylGJiMjpZGYav29dHZCf37aL50RERA6ltrZ++f33gYAA+WIhIiKiFtWK+tz9fsL7CPCoz91CCG3x3N/D3+axtSVs20JERBYxcqTx+7q4AJFst0ZERGQ/NKO8AWlUOBEREdm1mtr63O2q1M3dCoUC7V3bAwAqayptGldbw+I5ERFZxMGD+tcrFNKl4e2UFI46JyIisissnhMRETmUmroGxXOXprnb09UTAFBRU2GzmNoitm0hIqJWy8kB5sxpul6pBH74AejUCejVC6isBL75Bhg92vYxEhERkQEsnhMRETkUQyPPAcDNxQ0A8Nmhz7Bs9zK4ubghwicChdcKAQBBHkEmLauUKlysvIjIgEhAAPlX83WWQzxDUF1bbdTxvFXeuL///YjpbP8TfbN4TkRErZKaKhXO9U0/XVcHVFRIo8yDgoCCAsDT0/YxEhERUQs0xXOFQuqvRkRERHZNM/JcAQVclLq5O3V/Ks6WnQUAvLjnRZvHZozVP65GYnQi0ialyR2KQWzbQkREZlOrgblz9RfOAWnkuaa3uYeHdP3TT8Du3dJ9iYiIyE5oiuccdU5EROQQNCPPG7dsUZeqMTdjrhwhmSz9l3TknM2ROwyDWDwnIiKz5eVJo8ubs2iRNOo8NRU4elRa9/DDwK23Al26SOuJiIjIDrB4TkRE5FA0I88bt2zJK8pDnTDwQd3OZJ3JkjsEg1g8JyIis1UYmHdEqQQefbR+dHpjdXXSeo5AJyIisgMsnhMRETmU5kaeRwVGQalwnJJvbHis3CEY5DhnkoiI7M6xY/rXKxTA2rXSqHNDo9Pr6oDVq60XHxERERmJxXMiIiKH0tzI8zCfMKyduBYuCvufwyQxOtHuJw3lhKFERGS2kSP1r9+2DZg4UVqOipJGoTdXQH/rLWmEeliYdWIkIiIiI7B4TkRE5FCaG3kOAMk3JSM+Mh75V/JxqvgU/nXsX3BVuiLCJwJF14oAAIEegSYtuypdcbnyMnoE9AAEcPzqcZ3lYM9gbUwtHc9b5Y3p/afbfeEcYPGciIha4eDBpusSE+sL54BUFF+7FpgzR//EonV1QH4+i+dERESyYvGciIjIoTQ38lwjzCcMYT7SB+2kgUm2CqvNYdsWIiIyi75e5goF8OKLTfdNTpZGo+ujVAKRkZaPj4iIiEzA4jkREZFDMTTynCyHxXMiIjKLvl7mQkijyPWZOFEald5Qw97oREREJCMWz4mIiBxKSyPPyTJYPCciIrNoepk35OJieBR5Whrw00+ASiXd/uQTaVQ6ERERyYzFcyIiIofCkee2weI5ERGZJSwMWLOm/raLC5CS0vIo8oMHgepqafn++4HUVOvFSJa3Z88eJCQkIDQ0FAqFAlu3bm123/nz50OhUODtt9+2WXxERGQitRp4+WXglVek21VV0joiIiKyKxnHMvDQvx7CW9lvIfmrZCz/bjkAoKqmCupS5m5r4YShRERktsmTgXnzpOXMTGDYMMP7N+6TXlcn3T8+nq1bHEVFRQWio6Mxa9YsTJ48udn9tmzZgh9++AGhoaE2jI6IiEySmgrMnq277tgxoEsXqa8afx5GRERkF2JTY7FXvVfvtmNXjqHL212wduJaJN/E3G1pHHlORERmW7u2fnnEiJZHkevrk15b23yfdLI/48ePx4svvoi77rqr2X3Onj2Lhx9+GB9//DFcjfj5f3V1NUpLS3UuRERkZWp108K5hubbbY5AJyIikl3GsYxmC+cadaIO8zLmcQS6FbB4TkREZlGrgSVL6m8b8znbnD7p5Fjq6uowY8YMPPXUU+jXr59R91m5ciV8fX21l/DwcCtHSUREyMszvJ3fbhMREdmFr/O+Nmq/WlGL/CvM3ZbG4jkREZnFnFHkYWHSaPWGBfT332fLlrbk1VdfRbt27fDII48YfZ/FixejpKREezlz5owVIyQiIgDSN9qG8NttIiIiu3B71O1G7eeicEFkAHO3pbF4TkREZomKAhQK3XXGfM5OTpYK7+3+mHXD3Z2/Cm8r9u3bh9WrVyMtLQ2Kxm8OA1QqFXx8fHQuRERkZWFhwPr1+rcZOws4ERERWd3EnhMR7mP417kuChekTExBmA9zt6VxwlAiIjJLWBgwbhzw739Lt035nN29OxAeDpw8CcyYIY1E57xkji8zMxOXLl1CRESEdl1tbS2eeOIJvP322zh16pR8wRERUVMzZ9b3PZ86FRg/HujaVfomnIVzIiIiu/HAgAew8vuVGNBhABIHJuLw5cMorirGhJ4T0NWvKyIDIlk4txIWz4mIyGxBQdL1nDnA0qXGf85Wq4GGdVRNv/T4eH5Wd2QzZszAmDFjdNbFx8djxowZmDlzpkxRERFRs6qq6pdTUwEvL/liISIiomZV1lQCACb0nIBFwxbJHI1zYfGciIjMdu6cdD1ypGlF77w8QAjddZp+6Sye27fy8nLkN2hsf/LkSRw4cAABAQGIiIhAYGCgzv6urq7o2LEjevXqZetQiYioJZWV9cseHvLFQURERAZpiuftXdvLHInzYfGciIjMdvasdN25s2n30/RLb1hA57xkjiE3NxejR4/W3l60SBr1kJiYiLS0NJmiIiIis2iK5yqVlIiJiIjILrF4Lh9ZJwzds2cPEhISEBoaCoVCga1btza77/z586FQKPD222/bLD4iIjLM3OJ5WJjUVrWhBx7gqHNHEBcXByFEk0tzhfNTp07hscces2mMRERkJE3xvD0/iLdlLX3uXr58OXr37g1PT0/4+/tjzJgx+PHHH+UJloiI9GLxXD6yFs8rKioQHR2Nd9991+B+W7ZswQ8//IDQ0FAbRUZERC0pK5MuAGDqn2e1GtixQ3fdRx9J64mIiMgGMjKAJUukZRcXJuE2rKXP3T179sQ777yDX3/9Fd9//z26du2KsWPH4vLlyzaOlIiImnPl2hUAQNWNqhb2JEuTtW3L+PHjMb7x0MNGzp49i4cffhg7d+7EhAkTbBQZERG1RNPv3NtbupgiL0+aJLQh9jwnIiKykeHDgezs+tuFhUCXLsDatUBysnxxkVW09Ln7vvvu07n91ltvITU1FQcPHsRtt91m7fCIiKgFqftT8b/T/wMALNq5CN5u3ki+ifnaVmQded6Suro6zJgxA0899RT69etn1H2qq6tRWlqqcyEiIsvTtGzx8zN9sFpUFKBslIHY85yIiMgGMjJ0C+cadXXAvHkcge7krl+/jrVr18LX1xfR0dHN7sfP3UREtqEuVWNuxlztbQGBeRnzoC5lvrYVuy6ev/rqq2jXrh0eeeQRo++zcuVK+Pr6ai/h4eFWjJCIyHl98ol0feaMNFgtNdX4+4aFSYPbNJRKICWFo86JiIis7uuvm9+m+RkYOZ2MjAx4eXnB3d0dq1atwq5duxAUFNTs/vzcTURkG3lFeagTuj/brhW1yL/CfG0rdls837dvH1avXo20tDQoFAqj77d48WKUlJRoL2fOnLFilEREzkmtBj74oP62OYPVkpOB7t2l5TvvBAYMsGyMREREpMfttze/jT8Dc1qjR4/GgQMHsHfvXowbNw5Tp07FpUuXmt2fn7uJiGwjKjAKSoVu+dZF4YLIAOZrW7Hb4nlmZiYuXbqEiIgItGvXDu3atcPp06fxxBNPoGvXrs3eT6VSwcfHR+dCRESWlZcHCKG7ztTBaqmpwIkT0vKWLcCQIUBSksVCJCIiIn0mTtT/Uy8XF/4MzIl5enoiMjISQ4cORWpqKtq1a4dUAz8r5OduIiLbCPMJw9qJ9T/bViqUSJmYgjAf5mtbsdvi+YwZM3Dw4EEcOHBAewkNDcVTTz2FnTt3yh0eEZFTi4oCGv8oyJTBamo1MHt20/Xp6UBOTuvjIyIiIgM0E0RGRwMbNgC7dwOnTnGyUNKqq6tDdXW13GEQERGA5JuS4d7OHQCQmZTJyUJtrJ2cD15eXo78BsMUT548iQMHDiAgIAAREREIDAzU2d/V1RUdO3ZEr169bB0qERE1EBYGjBgBZGZKt00drJaX1/y2rCwgJqb1MRIREVEzKiul64QE/uzLCRj63B0YGIiXXnoJd9xxBzp16oTCwkK8++67OHv2LKZMmSJj1EREpCGEQNWNKgBAj4AeMkfjfGQtnufm5mL06NHa24sWLQIAJCYmIi0tTaaoiIjIGJpC+UMPAYsXm/Yr76io5rfFxrYuLiIiImqBpnjevr28cZBNGPrc/f777+PIkSNIT09HYWEhAgMDERMTg8zMTPTr10+ukImIqAFN4RwA2rsyd9uarMXzuLg4iMZNcw04deqU9YIhIiKTaD53R0eb3h41LAxYv75p65bERI46JyIisjoWz51KS5+7N2/ebMNoiIjIVJU1ldplD1cPGSNxTnbb85yIiOxbRYV0be7n7uRk4MwZ4KmnpNsBAQB/dERERGQDRUXSNXtaExER2b3jV44DAFwULrhQfkHmaJwPi+dERGQWTfHc09P8Y4SFAUuWSMtXrkgXIiIisqLUVGDXLmn5mWek20RERGSXUvenYmjqUABArahFxKoIpO5n7rYlFs+JiMhkOTn1k36eOdO6Y3l7A6Gh0vJ337XuWERERGSAWg3MnVt/Wwhg3jxpPREREdkVdakac7bPgUB96y0BgXkZ86AuZe62FRbPiYjIJElJwJAhQGGhdPvRR6V15kpNBc6dk5bvuYcD4IiIiKwmLw+oq9NdV1sL5OfLEw8RERE1K68oT6dwrlErapF/hbnbVmSdMJSIiOxbTg7w8cdAWRkQFAQcPgxs3950v/R0YOFC0yf71DcAbs4cID7e9ElIiYiIqAVRUYBSqVtAd3EBIiPli4mIiIj0igqM0rveReGCyADmblth8ZyIiPRKSpKK4sbKyjK9eK5vAJwQwOzZwI4dph2LiIiIWhAWBqxdKyVaQCqkp6TwG2siIiI7FOYThnGR47Ajv/7DsVKhRMrEFIT5MHfbCtu2EBFREzk5phXOASA21vTHidL/RTp27pRiICIiIgtLTgb8/KTl//5Xuk1ERER2qW9QXwDAHT3vwOf3fI7Tj51G8k3M3bbE4jkRETWRmWna/omJpo86B6SBblOn6t+WlWX68YiIiMgIVVXSdffu8sZBREREBtXU1QAA+of0x5R+UzjiXAYsnhMRURMjRxq/7/btQFqa+Y/15JP615szkp2IiIhaUFdXXzxv317eWIiIiMigmlqpeO6qdJU5EufF4jkRETUREwMMHWp4H4UCWL8emDix9Y+VmKi7ztyR7ERERNSCa9fqlz095YuDiIiIWqQZee7qwuK5XDhhKBER6RUXB/zwAxAdLRWyAwOBoiJp2+DBUtHcUvOLpaUBXl7Au+8CPXoAISH1LVj//GcgIcE6c5mp1dLI+aNHAZUKKCwEvL2B++9n8Z6IiNqoior6ZXd3+eIgIiKiFmmL5xx5LhsWz4mISK+TJ6XrBx8EFi2y/uPt3y9dHz8OvPZa/foPPgAWLgTWrbPsnGapqcDs2fq3rV4tjX5vTTsaIiIiu3T8uHTt6gqcO2edb6eJiIjIIrRtWzjyXDZs20JERHqdOiVdd+1q/cfKyQGys5vfLgQwd640UtwS1OrmC+ca6elSXERERG1Gamr9pCI1NUBEhLSOiIiI7BJHnsuPxXMiItLLlsXzzMyW96mrA/LzLfN4eXnG7ZeVZZnHIyIikp1aDcyZI30jrSEEMG+e5b6dJiIiIoviyHP5sXhORERNXLsGXLwoLbu5Wf/xRo5seR+lEoiMtMzjRUUZt59mcB4REZHDy8vTLZxr1NZa7ttpIiIisiiOPJcfi+dERNTEm2/WL0dHW/8X3TExUo9xQ9autVxb1rAwYP16w/skJnLSUCIiakOa++bYxcVy304TERGRRXHkufw4YSgREenIyQGWLq2/XVcn/aI7Pt66c4qlpUkTg/7rX0BVFVBUBPz2G/DDD0Dv3sCAAc3fNyMD+PxzoFMn6XZ+fn0dID8fGDxYmvi0YfzJycCSJcD588D06VLb16IiwNtbus3CORERtSlhYVIy37mzfp1SCaSkcNJQIiIiO8WR5/Jj8ZyIiLRSU/VPpKn5Rbe1P1vHxOgWrUeNkq6PHAGGDJFGg6el6d4nNhbYu9fwcTdvBp59Vhptnpxcv/7aNel62TKgV69Wh09ERGTf+vSRiud33gncfz8wbBgL50RERHaMI8/lx+I5EZGdy8mpn1AzK0vqQR4RARQWSuuCggwve3sDY8YAZ84AR48C169L/cwbjsyOjATKyoA1a/THYMl+48Zq+Lw10tOBe+4BJk6UbmdktFw4b2j2bGDfPqC6WrpdXCxdl5W1OlwiIiL7VyN9AEf//sCUKfLGQkRERC3iyHP5sXhORGTHkpKkgnFrrV7duvtPmWL7gWmNC+caCQn1I8i//tr04+r7gmDIEGDdOt1R6URERG2Opnjuyg/gREREjoAjz+XHCUOJiOxUTo5lCueW8MQTtn/MkSOb3zZ7tjTq/PbbLfNYQkh93dVqyxyPiIjILt24IV2zeE5EROQQOPJcfiyeExHZqeZGXttafLw8k2fGxAB//nPz2xMSgC+/BDp0sMzjafq6k2F79uxBQkICQkNDoVAosHXrVp3ty5cvR+/eveHp6Ql/f3+MGTMGP/74ozzBEhGRLo48JyIicigceS4/tm0hIrKynBzg44+lvto9egAlJcD588DAgcChQ1Lf7djY+uWEBKBLF6BnT5kDB6BQSC1S5PLee1JLleakpwN9+wKXLgHR0cC4cdL648elc33uHLBxo3GP5eJi+77ujqiiogLR0dGYNWsWJk+e3GR7z5498c4776B79+64du0aVq1ahbFjxyI/Px/BwcEyRExERFosnhMREemVczYHmQXSCLasgiy4ubghwicChdekScWCPIIMLnurvDGm+xicKT6Do1eO4nrNdVysvIjIgEhAAPlX83WWQzxDUF1b3eKxz5adBQDkFeVhVJdRtjshpMXiORGRFRnqWd6wqLt5c9NlzSSdco2GViqBtWtt3+u8oZgYIDHRcPua33+Xrg8eBB5+uGnfcqWy5fY3SiWQkiLvc3UU48ePx/jx45vdft999+ncfuutt5CamoqDBw/itttus3Z4RERkCIvnRERETSRtTUL6L63vmbr6x1ZONmbA7O2zkVmQibRJaVZ7DNKPxXMiIitpbc/yurr6wnmPHsBDDwHZ2dLn3YgIoKhI2hYYaHjZ2xu49Vapn/exY0BVFXD5snRMoH6UdsPlwYOBYcPso5iclgbExQEzZxreT9O3PD5eN+60NGDhQmDTJmn0f8Nz1L279AWFvTzXtub69etYu3YtfH19ER0d3ex+1dXVqK6u1t4uLS21RXhERM6HxXMiIiIdOWdzLFI4t4X0X9KxMGYhYjrL0FfVibF4TkRkJZbsWX78OPB//wdkZVnumI4kKQn47ruWv4zQ9C1vXAiPiZGnb7uzysjIwLRp01BZWYlOnTph165dCAoKanb/lStXYsWKFTaMkIjISbF4TkREpEPTqsVRZJ3JYvHcxjhhKBGRlYwcadnj7d0LZGRY9piOJC0N2L7d8D6aVjckr9GjR+PAgQPYu3cvxo0bh6lTp+LSpUvN7r948WKUlJRoL2fOnLFhtEREToTFcyIiIh0jIyz8wd3KYsNj5Q7B6bB4TkRkJTExQEiIZY+5Y4dlj+doPD0Nb1+0iO1X7IGnpyciIyMxdOhQpKamol27dkhNTW12f5VKBR8fH50LERFZAYvnREREOmI6xyC+R7zcYRglMTqRo85lwLYtRERWkJMDfPQRUChNko1x44CdO6W+3A1Nny59jh02DNizB/jqK8PHHTfOOvE6iqio5rcpFMCjj9ouFjJeXV2dTk9zIiKSCYvnRERETTw5/EnsPL4THT074qnYp5B9JhuuSldE+ESg6Jo0YVagR6DBZW+VN27tfivUJWocKzqGqpoqXK68jB4BPQABHL96XGc52DMYNbU1Rh97ev/pLJzLRNbi+Z49e/D6669j3759OH/+PLZs2YJJkyZpty9fvhyffvopzpw5Azc3NwwePBgvvfQSbr75ZvmCJiJqQVJS097cO3YAiYlSQb22FnBxAVJSgOTk+n0WLdJ/X43hw4GJE60VtWMICwPWrwdmz9Zdr1AA69Zx1LktlJeXI18zky2AkydP4sCBAwgICEBgYCBeeukl3HHHHejUqRMKCwvx7rvv4uzZs5gyZYqMURMREQAWz4mIiPTQFLFDfUKxaNgiYJjMAZFdkbV4XlFRgejoaMyaNQuTJ09usr1nz55455130L17d1y7dg2rVq3C2LFjkZ+fj+DgYBkiJiLSpVZLvcgBqbj93/82X/zeuBH44QegokLqy62v0JuWBixcCGzaJN0OCwNOnJBGnDt74VwjORmIj5f6vx87BvTsKZ0bFs5tIzc3F6NHj9beXrRoEQAgMTER77//Po4cOYL09HQUFhYiMDAQMTExyMzMRL9+/eQKmYiINFg8JyIiaqKmTsqPrkrmR2pK1uL5+PHjMX78+Ga333fffTq333rrLaSmpuLgwYO47bbbrB0eEZFBqanAnDlNW7E0p65OKpzHxRneLyZGulDzwsKA+fPljsI5xcXFQRh402/evNmG0RARkUlYPCciImpCM/Lc1YX5kZpymAlDr1+/jrVr18LX1xfR0dHN7lddXY3S0lKdCxGRpanVphXOAUCplEacExEREcmCxXOntGfPHiQkJCA0NBQKhQJbt27VbqupqcHTTz+N/v37w9PTE6GhoXjwwQdx7tw5+QImIrIxjjwnQ+x+wtCMjAxMmzYNlZWV6NSpE3bt2oWgoKBm91+5ciVWrFhhwwiJyBnl5ZlWOFcogLVr2VqEiIjIKeTkAJmZ0nJWFuDmBkRE1M8kHhRkeNnbGxgzBjhzBjh6FLh+Hbh4sf5b+Px83eWQEEAzMbOhY589Ky3n5QEjR1rv+ZNdMdQutbKyEvv378eSJUsQHR2Nq1ev4tFHH8Udd9yB3NxcmSImIrItjjwnQ+y+eD569GgcOHAAhYWFWLduHaZOnYoff/wRHTp00Lv/4sWLtf1XAaC0tBTh4eG2CpeInERUlPH7vvwyMGMGC+dEREROwdDs36ZYvbr1x2hOcjKwZ4802Qq1eYbapfr6+mLXrl0669555x0MGTIEBQUFiIiIsEWIRESy4shzMsTu27Z4enoiMjISQ4cORWpqKtq1a4fU1NRm91epVPDx8dG5EBFZWlgY8OSTLe+3fj2weDEL50RERE4hJ8cyhXNbSE+X4iVqpKSkBAqFAn5+fs3uw3apRNSWcOQ5GWL3xfPG6urqUK35SSIRkYwefdTw9u3bpYFdRERE5CQ0rVocRVaW3BGQnamqqsLTTz+N6dOnGxyItnLlSvj6+mov/LU3ETkyjjwnQ2QtnpeXl+PAgQM4cOAAAODkyZM4cOAACgoKUFFRgb///e/44YcfcPr0aezbtw+zZs3C2bNnMWXKFDnDJiICII0m79ZN/7bERGDiRNvGQ0RERDJztD7isbFyR0B2pKamBlOnToUQAmvWrDG47+LFi1FSUqK9nDlzxkZREhFZHkeekyGy9jzPzc3F6NGjtbc1vcoTExPx/vvv48iRI0hPT0dhYSECAwMRExODzMxM9OvXT66QiYh0eHpK1889B7RvL83VNWECEBMjb1xEREQkg5gYYPx44N//ljuSliUm8j8spKUpnJ8+fRrffvtti+1PVSoVVCqVjaIjIrIujjwnQ2QtnsfFxUEI0ez2zZs32zAaIiLTVVRI1xMmAEOHyhsLERER2YGnn5aK58HBwDPPANnZgKsrEBEBFBVJ+wQGGl729gZuvRVQq4Fjx4CqKuDyZaBHD2m/48d1l4ODgZoa4489fToL56SlKZzn5eVh9+7dCAwMlDskIiKbul57HQCL56SfrMVzIiJHp5kbqaxM3jiIiIjITtTWStcdOgB//LKWSE7l5eXIz8/X3ta0Sw0ICECnTp1wzz33YP/+/cjIyEBtbS0uXLgAAAgICICbm5tcYRMR2QzbtpAhDjdhKBGRvUhNrR/MNW6cdJuIiIicnKZ47uIibxxEf8jNzcWgQYMwaNAgAFK71EGDBmHp0qU4e/Ystm3bBrVajYEDB6JTp07ay969e2WOnIjINti2hQzhyHMiIjOo1cDcufW36+qAefOA+HhpIlEiIiJyUjduSNft+FGL7ENL7VINbSMicgaakeftlMzd1BTfFUREZsjLkwrmDdXWAvn5LJ4TERE5NY48JyIikpW6VI0Pf/4QR64cwcCOA3Ho0iEUVxUjNiJWu9yvQz8cunQI/h7+OHr5KADgVPEpeQMnu8TiORGRGby8mq5zcQEiI20fCxEREdkRFs+JiIhkk7o/FbO3z9be3nhwo3Z585HNepcbrotNjUVWcpZ1gySHwp7nREQmSk0Fbr5Zd51SCaSkcNQ5ERGR02PbFiIiIlmoS9U6hXNz7FXvRcaxDAtFRG0Bi+dERCZQq4E5cwB9rSHj420fDxEREdkZjjwnIiKSRV5RnkWOsyN/h0WOQ20Di+dERCbIy9NfOK+rk/qdExERkZNj8ZyIiEgWUYFRFjnOuMhxFjkOtQ0snhMRmUBfr3NAatvCfudERETEti1ERETyCPMJw/qE9a06xvCw4ZjYc6KFIqK2gP+jIyIyweef61+/aBH7nRMRERE48pyIiEhGyTcl4/Gdj6Psehkm9ZqEkV1G4vDlwyiuKsaw8GHa5T7BfXD48mH4ufuhT3AfnLh6AuMix7FwTk2weE5EZCS1GnjjDf3bpk61bSxERERkp1g8JyIiklXVjSoAwD9v/yfCfDjKjVqHbVuIiIyUZ2DukYoK28VBREREdoxtW4iIiGRTU1uDmroaAEB71/YyR0NtAYvnRERGiooCFIqm611c2O+ciIiI/sCR50RERLK5duOadpnFc7IEFs+JiIwUFgbMnq27TqkEUlLY75yIiIj+wOI5ERGRbCprKgEACiigclHJHA21BfwtIRGRCUJCpOtbbwXmzweGDWPhnIiIiBpg2xYiIiKLUpeqsf3Idhy9chQqpQqF1woBAEEeQU2Wy6rLAACuSlecLTvLnufUavwfHRGRCY4cka4nTgSmTJE3FiIiIrJDHHlORERkMan7UzF7++yWd2zket11RKyKwLqEdUi+KdkKkZGzYNsWIiIjqdXADz9Iy0FB8sZCREREdorFcyIiIotQl6rNKpxrCAjMy5gHdanaglGRszF75Hlubi4+//xzFBQU4Pr16zrbNm/e3OrAiIjsSWoqMGcOIIR0OzERuH4dSOYX2ORAmLuJiGyAbVvIgpi7iciZ5RXltfoYtaIW+Vfy2b6FzGbWyPNPP/0Uw4cPx+HDh7FlyxbU1NTg0KFD+Pbbb+Hr62vpGImIZKVW6xbOAWl53jxpG5EjYO4mIrIRjjwnC2HuJiJnFxUY1epjuChcEBkQaYFoyFmZVTx/+eWXsWrVKmzfvh1ubm5YvXo1jhw5gqlTpyIiIsLSMRIRySovT7dwrlFbC+Tn2z4eInMwdxMR2QiL52QhzN1E5OzCfMKwPmG92fdXKpRImZjCUefUKmb9lvD48eOYMGECAMDNzQ0VFRVQKBR4/PHHceutt2LFihUWDZKISE5RUYBC0bSA7uICRPILbHIQzN1ERDbCti1kIczdRERA8k3J2Hp0KzKOZeCWLrdgaOhQFF0rAgAEegTqXe7u3x2RgZEYFj6MhXNqNbP+R+fv74+ysjIAQOfOnfHbb7+hf//+KC4uRmVlpUUDJCKSW1gYsG4dMLvBPCVKJZCSIm0jcgTM3URENsKR52QhzN1ERBJXpSsAYNqfpmH+n+fLHA05G7PatowaNQq7du0CAEyZMgWPPvoo5syZg+nTp+O2226zaIBERPYgORn405+k5cWLgdOnOVkoORbmbiIiG9GMPGfxnFqJuZuISFJTVwOgvohOZEtmjTx/5513UFVVBQB49tln4erqir179+Luu+/Gc889Z9EAiYjsxfXr0vX48RxxTo6HuZuIyEY0I8/ZtoVaibmbiEhSU/tH8dyFxXOyPbP+RxcQEKBdViqVeOaZZywWEBGRvSovl669vOSNg8gclsrde/bsweuvv459+/bh/Pnz2LJlCyZNmgQAqKmpwXPPPYevv/4aJ06cgK+vL8aMGYNXXnkFoaGhlngaRET2j21byEL4uZuISMKR5yQns4rnpaWletcrFAqoVCq4ubm1KigiInvE4jk5Mkvl7oqKCkRHR2PWrFmYPHmyzrbKykrs378fS5YsQXR0NK5evYpHH30Ud9xxB3Jzc1v9HIiILEKtBrZvB44eBVQqoLBQWh8U1Pzy6dNATQ0QGwscOgQUF+su9+snLfv7S9cAcPy4rZ8ZtTH83E1EJOHIc5KTWcVzPz8/KBSKZreHhYUhKSkJy5Ytg1JpVlt1IiK7IgTwx3xNaOZzDJFds1TuHj9+PMaPH693m6+vr7Y3q8Y777yDIUOGoKCgABEREeYFT0RkKampujOAm2rz5paXNT79FCgoALKyzH88cmr83E1EJOHIc5KTWcXztLQ0PPvss0hKSsKQIUMAAD/99BPS09Px3HPP4fLly3jjjTegUqnw97//3aIBExHJ4f33pQI6AAwZAqxdywlDybHIlbtLSkqgUCjg5+fX7D7V1dWorq7W3m5upB0RUauo1a0rnJtj714gIwOYONG2j0ttAj93ExFJOPKc5GRW8Tw9PR1vvvkmpk6dql2XkJCA/v37IyUlBd988w0iIiLw0ksvMYkTkcNTq4G//rX+dl0dMG8eEB/PiUPJcciRu6uqqvD0009j+vTp8PHxaXa/lStXYsWKFRZ5TCKiZuXlyfO4O3aweE5m4eduIiLJ9drrADjynORh1m+79u7di0GDBjVZP2jQIGRnZwMARowYgYKCgtZFR0RkB/LypIJ5Q7W1QH6+PPEQmcPWubumpgZTp06FEAJr1qwxuO/ixYtRUlKivZw5c8YiMRAR6YiKkudxx42T53HJ4fFzNxGRRNu2hSPPSQZmFc/Dw8ORmpraZH1qairCw8MBAEVFRfD39zd4nD179iAhIQGhoaFQKBTYunWrdltNTQ2efvpp9O/fH56enggNDcWDDz6Ic+fOmRMyEZHZoqKAxm0kXVyAyEh54iEyh6VytzE0hfPTp09j165dBkedA4BKpYKPj4/OhYjI4sLCgPXrbfuYw4dz1DmZzZa5m4jInmnbtnDkOcnArLYtb7zxBqZMmYJ///vfiImJAQDk5ubiyJEj+PLLLwEAOTk5uPfeew0ep6KiAtHR0Zg1axYmT56ss62yshL79+/HkiVLEB0djatXr+LRRx/FHXfcgdzcXHPCJiIyS1gY8PTTwMqV0m0XFyAlhS1byLFYKne3RFM4z8vLw+7duxEYGNjq2ImILCY5WZrc8+uvgbg44OabgaIiaVtgYPPLBQVATQ0wbBhw+DBQXKy73KePtOznJy2fOCGNOGfhnFrBVrmbiMjeceQ5ycms4vkdd9yBo0ePIiUlBUePHgUAjB8/Hlu3bkXXrl0BAAsWLGjxOOPHj8f48eP1bvP19cWuXbt01r3zzjsYMmQICgoKEBERofd+nHSMiKzh1lul4nm3bsCePSyck+OxVO4uLy9HfoOeRSdPnsSBAwcQEBCATp064Z577sH+/fuRkZGB2tpaXLhwAQAQEBAANzc3yz8xIiJTuf7xwXvaNGkSEyI7ZancTUTk6DjynORkcvG8pqYG48aNw/vvv4+VmmGYNlJSUgKFQgE/P79m9+GkY0RkDeXl0nXHjiyck+OxZO7Ozc3F6NGjtbcXLVoEAEhMTMTy5cuxbds2AMDAgQN17rd7927ExcW16rGJiCyiRvoAri2iE9khOT93ExHZG448JzmZXDx3dXXFwYMHrRGLQVVVVXj66acxffp0g71QFy9erP0gD0gjzzX94IiIzKWZh6m8HFCrWUAnx2LJ3B0XFwchRLPbDW0jIrILLJ6TA5DrczcRkT3iyHOSk1kThj7wwAN6Jy6xFk3/VCEE1qxZY3BfTjpGRJaWmgo8+qi0/OuvQESEtI7Ikdg6dxMR2S0Wz8lBWCp379mzBwkJCQgNDYVCocDWrVt1tm/evBljx45FYGAgFAoFDhw40OrHJCKyJM3IczcXtoEk2zOr5/mNGzfwwQcf4L///S8GDx4MT09Pne1vvfWWRYID6gvnp0+fxrfffstiOBHZlFoNzJmju04IqUVqfDxHoJPjsGXuJiKyayyek4OwVO6uqKhAdHQ0Zs2ahcmTJ+vdPmLECEydOhVzGv/Hl4jIxtSlauwt2Iuia0U4dfUU8q/mo7KmEgBQWFmIbv7dZI6QnI1ZxfPffvsNN910EwDg2LFjOtsUCkXro/qDpnCel5eH3bt3IzAw0GLHJiIyRl6eVCxvrLYWyM9n8Zwch61yNxGR3dMUzzmJMdk5S+Xu8ePHY/z48c1unzFjBgDg1KlTpgdJRGRBqftTMWf7HAjobwV58/qbsS5hHZJvSrZxZOTMzCqe79692yIPXl5ejvz8fO3tkydP4sCBAwgICECnTp1wzz33YP/+/cjIyEBtbS0uXLgAAAgICIAb/7NLRDYQFQUoFE0L6C4uQGSkPDERmcNSuZuIyOFx5Dk5CHvO3dXV1aiurtbeLi0tlTEaImoL1KVqg4VzABAQmJcxD/GR8Qjz4Ug2sg2zep5bSm5uLgYNGoRBgwYBABYtWoRBgwZh6dKlOHv2LLZt2wa1Wo2BAweiU6dO2svevXvlDJuInEhYGPDAA7rrlEogJYWjzomIiBwSi+dErbZy5Ur4+vpqL+Hh4XKHREQOLq8oz2DhXKNW1CL/Sn6L+xFZilkjzwGp8P3555+joKAA169f19m2efNmo44RFxcHoa8fwh8MbSMishXNn7hx44BZs4Bhw1g4J8dkidxNROTwWDwnB2KvuXvx4sVYtGiR9nZpaSkL6ETUKlGBUVBA0WIB3UXhgsgA/gycbMeskeeffvophg8fjsOHD2PLli2oqanBoUOH8O2338LX19fSMRIRySY1FfjsM2l5506gtJSFc3JMzN1ERH9g8ZwchD3nbpVKBR8fH50LEVFrhPmEYV3COoP7KBVKpExMYcsWsimzRp6//PLLWLVqFRYuXAhvb2+sXr0a3bp1w7x589CpUydLx0hEJAu1Gpg7t/62EMC8eUB8PAvo5HiYu4mI/sDiOTkI5m4icjbJNyXjw4MfYs/pPUiMTkTH9h1x/Opx9AjogcGhgzEsfBgL52RzZhXPjx8/jgkTJgAA3NzcUFFRAYVCgccffxy33norVqxYYdEgiYjkkJwM1NXprqutBfLzWTwnx8PcTUT0BxbPyUFYKneXl5cjP7++P/DJkydx4MABBAQEICIiAleuXEFBQQHOnTsHADh69CgAoGPHjujYsaOFnxURkWEuChcAQHyPeEzvP13maIjMbNvi7++PsrIyAEDnzp3x22+/AQCKi4tRWVlpueiIiGSSkwP85z9N1yuVQCTbq5EDYu4mIvoDi+fkICyVu3NzczFo0CAMGjQIALBo0SIMGjQIS5cuBQBs27YNgwYN0hbqp02bhkGDBuH999+35NMhIjJKTZ2Up11dmKfJPpg18nzUqFHYtWsX+vfvjylTpuDRRx/Ft99+i127duG2226zdIxERDaXmal//ZQpHHVOjom5m4joDyyek4OwVO6Oi4uDEM1PwJeUlISkpCQLRExE1Ho1tX8Uz5XM02QfzCqev/POO6iqqgIAPPvss3B1dcXevXtx991347nnnrNogEREchg5Uv/6J56wbRxElsLcTUROSa0G9u4FioqAU6ek3msVFdK2wkIgKkrW8IgMYe4mImfEkedkbxTC0FfQjZSWlhq1nz3NtF1aWgpfX1+UlJTYVVxEZP+mTgW++KL+dmIikJYmWzjkYOwl/zB3E5HTSk0F5syRZvzWR6EA1q2TJjkhgv3kH+ZuInJmA9YMwK+XfsV/HvgP/tLjL3KHQ3bOFvnHpJHnfn5+UCgULe5XW1trdkBERPbipZek4rmbG/D990BMjNwREZmOuZuInJJabbhwDkjb5s0D4uPZk43sCnM3ETkzjjwne2NS8Xz37t3aZSEEbr/9dqxfvx6dO3e2eGBERHLT/Ko7IICFc3JczN1E5JTy8gwXzjVqa6VWLiyekx1h7iYiZ8ae52RvTCqe33LLLTq3XVxcMHToUHTv3t2iQRER2QNN8dzTU944iFqDuZuInFJUlNSWpaUCuosLEBlpm5iIjMTcTUTOjCPPyd4o5Q6AiMheVVZK1yyeExEROZiwMKmfuSFKJZCSwlHnREREdoQjz8nemDTynIjsW0YG8PXX0gCqQ4eA4mJg5kxg4kS5I3NMp09L15WVUutUfrYmIiJyIMnJwMcfA7t3Aw88AHTuDBw/DvToAQweDAwbxuRORERkZzjynOxNq4vnxkxkQkTWFxsL7N3bdP3mzcDw4UBWlu1jcmSpqdI8Y4DUCjUiQhrAlpwsb1xElsDcTUROo90fH3fi46UCOpGDYu4mImfBkedkb0wqnk+ePFnndlVVFebPnw/PRj0NNm/e3PrIiMhoGRn6C+cae/dKxfXFizkKvTlqtTS3mJcXsGsX8OyzutuFAObNkz57c5AaORLmbiJyajXSB3C48gM4OQ7mbiJyZhx5TvbGpOK5r6+vzu0HOHqDyC58/XXL++zdCyQkcBS6PqmpwNy5QF2d4f1qa6VR6CyekyNh7iYip8biOTkg5m4icmYceU72xqTi+YYNG6wVBxG1wu23A2vWGLfv3r3SSHWOQJeo1cYVzgHAxUXqJ0/kSJi7icipsXhODoi5m4iclRCCI8/J7nDCUKI2YOJEIDwcOHPGuP137GDxXCMvz7jCuUIBpKRw1DkREZFDYfGciIhINupSNbYf2Y7c87kAgCCPIBReK2yyrFKqcLHyIrr7ddfe99eLv6KjV0fbB03UCIvnRG3EAw8AK1cC/fsDSUnAnj3AV1/p33fcOJuGZtdOnzZuv23b+IUDERGRw2HxnIiISBap+1Mxe/tss+8/9qOxSIxORNqkNMsFRWQGpdwBEJFlVFVJ17ffDixaBGzdCiQmNt1v+HAWgTWSkoCZM1veLzGR54yIiMghsXhORERkc+pSdasK5xrpv6Qj52yOBSIiMh+L50RtxLVr0rWHR/26tDTgp5+AAQOk2wkJnCxUIycHSE83vM/06dL5S0uzSUhERERkaSyeExER2VxeUZ7FjpV1hkUMkhfbthC1EfqK5wAQEwPcey9w8CDQoYPt47JXmZmGtycmsmhORETk8Fg8JyIisrmowCiLHSs2PNZixyIyB0eeEzkwtRpYswZ47DGpOA40LZ4DgJeXdF1ebrPQ7N7Ikc1v276dhXMiIqI2gcVzIiIimwvzCcPaiWtbfZzE6ETEdI6xQERE5uPIcyIHlZoKzNbTQiw3t+k6b2/puqzMujE5kpgYaXLVX3+tX6dQAOvWsb85ERFRm8HiORERkSwm9JygXZ41cBaUUCLQIxBF14oAQGfZVemKy5WX0SOgB3xVvqiurcaEnhNYOCe7wOI5kQNSq/UXzgHgww+Bl14CwsLq13HkuX5jxkjF8+HDgRkzpKJ5w/NGREREDo7FcyIiIlkUlBQAACJ8I5B6Z6rM0RCZj21biBxQXgtzbzQurGtGnrN4rquiQrqOjwfmz2fhnIiIqM1h8ZyIiEgWp4tPA5CK50SOjMVzIgcU1cLcGzt3Ajk59bc1I8/ZtkWXpnju6SlvHERERGQlLJ4TERHJQjPyvItvF5kjIWodFs+JHFBYGLB+veF9srLql9m2Rb/KSumaxXMi4+3ZswcJCQkIDQ2FQqHA1q1bdbZv3rwZY8eORWBgIBQKBQ4cOCBLnEREEAK4cUNaZvGciIjIphq2bSFyZOx5TuSgZs5svu85AMTG1i+zbYuunBxg+3Zg/37p9sWL8sZD5EgqKioQHR2NWbNmYfLkyXq3jxgxAlOnTsWcOXNkiJDIzqnVUhI6ehRQqYDTp6XR0bGxwKFDQHGx7nK/ftKyvz/Qt6/07bi/PzBpkvTtb1SUc/Qd0yTv6mqgsFBaFxSkf1mlkpJ7t2719z94UJrshIiIqA1Ql6qxt2Av9p3bh/yr+QjxDEF1bTUAIMgjCIXXCk1aPl1yGjV1NYiNiMWhS4dQXFWss9yvQz8cunQI/h7+6BvcF1kFWTrLbi5uiPCJ0DnmV0e/AgDU1dXZ9NwQWZpCCCHkDsKaSktL4evri5KSEvj4+MgdDpHF/POfwCOP6N+WmAikpdXfvngR6NgRUCiA2lrp2lklJQHp6U3XNz5nRK3lDPlHoVBgy5YtmDRpUpNtp06dQrdu3fDzzz9j4MCBJh3XGc4dOanUVMPffJtDqQTWrgWSky17XHuSmCjNiG6J4zDZkwHMP+bjuSOyndT9qZizfQ4EHKeclxidiLRJaXKHQW2QLfKPrG1b+NNvIvOo1cBjj+muUyiAZcuAn35q+rlQ07ZFiPpWJc5CrQbWrJFqCnfcob9wDkjrG/aJJyLbqa6uRmlpqc6FqM1Rqy1fOAeAujpg3jzp+G1RTo5lCucAkz0RETk8dana4QrnAJD+SzpyzjIHk2OStXiu+en3u+++2+z2ESNG4NVXX7VxZET2LS9P+qzckBBAXBwQE9N0//bt60ebO1PrltRUIDwceOgh4IMPpF97G9KwTzwR2c7KlSvh6+urvYSHh8sdEpHl5eVZ79i1tUB+vvWOL6fMTMsej8meiIgcWF5RnsMVzjWyzjAHk2OStef5+PHjMX78+Ga3z5gxA4D0029jVVdXo7q6Wnubo9eoLaqoaLrOxQWIjNS/v0IhjT4vK5MuISHGP5ZaLX3eb01L1ZaOkZMDfPyxFFvj9qXmtoINDQVeeMG0OBv2iSci21m8eDEWLVqkvV1aWsoCOrU9UVHWO7ah/wQ4upEjLXs8JnsiInJgUYFRUEDhkAX02HDmYHJMbW7C0JUrV2LFihVyh0FkNfp6diuVQEqK4eK2t7dUnDZl5HlqKjB3rjTK3dyWqi0do7ke5I1t3tzycmskJuoftU9E1qdSqaBSqeQOg8i6wsKA9est37rFxaXl/wQ4spgYYNAg4OefW38sJnsiInJwYT5heOTmR7D6x9Vyh2KSxOhExHRmDibH1OaK5xy9Rm2RZmT2iRP6W48IAcTHGz6Gpu95WZlxj6lW1xe9gfqWqvHxwPnz+keK9+ghjfoGgFOngIMHgZ07pfg0x5g9G/jvf4GICODw4ZZbqVjb7NnS8+RnaSIisrrkZOCll4CTJ4F77pESZ0GB9BOrYcOkxFhcrLvcp4+07OcnLWdnSzOBZ2YCN98MfPll2y2ca9x+u1Q8j4kBbr0VKCqS1gcG6l92dQUuX5bOr68vUF0NTJjAZE9ERG3CyIiRWP3javQK7IVJPSfh+NXjCPYMRk1tDQAg0CMQRdeKTFouKClAjajBsPBhOHz5MIqrinWW+wT3weHLh+Hn7oc+wX2QfSZbZ9lV6YoIn4gmx/dWeWN6/+ksnJNDa3PFc45eo7bGmJHZQkitTg19dtYUz40dea6vr3ptrVRs3rnTuGM059NPW3d/S0lMBNatkzsKIsdSXl6O/Aa9lU+ePIkDBw4gICAAERERuHLlCgoKCnDu3DkAwNGjRwEAHTt2RMeOHWWJmcguPfEEMHSoeff97DOpeO7h0fYL50D9bOe33gq88oq8sRAREcmsskbKi138uuCVsTLlxWHNLBO1QW2ueE7UluTkGNfSRKlsudWpt7d0bah4rlZLI8Fzc6UBW/q0tnAupzvvBHr3BtzdOQCNyFy5ubkYPXq09rbm116JiYlIS0vDtm3bMHPmTO32adOmAQCWLVuG5cuX2zRWIrtUI40Kg6ur+cdo31661hSV2zrN89Q8byIiIiemKZ63d2VeJLIFFs+J7FhmpnH7rV3b8sCzltq2pKZavg2rPUlMBNLS5I6CyPHFxcVBiOYnKEpKSkJSUpLtAiJyNCyem47FcyIiIq1rN64BYPGcyFZkLZ7zp99EhvXs2fI+27cDEye2vJ+hti1qtf0UzhcsqK8rBAaa1wq28TJ7mhMRkd2wZPG8oEDqo95wApLGy9XVQIcO0u3jx5vuo1JJPdQ1P2HLzwdCQqT76TueMcunT0vPMzYWOHRIStgNl/v1k5b9/YG+fYGsLN1lNzdpchTNMbOzpetLl8w/Z0RObM+ePXj99dexb98+nD9/Hlu2bMGkSZO024UQWLZsGdatW4fi4mLExsZizZo1iIqKki9oIjuiLlVj+5HtOHrlKFRKFU6XnEZNXQ1iI2Jx6NIhFFcV6yz369APhy4dgr+HP/oG90VWQZbOspuLGyJ8IlB4TcpzQR5BOsvVddXo0F7K3cevHm+yz28XfwMAFJYX2vpUEDklWYvn/Ok3UfNSU4E5cwzvk5hoXOEcMNy2JS/PtNisQaGQ+o8nJ8sdCRERkRVZoni+cqV0XVoKfPBB62Oyls2bW142xeuvSwV0/pSMyCQVFRWIjo7GrFmzMHny5CbbX3vtNfzjH/9Aeno6unXrhiVLliA+Ph6///473N3dZYiYyH6k7k/F7O36R5ptPrK5xWVr+s/J/yA2NRZZyVk2eTwiZ6UQhn573QaUlpbC19cXJSUl8PHxkTscIqOo1dKAK33/OhcskAaQmdqz+/HHgbfflgZ73Xcf8OCD9a1e1GogPNy8WBcsAM6dA776qum20aPre4wHB0vrTpyQrgMDgSJpIm4MHix9CeAMc56R82D+MR/PHbVpHh5AVRVw6hTQpYvp98/JAYYMsXhYDuWnn/iTMrIKZ8g/CoVCZ+S5EAKhoaF44okn8OSTTwIASkpKEBISgrS0NO0Atsaqq6tRrfmFCqRzFx4e3qbPHTkfdaka4avM/KBsQ9unb8fEnkaOqiNqY2yRu9nznMgO5eXpL5wDwNSpQFyc6cf84gvp+tAh4Nlnpcv69dJI77AwadmU1i1KpdRrXTNSPClJd3JT9hgnIiLSo7Ujz42dEKUty8pi8ZzIQk6ePIkLFy5gzJgx2nW+vr64+eabkZ2d3WzxfOXKlVixYoWtwiSSRV6RHfxE2wg78neweE5kRSyeE9khTX/yxpTK+pakpsjIAM6ebbp+7lwgPl4qnicnA08/LY0GnzRJalkaGCiNGv/zn6XR6ceOSSPIIyOlvuMNR4qnpQELF0qfZ2Nj+ZmWiIioCSGA2lpp2dzi+ciRlovHUcXGyh0BUZtx4cIFAEBISIjO+pCQEO02fRYvXqxtuwrUjzwnakuiAh2j7/+4yHFyh0DUprF4TmSHPv9c//pFi8xrbfL11/rX19VJ84KFhUkD4TRtVFJS6ucWM0VMDIvmREREzdKMOgfML57HxEg/72r4cy9nkpjI/2wQ2QGVSgWVSiV3GERWFeYThvUJ65vteW4PhocN56hzIitj8ZzIzqjVwJtvNl2vVAKPPmreMW+/HVizRv8xNSPZz5+Xrl1dpVHnREREZGHXr9cvt2bCUM3PvTZtAsrKdCcSabx8/brhiUdcXYHLl4EePaTbx49L+2sK/YaO3dxyQYF0/2HDgMOHgeJi3eU+faRlPz9pOTtbd9nVVZr8peEx3d1Nn/CFiFrUsWNHAMDFixfRqVMn7fqLFy9i4MCBMkVFZD+Sb0rGq1mvIu9KHu7ufTci/SNRUFKAGlGDYeHDcPjyYRRXFess9wnug8OXD8PP3Q99gvsg+0y2zrKr0hURPhEouibluUCPQJ3l63XXEdxeyt0nrp5oso+r0hWVNypxT797WDgnsgEWz4nsTHP9zs0ddQ5Ik3EOHw7s3au7fu3a+mNq2rp06iQV1YmIiMjCLDHyXIM/9yIiC+jWrRs6duyIb775RlssLy0txY8//ogFCxbIGxyRnRCQPqA/NuwxjIgYYfoBhjWzTEQOgSUyIjtTUQEoFLrrWjPqXCMrC9i+HXBxkW4vXgzs2yf1QweAgwela446JyIishJLFs+JiIxUXl6OAwcO4MCBAwCkSUIPHDiAgoICKBQKPPbYY3jxxRexbds2/Prrr3jwwQcRGhqKSZMmyRo3kb2oqZXyt6uSuZvIGXHkOZEdSUrS38J0xgzzR503dPFi/TxlK1dK12vWSL/U1vySe/9+IDVVmkCUiIiILEhTPHdxafpNORGRleTm5mL06NHa25qJPhMTE5GWloa//e1vqKiowNy5c1FcXIwRI0Zgx44dcHd3lytkIrtSU/dH8dyFxXMiZ6QQQl+DiLajtLQUvr6+KCkpgY+Pj9zhEDUrJwcYMkT/NhcX4NSp1hXQ1WqgSxdpktCWWOLxiJwd84/5eO6ozTp1CujWTerffe2a3NEQUSPMP+bjuaO2rMPrHXC58jIOzj+I/iH95Q6HiBqwRf5h2xYiO5GZ2fy22logP791x8/LM65wbqnHIyIiogZycoDXX6+/rVbLFwsREREZjSPPiZwbi+dEdqKoqPltLi5AZGTrjh8VZfxEoApF6x+PiIiI/pCUJP287L33pNtVVUBEhNQnjYiIiOwae54TOTcWz4nsgFoNvPKK/m1KJZCS0voWKmFhwNq19ROGGsI2rERERBaSk6N/QhMhgHnzOAKdiIjIznHkOZFzY/GcyA4011Jl2TLg9GnLTd6ZnCy1W33rLcP71dWxbQsREZFFWLsvGxEREVkVR54TObd2cgdA1Fbl5ADbtwPV1UBhIeDtDdx/PxATI23PyAA+/xzo1AkoK2t6fxcXYPZsy0/aGRYGjBhheB9LtIkhIiIiACNHNr+NCZeIiMiu1dbVQkAAANxc3GSOhojkwOI5kRU88ADw8cdN169eDSQmAkeOAD/+2PIxLF041ygvN7z98cet99hEREROJSYGGD4c2LtXd72l+rIRERGR1WhatgBs20LkrFg8JzJArZZaqnh5SQXnqKj6z7hqtTSyPDdXuh0UJI0wv3xZWt8cfW1P9fnoI+DFF63zmVozeai+VjEAcMstln9MIiIipzVtmlQ879tX+nY8MhIYNoyFcyIiIjunadkCsG0LkbNi8ZyoGampwNy5ugVmpVKadBOQWqpYk6YNqjU+V2smD50zR5qvrDG2XyUiIrKgigrp+uabgcWL5Y2FiIiIjMaR50TE4jmRHmp108I5IN22dtFcw9ptUJOTgZAQICGh6bbYWOs9LhERkdOprJSu27eXNw4iIiIyScOR5y4KFxkjISK5KOUOgMge5eU139LEFmzVBnXiRKkHe0OJifWTmhIREZEFsHhORETkkDQjz12VrlAoFDJHQ0Ry4Mhzclo5OUBmJhAQIF0XF0sjrg8dAs6dAxQK/S1NrGHBAqlXeo8ewODBtm2DmpYGLFwIZGVJz5+FcyIiIgtj8ZyIiMghaUaes2ULkfNi8ZycUlKS/ok7N2+2/GMlJgIjR+pv96LpoZ6cbPnHNUVMDIvmREREFpGTI80cXl0tzSQOAD/8IF1rbhMREZHRcs7m4ONfP0ZZdRmCPIJQeE3Kp80tq5QqXKy8iMiASEAA+VfzdZZDPENQXVtt8Bia5ZKqEgCAEALqUjXCfDjZN5GzYfGcnE5Ojv7CeWvceSfQuzdQVCTdDgwE3N2BCRPqi9Lx8cDGjcD+/fKMMCciIiIra+7beY133wXKy6WffREREVGLkrYmIf0XC3+AN8O1G9cQsSoC6xLWIfkmmUe/EZFNsXhOTicz07LHS0w07jNwWBiweLFlH5uIiIjshLHfzqenS/3S+JMvIiIig3LO5thF4VxDQGBexjzER8ZzBDqRE2HxnJzOyJHm33f2bKBPHyA7G/DzA+bO5WdfIiIigmnfzmdl8T8QRERELcgssPDINwuoFbXIv5LP4jmRE2HxnJxOTIzUTuVf/zLtfuvXy9+bnIiIiOyUKd/Ox8ZaLw4iIqI2YmREK0a+WYmLwkXqn05EToPFc3JK8fFS8dzHB1i2DDh8GCgulnqQa5b79AEKCoBevYAZM9ibnIiIiAyIiQFuuw345hvD+yUmctQ5ERGREWI6x+Av3f+CXSd2yR0KAECpUCJlYgpHnRM5GRbPyekkJgIffigtl5YCTz4JrFvHUeVERETUSvPnS8Xz8HDgvvsMzyRORERELVoYsxC7TuxCSPsQJPRMQKBHIIquSfm1uWVXpSsuV15Gj4AegACOXz2usxzsGYya2hqDx2i43N2/OyIDIzEsfBgL50ROiMVzcio5OfWFcw0hpN7l8fEcXU5EREStUFkpXfftC7zyiryxEBERtQGVNVJu7RfSD+vuXCdzNETkjJRyB0BkS83N5VVXB+Tn2zYWIiIiamM0xfP27eWNg4iIqI3QFM/buzK3EpE8OPKc2rycHGD7dqC6Gvj9d/37KJVAJOf8ICIiotZg8ZyIiMiiWDwnIrnJOvJ8z549SEhIQGhoKBQKBbZu3aqzXQiBpUuXolOnTvDw8MCYMWOQl5cnT7DkkBITgSFDgBdeAF57DcjIaLqPQgGsXcuWLURExmDuJjKgokK69vSUNw4iIqI2gsVzIpKbrCPPKyoqEB0djVmzZmHy5MlNtr/22mv4xz/+gfT0dHTr1g1LlixBfHw8fv/9d7i7u8sQMTkSff3N9fnxR87dRURkLOZuklVOjtSDLSBAui4uBmJjgUOHpOV+/aRlf3+p73hWlu6ymxsQEQEUFkrHCwpqeVmlAi5erP+JWn6+7nJIiPTzNkB6bECakZyIiIha7UL5BQBAXV2dzJEQkbOStXg+fvx4jB8/Xu82IQTefvttPPfcc7jzzjsBAB9++CFCQkKwdetWTJs2zZahkgNqrr95Y5pBYkRE1DLmbpJNUhKQnt50/ebN+pfl9OmnUtE9LU3uSIiIiBxW6v5UrP5xNQBg48GNGNVlFJJvSpY5KiJyNnY7YejJkydx4cIFjBkzRrvO19cXN998M7Kzs5u9X3V1NUpLS3Uu5DzUamDNGiA5Gfjuu5b3Z69zIiLLYe4mq8nJ0V84t2fp6VLcREREZDJ1qRpzM+ZCQAAABATmZcyDulQtc2RE5Gzstnh+4YL005yQkBCd9SEhIdpt+qxcuRK+vr7aS3h4uFXjJPuxbh0QHg489BDwwQfSJKGGsNc5EZFlMXeT1Rj7czJ7k5UldwREREQOKa8oD3VCt1VLrahF/pV8mSIiImdlt8Vzcy1evBglJSXay5kzZ+QOiWwgIwOYO7fl/aZPB2bPlkanFxRII9SJiEhezN3UopEj5Y7APLGxckdARETkkKICo6BU6JasXBQuiAzgT8eJyLbstnjesWNHAMDFixd11l+8eFG7TR+VSgUfHx+dC7VtSUlAQoJx+86dK41Qnz+fI86JiCyNuZusJiYGmDJF7ihMk5jIGcmJiIjMFOYThrUT12pvKxVKpExMQZgPP8gTkW3JOmGoId26dUPHjh3xzTffYODAgQCA0tJS/Pjjj1iwYIG8wZFdyMkB3nwT+Owz4+/j6Wm9eIiInB1zN1nViy8CX3wBuLtLPyHLygKKi4Fhw4DDh6XlPn2kZT8/aTk7W3fZ1RWIiACKiqRjBga2vOzqCly+DPToId0+flx3OTgYqKmpv5+7OzBhAgvnRERErTSl3xTM3j4bAHBowSH0Du4tc0RE5IxkLZ6Xl5cjP7++X9XJkydx4MABBAQEICIiAo899hhefPFFREVFoVu3bliyZAlCQ0MxadIk+YImu5CUZN68YRUVFg+FiMipMHeTbCorpWt/f+k/AklJckZDREREVnamRGrl5+/uz8I5EclG1uJ5bm4uRo8erb29aNEiAEBiYiLS0tLwt7/9DRUVFZg7dy6Ki4sxYsQI7NixA+7u7nKFTHYgJ8e8wrmLCxDJ9mhERK3C3E2y0RTP27eXNw4iIiKyiYKSAgBAhG+EzJEQkTOTtXgeFxcHIUSz2xUKBZ5//nk8//zzNoyK7F1mpnH73Xsv8OWXQG2tVDhPSWGfcyKi1mLuJtmweE5ERORUWDwnIntgtz3P7V1ODvDxx0BZGRAUBBQWSut79JBGNw8fzkKttQQEGLffE08Ab7wB5OdLrwlfDyIiIpk19x8oY5avXpWuS0sBtZqJnYjIgsrKyrBkyRJs2bIFly5dwqBBg7B69WrEyDB/Q87ZHHz868coqy5DkEcQCq9JeaDx8umS06ipq0FCrwScKzmHI1eOYGDHgTh06RCKq4rRr0M/HLp0CP4e/ugb3BdZBVnw9/DHiIgROHH1BNxdpF/FHb96vMnxe/j3QGRgJIaHD3f6CSqNfT1aep1iI2K1r03D5eZep77BfZGSkwIAULmoZHjmREQShTA0fKwNKC0tha+vL0pKSuDj42ORYxrTb1uhANatA5KTLfKQ9Adje50nJgJpadaOhoioedbIP86C566NMnfCEn34Hy0isgJnzj/33nsvfvvtN6xZswahoaH46KOPsGrVKvz+++/o3Llzi/e31LlL2pqE9F8slCssQAEF1iWsQ/JNzplv7On1SIxORNqkNLnDICI7Y4vczeK5CdRq4J//BF57zfj7/O1vwPnzwMCBwKFDQHEx0K+ftOzvD/TtC2RlScvz5gEyfLHvMHJygCFD9G97+WWgf39plHlsLM8jEcnPmT+AtxbPXRtkKImbS6kETp/mCHQishhnzT/Xrl2Dt7c3vvrqK0yYMEG7fvDgwRg/fjxefPHFJveprq5GdXW19nZpaSnCw8Nbde5yzuZgyHoL5woLcFG44NRjp5xuBLo9vh4/zf4JMZ35YZ+I6tkid7Nti5FSU4HZs02/n6bQvnFj/brNm5t/DI6Ybp6hXufDhgFxcTYLhYiIiExh7IQlpqirk741Z/GciKhVbty4gdra2iaTe3t4eOD777/Xe5+VK1dixYoVFo0js8AKucICakUt8q/kO13x3B5fj6wzWSyeE5HNKeUOwBGo1eYVzs2Rng5kZNQ/7u7d0jUBI0fqX69USj3NiYiIyE41l8Rbg/8BICKyCG9vbwwbNgwvvPACzp07h9raWnz00UfIzs7G+fPn9d5n8eLFKCkp0V7OnDnT6jhGRlghV1iAi8IFkQHOl2/s8fWIDY+VOwQickIceW6EvDzbPt4ddwAPPiiNVq+rkz4brl3Ltp4HD+pfv3YtB50RERHZtZgYYNw4YMcOyxxPoeB/AIiILGjjxo2YNWsWOnfuDBcXF9x0002YPn069u3bp3d/lUoFlcqykzjGdI5BYnSi3fTY1hjTbQyW7V4GAFApVbhYeVEqpgvgfMV53NrtVpwrOYd9F/YhxDME1bXV8FZ54/7+92tHSTecdLOHfw8AwKXKS1ApVVC5qpDQM8HuRlTHdI7BuB7jsOO4hXJ3KyVGJ9rdOSIi58Ce50ZQq4Hw8Oa3L1gg9TLftMm8GI2VnOy8fdHVaiAiAmj8bmW7UyKyV87aN9USeO7aqI8+AmbMkJL2uHFAYCBQVCRtM3b5+nWgZ09g4kQmfyKyOOYfoKKiAqWlpejUqRPuvfdelJeX41//+leL97Pkucs5m4NNv21CWVUZAj0CUXRNygONlwtKClAjajCh5wScLz2Po0VHMaDjABy+fBjFVcXoE9wHhy8fhp+7H/oE90H2mWz4ufshNiIWp4pPQaWUiv8nrp7QOf6RoiP4/oz+djWmSoxOxI26G/j414+N2tfeJsT86OBHmLFlBsK8wzCuxziDr0dLr9Ow8GHa16bhcnOvU8PluYPnsnBORHqx57mdCAuTRoJ/+KHueoUCWLeufkT4bbdZt71Laqrz9kXPy2taOAfY7pSIiMhhFBRI12PGSP+BIiIiu+Pp6QlPT09cvXoVO3fuxGuaSbxsKKZzjHUKpcNa3kVdqkb4KgMj50xkyij69F/SsTBmoV0ViQtKpNw9pscYrLvTRrl7WDPLREQyYfHcCGq1NFiqsR9/1B0FnpwMxMdL7VaOHpUmsDx/XloeMAA4fFgaod6nj7Ts5yctZ2RIvc2NlZ4OLFzoXCPQo6L0r3dxYbtTIiIih6ApnkdEyBsHERE1sXPnTggh0KtXL+Tn5+Opp55C7969MXPmTLlDs6m8Ihv3bG3E3ibE1BTPI3yYu4nIebF4boS8PGmEc2MVFU3XhYUBixebdvxBg0wrngNAVpZzFc/1tUhVKoGUFI46JyIicginT0vXLJ4TEdmdkpISLF68GGq1GgEBAbj77rvx0ksvwdXVVe7QbCoqsJlRWzZibxNini6RcneEL3M3ETkvFs+NEBUlFWobFtAtOeI5KkpqAWNK9/kffgByctp2AV2tBvbuldqyPPec7jaFQjoHbfn5ExERtSkceU5EZLemTp2KqVOnyh2G7MJ8wrA+YT1mb7dMP9bE6EQAxrVvsccJMbUjz1k8JyInxuK5EcLCgLVrpck6a2ulwrklRzyHhUmtP+fMMb6A/tln0qWt9j9PTTV8PoTQP/KfiIhIR04O8PHHQFkZEBQEFBZK6xsvnz4N1NQACQnAuXPAkSPAwIHAoUNSz7V+/aRlf3+gb1/pJ2D+/s47k7epfvoJOHZMWnZzkzcWIiIiA5JvSkZ8ZDwyjmbgWNExuCndtBNguipdcbnyMnoE9AAEcKHiAuK6xeF86XnsP78fwZ7BqKmtgbfKG9P7T9cWwxfGLNROgtrdvzsA4HLlZXx19CucKD6BxSMW4+XbXpbrKev1k/onHCuUcrebC3M3ETkvhRCmjHd2PJacdVWtlkZBR0Zap1WIWg1kZwNFRcDVq8Dly0BwMFBSArz6avP3++mntvW5Xa2WBqUZemcqlVKdgy1biMhe2WLW77bKYucuKUmaKMTa2uo32Zai73VYv75+xnUiIjvB3G0+njvz3PP5Pfi/w/+Hd29/Fw/FPCR3OFpJW5OajJZfn7AeyTcxdxORfbFF/uHIcxOEhVm3WBsWBkyZ0nT97t2Gi+dtrf95Xl7LI/CnTGHhnIiIDMjJsU3hHHDOmbyN1dzrMHeuNMs6kzkRETkxVTsVAKD6RrXMkdTLOZujt83M3Iy5iI+MR5gPczcRORel3AFQy6JamLMk1r7mFGk1L6+W93niCevHQUREDiwz07aPl5Vl28dzFM29DnV10s/5iIiInJimHcr12usyR1Ivs0B/7q4Tdci/wtxNRM6HxXMHEBYm/bpZn8TEtjfQrbzc8Pa2+JyJiMjCRo607eO1tW+yLaW510GptNzM60RERA7KTWl/xfOREfpzt1KhRGQAczcROR+2bXEQycnSr5szMoCvvgJ27AB8fKTJS5OTAZUKuHix/nPo+fPArbdKc57t2weEhADV1YC3N3D//fXF54bzqPXoIa27dEk6nkolzZtm60J1VJT0mbquTnf9448D06ezcE5EREaIiZG+bbVVz3MmJ/1iYqT/TGzfXr9OoZBmYmfLFiIicnKati32VDyP6RyDhJ4J2H6sPncroMDaiWvZsoWInBKL5w4kLAyYPx+oqZGK56WlwAcfNL//xo36169eLX3Or60FPvrI8GO+8ILt50ELCwNef72+NYuLC5CSwnnFiIjIRGlpUi/yTZukb4kDA6VZuYGmywUFUoKdMEH6BvroUWDAAODwYaC4GOjTR1r285OWs7Ol5blzWThvyeLFUvHczw9YuRKYOJGFcyIiItS3bamutZ+e5wCweMRibD+2HX4qP6y8bSUm9prIwjkROS0Wzx2MWg088kjrj2PKQLz0dKBnT+DBB233WffOO6Xiubu7NIEoP2MTEZFZYmJY3JZbZaV0rRkFQERERADss+c5AFTWSLk7zDcM82OYu4nIubHnuYPJy5PncZ99FoiIAFJTbfN4ms/Z3t4snBMRETk0TVJv317eOIiIiOyMvRfP27sydxMRceS5g4mKku+xhQBmz5YK2sOHW7eoXVEhXXt6Wu8xiIiIyAZYPCciItJL5WJ/Pc8BFs+JiBriyHMHExYGrF/f+uMkJkoXc9x7L9Cli3VHobN4TkRE1EaweE5ERKSXvfY8Z/GciKgeR547oORkID4eyMgA9u2T1rm6ApcvAz16SLcvXADi4qQ5z/bvB4KDpXnQvL2B6dPr2782nEete3dp3YkTLRfo6+qkUei7dknH7dcPOHQI8PcH+vYFsrJ0l93cpLYvhYXS/YOCDC8XFEi3q6qkPu9s3UJERHYpJ0eaDNPdXbp9/Lh03VKiAwCVCrh4EYiMlG6fPw/ceitw7pyU4ENCgOpqKXnff3998s7JAT7+WEremsR/6ZJ0vOpqoEOH+li8vYGBA4HMTGni09hYKWEXF1s+eTd+Tr6+Ulyac1JUxKRORETUgKZ4nn8lHy/veRnHrx6Ht8obAzsORObpTBRXFSM2IhaHLh1CcVUx+nXoh0OXDsHfwx99g/siqyBLZ9nNxQ0RPhEovCbl5SCPoBaXVUoVLlZeRGRAJHxVvrhUeQnHi6TcXVRZBHWpmpOFEpFTUwghhNxBWFNpaSl8fX1RUlICHx8fucNxGKmpUnHcHigUwLp10pcGRESOgvnHfA5z7mbMAD76yHaPl5gI1Nba9jEtjUmdiOyYw+QfO8RzZ54HtzyIjQc3yh2GQQoosC5hHZJvYu4mIvtji/zDti2kV3Iy8NNPckchEQKYN08arEZERGQXcnJsX8ROT3fswjnApE5ERPQHdana7gvnACAgMC9jHtSlzN1E5JxYPKdmxcRYpr+6JdTWAvn5ckdBRET0h8xMuSNwXEzqREREyCvKkzsEo9WKWuRfYe4mIufE4jkZlJwMnDkDvPyyvHG4uNS3hCUiIpLdyJFyR+C4mNSJiIgQFRgFBRRyh2EUF4ULIgOYu4nIObF4Ti0KCwMWL5ZvFLpSCaSkcH4xIiKyIzExUg9yW0pMtP1jWhqTOhEREQAgzCcM6xLW2X0BXalQImViCicNJSKnxQlDySRqNbBxI3D0KDBgAHD4MFBcDPTpIy37+UnL2dm6y66uQEQEUFQkHScwsOXl7t2lgWnDhvEzNhE5HuYf8znUucvJAf71L0Clkm6fOCFdG5PoXF2By5eBHj2k2xcuAHFxwPnzwP79QHAwUFMDeHsD06dLBXvNY27aBJSVSckSkI7j5gZcvy7dTxOLt7eUsLOypIQ9bJh1k3fD5+TrKy0HBwP+/tJ+TOpEZMccKv/YGZ4786lL1cg+k438onycuHoC3ipvDOg4AFkFWSiuKsaw8GE4fPkwiquK0Se4Dw5fPgw/dz/0Ce6D7DPZOsuuSldE+ESg6JqUlwM9AltcdlW64nLlZfQI6AFflS8uV15GcPtg+Hv4I7B9IIaFD2PhnIjsli3yj90Xz8vKyrBkyRJs2bIFly5dwqBBg7B69WrEaD5AtoBJnIiI5MD8Yz6eOyIikgPzj/l47oiISA62yD9237Zl9uzZ2LVrFzZu3Ihff/0VY8eOxZgxY3D27Fm5QyMiIiIiIiIiIiKiNsqui+fXrl3D//3f/+G1117DqFGjEBkZieXLlyMyMhJr1qyROzwiIiIiIiIiIiIiaqPsunh+48YN1NbWwt3dXWe9h4cHvv/+e733qa6uRmlpqc6FiIiIbKesrAyPPfYYunTpAg8PDwwfPhw5OTlyh0VERERERERkErsunnt7e2PYsGF44YUXcO7cOdTW1uKjjz5CdnY2zp8/r/c+K1euhK+vr/YSHh5u46iJiIicG1uuERERERERUVtg18VzANi4cSOEEOjcuTNUKhX+8Y9/YPr06VAq9Ye+ePFilJSUaC9nzpyxccRERETOiy3XiIiIiIiIqK1oJ3cALenRowf+97//oaKiAqWlpejUqRPuvfdedO/eXe/+KpUKKpVKe1sIAQBs30JERDalyTuaPOQszG25Vl1drb1dUlICgLmbiIhsy1lztyXwczcREcnBFrnb7ovnGp6envD09MTVq1exc+dOvPbaa0bdr6ysDADYvoWIiGRRVlYGX19fucOwmYYt1/r06YOQkBBs2rQJ2dnZiIyM1HuflStXYsWKFU3WM3cTEZEcnC13WwI/dxMRkZysmbsVws6/Vt+5cyeEEOjVqxfy8/Px1FNPwd3dHZmZmXB1dW3x/nV1dTh37hy8vb2hUCjMjqO0tBTh4eE4c+YMfHx8zD6OpTEu0zE20zEu09hrXID9xmavcQHmxyaEQFlZGUJDQ5ttNdZWHT9+HLNmzcKePXvg4uKCm266CT179sS+fftw+PDhJvs3HnleV1eHK1euIDAwkLnbhuw1LoCxmYNxmcZe4wLsNzZ7jQtg7pYDP3fLw17jAhibORiXaew1LsB+Y7PXuAD7zt12P/K8pKQEixcvhlqtRkBAAO6++2689NJLRhXOAUCpVCIsLMxi8fj4+NjdGwxgXOZgbKZjXKax17gA+43NXuMCzIvNWUettbblGgD4+flZLB57fV8xLtMxNtMxLtPYa1yA/cZmr3EBzN22xM/d8rLXuADGZg7GZRp7jQuw39jsNS7APnO33RfPp06diqlTp8odBhEREZnI3JZrRERERERERPbA7ovnRERE5Fj0tVzr3bs3Zs6cKXdoREREREREREZjIzcjqVQqLFu2rMnPyuXGuEzH2EzHuExjr3EB9hubvcYF2Hds9qqkpAQLFy5E79698eCDD2LEiBHYuXOn0S3XLMVeXzvGZTrGZjrGZRp7jQuw39jsNS7AvmMjw+z1tWNcpmNspmNcprHXuAD7jc1e4wLsOza7nzCUiIiIiIiIiIiIiMjWOPKciIiIiIiIiIiIiKgRFs+JiIiIiIiIiIiIiBph8ZyIiIiIiIiIiIiIqBEWz4mIiIiIiIiIiIiIGmHxnIiIiIiIiIiIiIioEYcunq9cuRIxMTHw9vZGhw4dMGnSJBw9elRnn6qqKixcuBCBgYHw8vLC3XffjYsXL2q3//LLL5g+fTrCw8Ph4eGBPn36YPXq1TrH2Lx5M/7yl78gODgYPj4+GDZsGHbu3GlUXJ6ennB3d4dKpcKYMWOQl5enE1f79u3h4uICFxcX+Pj4WDWuhrGpVCrt4w4bNkwbl75z5ufnB4VCgQMHDsh+ziZNmgSFQqH38vHHH1vtnEVGRqJdu3ZQKpVQKBTYunWrzj5VVVWYP38+3N3doVAo0K5dO0yYMEH7XjPmnH3//feIjY1FYGAgPDw80Lt3b6xatarV56y17zNrxqV5j911113o16+f9n1mjbgaxmbo/f+f//yn2fdYTk6OVc+Zh4cH3Nzc4ObmpvNvrvE5c3V1hZubGzw9PbV/04yJq6GsrCy0a9cOAwcObPU5q6qqwtChQ+Hq6gqFQgFXV1eT/86aGput3mfmnDMAEEJg6dKl6NSpEzw8PHTiAoDvvvvO4PusLWPuZu5m7mbuZu5m7mbudizM3czdzN3M3czdzN1OnbuFA4uPjxcbNmwQv/32mzhw4IC4/fbbRUREhCgvL9fuM3/+fBEeHi6++eYbkZubK4YOHSqGDx+u3Z6amioeeeQR8d1334njx4+LjRs3Cg8PD/HPf/5Tu8+jjz4qXn31VfHTTz+JY8eOicWLFwtXV1exf/9+g3E9/vjjwsvLSwwePFh06tRJ3H777aJbt27i2rVr2rhmzJghHn/8cdGpUyfh4uJi1bg0sd1zzz3Cy8tLrFq1SowcOVJ4eHiILl26iGvXrjU5Z9OmTRN+fn4CgPj555/t4px98cUXYseOHWLw4MEiJiZGzJ49W3Tr1k2sX7/eaudszpw5YuHChWLp0qUCgOjYsWOT95mXl5cIDg4Wa9asEf379xdeXl7a95ox52z//v3ik08+Eb/99ps4efKk2Lhxo2jfvr1ISUlp9TlrzfvMmnFp/l127NhR531mjbg0sbX0/p8zZ44IDQ3VeZ916NBBdOvWTdTV1Vn1nL388stiwYIFon///gKA2Lt3r857LDw8XCQkJIiQkBDRp08fMWDAAO3fNGPi0rh69aro3r27GDt2rIiOjm72fBl7zubPny98fHzEggULxP333y9cXFxM/jtramy2ep+Zc86EEOKVV14Rvr6+YuvWreKXX34Rd9xxhzYuIYSorq4W58+f17lo/pbV1dW1eHxHxtzN3M3czdzN3M3czdztWJi7mbuZu5m7mbuZu505dzt08byxS5cuCQDif//7nxBCiOLiYuHq6iq++OIL7T6HDx8WAER2dnazx3nooYfE6NGjDT5W3759xYoVK5rdXldXJzp27Chef/11bVz/+te/hEqlEqmpqU3ievnll20elxD158zV1VVs2rRJ55x9/fXXonfv3mL79u0CgEhPT7dZbMacM81r6efnJ55//nmrxdXQyZMnBQC97zMXFxdtfJrYDL2mxsR21113iQceeKDZ7XK9zywZ19dffy26deumPV+a/yxaOy4hDL//NQ4ePCgAiDlz5jR7XEvE1lBubq4AINavXy+EqH+Ppaena+PTvMc2bdrU7GvaXFz33nuveO6558SyZctaTEimnrMNGzYILy8vs99n5sZm7fdZa86ZENJrqFKpxKZNm/Te5/r16yI4OLjZv2VtGXM3c7c14mqIudvycTF3N8XczdztTJi7mbutEVdDzN2Wj4u5uynmbuZuYzl025bGSkpKAAABAQEAgH379qGmpgZjxozR7tO7d29EREQgOzvb4HE0x9Cnrq4OZWVlBvc5efIkLly4gDFjxmjjioiIwM0334yMjIwmcXXq1AkKhcKmcWmOCQADBgxAdna29pwNGDAAc+bMwcaNG/GnP/0JAHDw4EGbxWbMOevduzeCgoJQUlKCmTNnWi2u5jR+n9XW1mrj07zP/Pz8mn1NW4rt559/xt69e3HLLbc0u48c7zNLxnXx4kXMmTMHn3/+OUJDQ5s9njXi0hwTaPr+b3jOjh07BkA6d9aMraGysjIAgK+vL4D695ifn582Ps177Pz5883+TdMX14YNG3DixAksW7bMqFjMOWcuLi5m/Z1tTWzWfJ+19pwB0mt58803N3tOtm3bhqKiomb/lrVlzN3M3daIqznM3czdloytIeZu5m5nwtzN3G2NuJrD3M3cbcnYGmLuZu42VjuT9rZjdXV1eOyxxxAbG6tNOhcuXICbmxv8/Px09g0JCcGFCxf0Hmfv3r347LPP8K9//avZx3rjjTdQXl6OqVOnNruP5vjBwcGYN2+eNq6QkBAUFBTojUupVNosrpCQEJ1zFhoaigsXLmjP2aOPPor58+fjz3/+M06dOgUAKCoqsklsppyzmpoadO3aFWFhYVaLq6G6ujoAwMCBA3XeZ5q+bA3jCwkJwfXr1/W+poZiCwsLw+XLl3Hjxg0sX74cs2fPbjYeW77PLB2Xr68vbr/9du37LCgoCOfOnbNJXC29/xues9TUVPj6+qKqqsqqsWnU1dXhhRdeAABERkZq43Zzc0N5eblOfJq/Zfr+pumLKy8vD8888wwyMzPRrp1xf/7NOWcNY9PH0rFZ833W2nPWkKFzkpqaivj4eL1/y9oy5m7mbmvF1RBzN3O3tWLTYO5m7nYmzN3M3daKqyHmbuZua8WmwdzN3G2KNjPyfOHChfjtt9/w6aefmn2M3377DXfeeSeWLVuGsWPH6t3nk08+wYoVK/D555+jQ4cOAICPP/4YXl5e2ktmZqZ2/7///e92GRfQ/Dmrra1FWVkZFi9eLEtsxp4ztVqNkpISDBgwwCZxAcDSpUsBAK+88orB2AxpKbbMzEzk5ubi/fffx9tvv41Nmza1GJst3meWjuuf//ynUe8za8QFGPc3Q61WY+fOnQgODrZZbAsXLmwyAZOp9MVVW1uL++67DytWrEDPnj313s8S50yO2Kz1PrPEOTOG5n2WnJxs8n0dHXM3c7e14wKYu5m7rR8bczdztzNh7mbutnZcAHM3c7f1Y2PuZu42iUlNXuzUwoULRVhYmDhx4oTO+m+++UYAEFevXtVZHxERId566y2ddYcOHRIdOnQQf//735t9nE2bNgkPDw+RkZGhs760tFTk5eVpL5WVleL48eMCgAgJCdGJa9SoUeKuu+5qEteGDRuEQqGwWVz33nuvzjkbNWqUeOSRR7TnTKFQCBcXF+1Fs+7BBx+0m3P2/PPPC6VSqdPfyBpxaSxcuFB06tSpSd8mzTlrHF9ERITw8/PTeU2Nia2hF154QfTs2dNi56w17zNLx3X77bcLpVKp8x4DIFxcXLTvM2vF1dL7X3POnn/+eREcHGz23wxTYhOi/m/Znj17dN5nmri++uornfg0cTWMr7m4rl69qj2/motCodCu++abbyxyzjZs2CB8fX1NOmetjc1a77PWxtW4v5vmnDWmeZ9dv3692fdPW8TczdxtzXOmwdxt2biYu5m7LRUbc7djYu5m7rbmOdNg7rZsXMzdzN2Wis2Zc7dDF8/r6urEwoULRWhoqDh27FiT7ZqG+l9++aV23ZEjRwQaNdT/7bffRIcOHcRTTz3V7GN98sknwt3dXWzdutWouB566CGhVCrF008/rV1fUlKi01C/YVz6JpSwdFxCCFFbWyvat28vfHx8tOdME1fDSQjeeust8euvv4pff/1VrF+/XgAQL7/8sjhz5oxVYjP1nNXV1YnOnTvb5Jw1fJ99++23Tf5xNpy4RBOf5n3WMD5jYmtsxYoVokuXLs3GZav3mTXiWrNmjfY9tm3bNu35+vLLL8WZM2csHpcQxr//v/zyS1FXVye6desmZs6caZNz1vBvmWaCHM37rPHEJV9++aX2Pfbpp59q4zMUV21trfZ8ay4LFiwQvXr1Er/++qvOLPbmnjMhmp+4xNKx2eJ9Zu4500xc8sYbbzSJq/HEJZr32RNPPKH3WG0RczdzN3M3c7excQnB3M3czdxtD5i7mbuZu5m7jY1LCOZu5u62l7sduni+YMEC4evrK7777jtx/vx57aXht5bz588XERER4ttvvxW5ubli2LBhYtiwYdrtv/76qwgODhYPPPCAzjEuXbqk3efjjz8W7dq1E++++67OPsXFxQbjmjt3rvDx8RFpaWni22+/FRMnThTdunUT165d08a1adMm8fHHH4vw8HChVCrFzz//LH7++Wfx448/WjwuTWzu7u7Cy8tLG1d8fLzo0qWLuHbtmt5zdtNNN+n8QZH7nH377bfivffeEwDEwIEDrfpaamLz8fER69atExs3bhQAxPvvvy+ys7PF+fPntefMy8tLdOjQQbz//vtiwIABwsvLS/teMya2d955R2zbtk0cO3ZMHDt2TKxfv154e3uLZ599ttXnrDXvM2vG1fDfZcP3mTXOlyY2Y9//b7zxhvY9ZurfDHPP2bZt28SuXbu077MPP/xQ/Pzzz+L8+fPauBISEkTHjh1F3759xYABA7R/04yJqzFjZrA29px17txZrF27VsybN08olUoxYMAA8fPPP4uysjKrxGar95k550wIIV555RXh5+cnvvrqK3Hw4EFx5513auNq6L///a8AIA4fPtziMdsK5m7mbuZu5m7mbuZu5m7HwtzN3M3czdzN3M3c7cy526GL55pvMhpfNmzYoN3n2rVr4qGHHhL+/v6iffv24q677tL+4RVCekH0HaPhN1W33HKL3n0SExNNiqtPnz7i6NGjOnG5ubk1e2xLx2UotpUrVzZ7zuLj43WSuNznzN/fX7i4uIiAgACrv5aGYgMgli1bpo1t3rx5QqVSCUD6acn48eO18RkT2z/+8Q/Rr18/7beNgwYNEu+9956ora1t9TlrzfvMmnE1/Hf5008/ad9n1jhfhmLT9/53c3MTSqXSrL8ZljpnDd9nDc9Zu3bthKurq/Dw8NDGZ0xcjRmTkIw9Z7169dK73+7du60Sm63eZ+acMyGkb7aXLFkiQkJChEqlErfddps2roamT58uhg8f3uLx2pLmXjvmbv1xGYqNudv0c6b5m6qJjbnbvNeSuZu525zYbPU+M+ecCcHcbUhzrx1zt/64DMXG3G36OdP8TdXExtxt3mvJ3M3cbU5stnqfmXPOhLBd7lYIIQSIiIiIiIjo/9m78/CmyvRv4N8kpE1KmzRdaFNK2Vpj8aeAiqKggKgVAcUF3EaLrCozo8OMOryuuOGoM+qMioAV0HF0XMBR3MYZQRgWLZsLlNiyB0JoC026nNOmyXn/CAlNm6RpmiZN8/1cVy9PznontTzJnfvcDxERERGRhzzaARARERERERERERERdTdMnhMRERERERERERERtcLkORERERERERERERFRK0yeExERERERERERERG1wuQ5EREREREREREREVErTJ4TEREREREREREREbXC5DkRERERERERERERUStMnhNRQOvWrYNMJkNNTU20QyEiIqIgcOwmIiKKLRy7ibovJs+JepDXX38dKSkpaG5u9qyrq6uDUqnE2LFjvfZ1D8579+7t1DUPHDgAmUyGnTt3duo8RERE8YhjNxERUWzh2E0UX5g8J+pBxo0bh7q6OmzdutWzbsOGDcjOzsZ3330HURQ969euXYu8vDwMHjw4GqESEREROHYTERHFGo7dRPGFyXOiHsRgMECv12PdunWedevWrcO1116LgQMHYsuWLV7rx40bh7fffhvnn38+UlJSkJ2djVtvvRXHjx/3e42GhgZMmDABo0aNQk1NDQYOHAgAGD58OGQymeeb9rFjx+K+++7zOnbKlCmYPn16uJ4uERFRzOPYTUREFFs4dhPFFybPiXqYcePGYe3atZ7Ha9euxdixYzFmzBjPekEQ8N1332HcuHGw2+148skn8cMPP+Djjz/GgQMH/A60NTU1uOKKK+B0OvH1118jNTUV33//PQDgP//5D8xmM1atWtXlz5GIiKgn4dhNREQUWzh2E8WPXtEOgIjCa9y4cbjvvvvQ3NwMQRCwY8cOjBkzBna7Ha+//joAYPPmzWhsbMS4ceOQl5fnOXbQoEH461//ihEjRqCurg7JycmebceOHcNNN92EgoIC/OMf/0BCQgIAIDMzEwCQnp6O7OzsCD5TIiKinoFjNxERUWzh2E0UP1h5TtTDjB07FvX19SgtLcWGDRtwxhlnIDMzE2PGjPH0X1u3bh0GDRqEvLw8bNu2DZMnT0ZeXh5SUlIwZswYAMChQ4e8znvFFVcgPz8f//znPz0DOBEREXUex24iIqLYwrGbKH4weU7Uw+Tn5yM3Nxdr167F2rVrPYNyTk4O+vXrh02bNmHt2rW47LLLUF9fj6KiImg0GrzzzjsoLS3F6tWrAQBNTU1e5504cSLWr1+P3bt3BxWHXC6HJEle6+x2exieIRERUc/CsZuIiCi2cOwmih9MnhP1QOPGjcO6deuwbt06z0QiAHDppZfiiy++wPfff49x48Zhz549qK6uxrPPPotLLrkEZ555pt9JS5599lkUFxdj/PjxXgO5+9twh8PhtX9mZibMZrPnscPhwM8//xzGZ0lERNRzcOwmIiKKLRy7ieIDk+dEPdC4cePwv//9Dzt37vR8Aw4AY8aMwZIlS9DU1OTpu5aQkIC//e1v2LdvHz755BM8+eSTfs/7wgsv4LbbbsNll12GPXv2AAD69OkDtVqNL7/8EhaLBVarFQBw2WWX4bPPPsNnn32GPXv24O6770ZNTU2XPm8iIqJYxbGbiIgotnDsJooPTJ4T9UDjxo2DIAjIz89HVlaWZ/2YMWNQW1sLg8EAvV6PzMxMrFixAh988AGGDBmCZ599Fi+88ELAc7/44ouYNm0aLrvsMvzyyy/o1asX/vrXv2LJkiXIycnBtddeCwCYMWMGiouLcccdd2DMmDEYNGgQxo0b16XPm4iIKFZx7CYiIootHLuJ4oNMat0ciYiIiIiIiIiIiIgozrHynIiIiIiIiIiIiIioFSbPiYiIiIiIiIiIiIhaYfKciIiIiIiIiIiIiKgVJs+JiIiIiIiIiIiIiFph8pyIiIiIiIiIiIiIqBUmz4mIiIiIiIiIiIiIWmHynIiIiIiIiIiIiIioFSbPiYiIiIiIiIiIiIhaYfKciIiIiIiIiIiIiKgVJs+JiIiIiIiIiIiIiFph8pyIiIiIiIiIiIiIqBUmz4mIiIiIiIiIiIiIWmHynIiIiIiIiIiIiIioFSbPiYiIiIiIiIiIiIhaYfKciIiIiIiIiIiIiKgVJs+JiIiIiIiIiIiIiFph8pyIiIiIiIiIiIiIqBUmzykkX375JYYNGwaVSgWZTIaamhpMnz4dAwYM8Oxz4MAByGQyvPDCC9ELlHq81v/fAYBMJsPjjz8elXi6i3Xr1kEmk2HdunWedb5eKyLq2TheU3fB8do3jtdE1Fkc66m74FhPPRWT5z3A/v378etf/xpnnHEGkpKSkJSUhCFDhmDevHn48ccfw3696upqTJs2DWq1Gq+++irefvtt9O7dO+zXkclk+PWvf+1z24oVKyCTybB169awXzcSBgwYAJlM5vlRqVQoKCjA/fffjxMnTkQ7vA5zf/D78MMPvdY3NTVh0qRJkMvlePPNN6MUHbBp0yY8/vjjqKmpifi1x44dC5lMhoKCAp/bv/76a8//B61fv3gQ6O+cqKfheB17OF5HFsfr7qv13zkTcUS+cayPPRzrIyuaY73T6cRbb72FCy+8EGlpaUhJScEZZ5yBO+64A1u2bIl4POEyYMAATJo0Kdph9Gi9oh0Adc6aNWtw0003oVevXrjtttswdOhQyOVy7NmzB6tWrcLixYuxf/9+9O/fP2zXLC0tRW1tLZ588klcfvnlnvXLli2D0+kM23V6umHDhuH3v/89AEAURWzbtg0vvfQSvv32W3z//fdRjq7z7HY7brzxRnz++edYtmwZZsyYEbFrC4KAXr1O//O2adMmLFy4ENOnT0dqamrE4nBTqVSoqKjA999/jwsuuMBr2zvvvAOVSgVRFLs8Dv6NEkUPx+vYxfG663C89o1/o0SxiWN97OJY33W601j/29/+Fq+++iquvfZa3HbbbejVqxeMRiO++OILDBo0CCNHjoxoPBQ7mDyPYXv37sXNN9+M/v3747///S/0er3X9j/96U947bXXIJcHvsGgvr6+Q99OHz9+HADa/EOnVCqDPkd309HXIBz69u2LX/3qV57Hs2bNQnJyMl544QWUl5f7rXzqiGg8L8A1OE+bNg1r1qzBkiVLMHPmzIheX6VSRfR67Rk8eDCam5vx7rvven0YF0URq1evxsSJE/HRRx91eRyx/DdKFMs4XocPx+vw4njtjeM1EYWKY334cKwPL471LhaLBa+99hpmz56NpUuXem176aWXUFlZGaXI2tfc3Ayn04mEhIRohxK32LYlhj333HOor6/H8uXL2wzOANCrVy/89re/Rb9+/Tzrpk+fjuTkZOzduxdXX301UlJScNtttwEANmzYgKlTpyIvLw+JiYno168ffve730EQBM/xY8eORXFxMQBgxIgRkMlkmD59uufc7fVnlCQJc+bMQUJCAlatWtXJV8Dbjz/+iOnTp2PQoEFQqVTIzs7GjBkzUF1d7bXf448/DplMht27d+PWW2+FTqfD6NGjAbhu43n88ceRk5ODpKQkjBs3Drt378aAAQM8zxMATpw4gT/84Q84++yzkZycDI1GgwkTJuCHH37o1HPIzs4GAK9vZgFgz549uPHGG5GWlgaVSoXzzz8fn3zyidc+7tvlvv32W9xzzz3o06cPcnNzAQAHDx7EPffcA4PBALVajfT0dEydOhUHDhzwOofdbsfChQtRUFAAlUqF9PR0jB49Gl9//XXQz6G5uRk333wz/vWvf2Hx4sWYPXu2Z5v7tW/NHXvLeP71r39h4sSJyMnJQWJiIgYPHownn3wSDoej3Rha9lV7/PHHcf/99wMABg4c6Lkdz32t5cuX47LLLkOfPn2QmJiIIUOGYPHixW3OuXXrVhQVFSEjIwNqtRoDBw7s0Df2t9xyC/75z396VYB8+umnaGhowLRp03wec+TIEcyYMQNZWVlITEzEWWed5fMWO5PJhClTpqB3797o06cPfve736GxsbHNfq3/Rn31WQVO34q9YsUKr2OTk5Nx6NAhTJo0CcnJyejbty9effVVAMBPP/2Eyy67DL1790b//v3xj3/8I+jXhqin43jtjeM1x2s3jtccr4l6Co713jjWc6x36y5j/f79+yFJEkaNGuUzxj59+nged+S1cbdM+fe//+2Ze2DIkCE+/6Zqampw3333oV+/fkhMTER+fj7+9Kc/eb3naNkW7aWXXsLgwYORmJiI3bt3B3x+1LVYeR7D1qxZg/z8fFx44YUdOq65uRlFRUUYPXo0XnjhBSQlJQEAPvjgAzQ0NODuu+9Geno6vv/+e/ztb3+DyWTCBx98AAB46KGHYDAYsHTpUjzxxBMYOHAgBg8eHNR1HQ4HZsyYgX/+85+e6p32iKKIqqqqNuvr6urarPv666+xb98+3HnnncjOzsauXbuwdOlS7Nq1C1u2bGnzj9/UqVNRUFCAZ555BpIkAQAWLFiA5557DpMnT0ZRURF++OEHFBUVtblFd9++ffj4448xdepUDBw4EBaLBUuWLMGYMWOwe/du5OTktPvc7Ha757mJoogdO3bgL3/5Cy699FIMHDjQs9+uXbswatQo9O3bF3/84x/Ru3dvvP/++5gyZQo++ugjXHfddV7nveeee5CZmYlHH30U9fX1AFy3823atAk333wzcnNzceDAASxevBhjx47F7t27Pf8PPP7441i0aBFmzZqFCy64ADabDVu3bsX27dtxxRVXtPucmpubccstt2D16tV49dVXMXfu3HaP8WfFihVITk7G/PnzkZycjG+++QaPPvoobDYbnn/++aDPc/311+OXX37Bu+++ixdffBEZGRkAgMzMTADA4sWLcdZZZ+Gaa65Br1698Omnn+Kee+6B0+nEvHnzALgqOq688kpkZmbij3/8I1JTU3HgwIEOvcm89dZb8fjjj2PdunW47LLLAAD/+Mc/MH78eK+B2s1isWDkyJGe/oKZmZn44osvMHPmTNhsNtx3330AXLfBjR8/HocOHcJvf/tb5OTk4O2338Y333wTdGzBcjgcmDBhAi699FI899xzeOedd/DrX/8avXv3xkMPPYTbbrsN119/PV5//XXccccduOiii7z+XyaKVxyvvXG8duF47Y3jdfhwvCaKPI713jjWu3Cs9xbNsd7dLumDDz7A1KlTPa9zOJSXl+Omm27CXXfdheLiYixfvhxTp07Fl19+6fldNTQ0YMyYMThy5Ajmzp2LvLw8bNq0CQsWLIDZbMZLL73kdc7ly5dDFEXMmTMHiYmJSEtLC1u8FAKJYpLVapUASFOmTGmz7eTJk1JlZaXnp6GhwbOtuLhYAiD98Y9/bHNcy/3cFi1aJMlkMungwYOedcuXL5cASKWlpV77FhcXS/379/c83r9/vwRAev755yW73S7ddNNNklqtlr766qugniOAdn9axuAr/nfffVcCIK1fv96z7rHHHpMASLfccovXvseOHZN69erV5jV9/PHHJQBScXGxZ50oipLD4fDab//+/VJiYqL0xBNPtPvc+vfv7/P5jBo1SqqqqvLad/z48dLZZ58tiaLoWed0OqWLL75YKigo8Kxz/15Gjx4tNTc3e53D12uzefNmCYD01ltvedYNHTpUmjhxYrvxt7Z27VoJgOd5vfrqqz73c7/2rblj379/f8CY586dKyUlJXm9Fq3/v5Mk1/87jz32mOfx888/3+b8ga5TVFQkDRo0yPN49erVPv+fD8aYMWOks846S5IkSTr//POlmTNnSpLk+jtNSEiQVq5c6Xn9PvjgA89xM2fOlPR6fZv/H26++WZJq9V64n7ppZckANL777/v2ae+vl7Kz8+XAEhr1671rG/9Wrmv23IfSTr9t7t8+XKvYwFIzzzzjGfdyZMnJbVaLclkMum9997zrN+zZ0+b34E/AKR58+a1ux9RrOJ4zfGa47ULx+ueNV63/HeDKN5xrOdYz7HepbuP9XfccYcEQNLpdNJ1110nvfDCC1JZWVmb/Try2rhf548++sizzmq1Snq9Xho+fLhn3ZNPPin17t1b+uWXX7zO+cc//lFSKBTSoUOHJEk6/beq0Wik48ePB/W8+vfvH9L/KxQ8tm2JUTabDQCQnJzcZtvYsWORmZnp+XHfptnS3Xff3WadWq32LNfX16OqqgoXX3wxJEnCjh07Qo61qakJU6dOxZo1a/D555/jyiuvDPrYa6+9Fl9//XWbH/etPv7id38r7p7wYfv27W32v+uuu7we//e//0VzczPuuecer/W/+c1v2hybmJjo6VfncDhQXV2N5ORkGAwGn9fy5cILL/Q8nzVr1uDpp5/Grl27cM0113huxztx4gS++eYbTJs2DbW1taiqqkJVVRWqq6tRVFSE8vJyHDlyxOu8s2fPhkKh8Pva2O12VFdXIz8/H6mpqV7xpqamYteuXSgvLw/qObRmsVjQq1evsFQvtYzZ/dwvueQSNDQ0YM+ePZ0+v6/rWK1WVFVVYcyYMdi3bx+sViuA0z0E16xZA7vdHvK1br31VqxatQpNTU348MMPoVAo2lQnAK5bKD/66CNMnjwZkiR5fu9VVVUoKiqC1Wr1/N4+//xz6PV63HjjjZ7jk5KSMGfOnJDjDGTWrFme5dTUVBgMBvTu3dvrVnaDwYDU1FTs27evS2IgiiUcrzlec7wOD47XHcPxmihyONZzrOdYHx5dPdYvX74cr7zyCgYOHIjVq1fjD3/4AwoLCzF+/Pg2v7uOyMnJ8XqfoNFocMcdd2DHjh04duwYAFfF+yWXXAKdTuf1fuHyyy+Hw+HA+vXrvc55ww03eCryKfrYtiVGpaSkAPB9i9SSJUtQW1sLi8XiNemFW69evTz9tlo6dOgQHn30UXzyySc4efKk1zb3P1ShWLRoEerq6vDFF19g7NixHTo2NzfXa9ZwN5PJ1GbdiRMnsHDhQrz33nueiVPcfMXfehA5ePAgACA/P99rfVpaGnQ6ndc6p9OJl19+Ga+99hr279/v1esrPT29nWflkpGR4fXcJk6cCIPBgBtvvBFvvPEGfvOb36CiogKSJOGRRx7BI4884vM8x48fR9++ff0+L8B1q/CiRYuwfPlyHDlyxHMrHOD92jzxxBO49tprccYZZ+D//u//cNVVV+H222/HOeecE9Rzeu655/DSSy/hxhtvxL///W+f/cSCtWvXLjz88MP45ptvPG9IfcXcWRs3bsRjjz2GzZs3o6Ghoc11tFotxowZgxtuuAELFy7Eiy++iLFjx2LKlCm49dZbkZiYGPS1br75ZvzhD3/AF198gXfeeQeTJk3y/C23VFlZiZqaGixdurTNZCZu7v/HDx48iPz8/Da3PhoMhqDjCpZKpWozgGu1WuTm5ra5vlarbfPvCFE84njN8dqN43XncLwOHsdrosjiWM+x3o1jfed09Vgvl8sxb948zJs3D9XV1di4cSNef/11fPHFF7j55puxYcOGkOL2Nb6fccYZAFw9zLOzs1FeXo4ff/zRb0K89d8J26l1L0yexyitVgu9Xo+ff/65zTZ3n7XWE064tfxm1s3hcOCKK67AiRMn8OCDD+LMM89E7969ceTIEUyfPt1rAoOOKioqwpdffonnnnsOY8eO7bLZlqdNm4ZNmzbh/vvvx7Bhw5CcnAyn04mrrrrKZ/wtv9XsqGeeeQaPPPIIZsyYgSeffBJpaWmQy+W47777OvVajR8/HgCwfv16/OY3v/Gc6w9/+AOKiop8HtP6DYWv5/Wb3/wGy5cvx3333YeLLroIWq0WMpkMN998s1e8l156Kfbu3Yt//etf+Pe//4033ngDL774Il5//XWvCiZ/9Ho9vv76a4wePRoTJ07Et99+i6FDh3q2+5p0A0CbiUZqamowZswYaDQaPPHEExg8eDBUKhW2b9+OBx98sFOvcUt79+7F+PHjceaZZ+Ivf/kL+vXrh4SEBHz++ed48cUXPdeRyWT48MMPsWXLFnz66af46quvMGPGDPz5z3/Gli1bfFaZ+KLX6zF27Fj8+c9/xsaNG/HRRx/53M993V/96leeSYBaC/ZNUyDB/j7cWldNtLe+5RtBonjF8botjtcuHK+Dx/Ga4zVRd8axvi2O9S4c64MX6bE+PT0d11xzDa655hqMHTsW3377LQ4ePIj+/ft3eNwNhtPpxBVXXIEHHnjA53Z3st2tM38TFH5MnsewiRMn4o033sD333+PCy64oFPn+umnn/DLL79g5cqVuOOOOzzrOzKTsz8jR47EXXfdhUmTJmHq1KlYvXp1mxmrO+vkyZP473//i4ULF+LRRx/1rO/ILU7uCSQqKiq8vuWrrq5u823/hx9+iHHjxqGkpMRrfU1NjWfSi1A0NzcDOF21MGjQIACAUqn0+S1/sD788EMUFxfjz3/+s2edKIqoqalps29aWhruvPNO3Hnnnairq8Oll16Kxx9/PKgB2h3zV199hTFjxqCoqAgbNmxAQUEBAHiqBGpqajy3WwGnKwvc1q1bh+rqaqxatQqXXnqpZ/3+/fuDfcpe/A1+n376KRobG/HJJ58gLy/Ps37t2rU+9x85ciRGjhyJp59+Gv/4xz9w22234b333gv6tQFct4LPmjULqampuPrqq33uk5mZiZSUFDgcjnZ/7/3798fPP/8MSZK8nqfRaGw3lpa/j5Za/z6IqHM4Xp/G8Towjtccr33heE3U/XGsP41jfWAc67vPWO92/vnn49tvv4XZbEb//v2Dfm3c3HcltHxuv/zyCwBgwIABAIDBgwejrq6uU//vUPSw53kMe+CBB5CUlIQZM2bAYrG02d6RKhJ3JUrLYyRJwssvv9z5QAFcfvnleO+99/Dll1/i9ttvD9u3k26+4gfQZsbiQMaPH49evXph8eLFXutfeeUVn9drfa0PPvigU32yANeAAcDzjXCfPn0wduxYLFmyBGazuc3+lZWVQZ3XV7x/+9vf2nxzWl1d7fU4OTkZ+fn5aGxsDPo5AMDZZ5+Nzz77DHV1dbjiiis8r4t79veW/bzq6+uxcuXKNvEC3r/PpqYmvPbaax2Kw613794A2n7o9HUdq9WK5cuXe+138uTJNq/fsGHDAKDDr82NN96Ixx57DK+99hoSEhJ87qNQKHDDDTfgo48+8lnB0vL3fvXVV+Po0aP48MMPPesaGhr83j7eUv/+/aFQKNr0Vwv1dSYi3zhen8bxOjCO1xyvfeF4TdT9caw/jWN9YBzrozPWHzt2DLt3726zvqmpCf/9738hl8s9dw4E+9q4HT16FKtXr/Y8ttlseOuttzBs2DBkZ2cDcN2NsXnzZnz11Vdtjq+pqfF8WUPdEyvPY1hBQQH+8Y9/4JZbboHBYMBtt92GoUOHQpIk7N+/H//4xz8gl8t99lBr7cwzz8TgwYPxhz/8AUeOHIFGo8FHH30U1h6IU6ZMwfLly3HHHXdAo9FgyZIlYTu3RqPBpZdeiueeew52ux19+/bFv//97w59G5qVlYV7770Xf/7zn3HNNdfgqquuwg8//IAvvvgCGRkZXt8iTpo0CU888QTuvPNOXHzxxfjpp5/wzjvveL6NDsaRI0fw97//HYDrH+wffvgBS5YsQUZGhtdEKK+++ipGjx6Ns88+G7Nnz8agQYNgsViwefNmmEwm/PDDD+1ea9KkSXj77beh1WoxZMgQbN68Gf/5z3/a9IAbMmQIxo4di/POOw9paWnYunUrPvzwQ/z6178O+nm5XXTRRVi1ahUmT56MK664Ahs2bMCVV16JvLw8zJw5E/fffz8UCgXefPNNZGZm4tChQ55jL774Yuh0OhQXF+O3v/0tZDIZ3n777ZBvKz7vvPMAAA899BBuvvlmKJVKTJ48GVdeeSUSEhIwefJkzJ07F3V1dVi2bBn69Onj9YZo5cqVeO2113Dddddh8ODBqK2txbJly6DRaPxWo/mj1Wrx+OOPt7vfs88+i7Vr1+LCCy/E7NmzMWTIEJw4cQLbt2/Hf/7zH5w4cQKAaxKaV155BXfccQe2bdsGvV6Pt99+G0lJSUHFMnXqVPztb3+DTCbD4MGDsWbNmjb91oioczhen8bxOjCO1xyv/cXC8Zqoe+NYfxrH+sA41kdnrDeZTLjgggtw2WWXYfz48cjOzsbx48fx7rvv4ocffsB9993nuVMh2NfG7YwzzsDMmTNRWlqKrKwsvPnmm7BYLF6J//vvvx+ffPIJJk2ahOnTp+O8885DfX09fvrpJ3z44Yc4cOBAp+6UoC4mUcyrqKiQ7r77bik/P19SqVSSWq2WzjzzTOmuu+6Sdu7c6bVvcXGx1Lt3b5/n2b17t3T55ZdLycnJUkZGhjR79mzphx9+kABIy5cv9+y3fPlyCYBUWlra5tz9+/f3PN6/f78EQHr++ee99nvttdckANIf/vCHgM8LgDRv3jyf23zFYDKZpOuuu05KTU2VtFqtNHXqVOno0aMSAOmxxx7z7PfYY49JAKTKyso2521ubpYeeeQRKTs7W1Kr1dJll10mlZWVSenp6dJdd93l2U8URen3v/+9pNfrJbVaLY0aNUravHmzNGbMGGnMmDEBn5ckSVL//v0lAJ4fuVwu9enTR7rlllukioqKNvvv3btXuuOOO6Ts7GxJqVRKffv2lSZNmiR9+OGHAV8Tt5MnT0p33nmnlJGRISUnJ0tFRUXSnj17pP79+0vFxcWe/Z566inpggsukFJTUz3/Hz399NNSU1NTwOezdu1aCYD0wQcftNn2z3/+U5LL5dKIESMkm80mbdu2TbrwwgulhIQEKS8vT/rLX/7iiX3//v2e4zZu3CiNHDlSUqvVUk5OjvTAAw9IX331lQRAWrt2rWe/1v/fSZLU5ncuSZL05JNPSn379pXkcrnXtT755BPpnHPOkVQqlTRgwADpT3/6k/Tmm2967bN9+3bplltukfLy8qTExESpT58+0qRJk6StW7cGfF0kSZLGjBkjnXXWWSG9fhaLRZo3b57Ur18/SalUStnZ2dL48eOlpUuXeu138OBB6ZprrpGSkpKkjIwM6d5775W+/PLLoF6ryspK6YYbbpCSkpIknU4nzZ07V/r555/b/N37+7fD3/Pr37+/NHHixIDPW5IC/50T9TQcr104XnO8duN4Hbvjtb9/N4jiHcd6F471HOvdustYb7PZpJdfflkqKiqScnNzJaVSKaWkpEgXXXSRtGzZMsnpdHrtH+xr4x5Hv/rqK+mcc86REhMTpTPPPNPn619bWystWLBAys/PlxISEqSMjAzp4osvll544QXP7zWU8TXYsZxCJ5MkzhBDFEhNTQ10Oh2eeuopPPTQQ9EOh4iIiHzgeE1ERNSzcayn7mbAgAH4v//7P6xZsybaoVAXYs9zohYEQWizzt2bbezYsZENhoiIiHzieE1ERNSzcawnou6CPc+JWvjnP/+JFStW4Oqrr0ZycjL+97//4d1338WVV16JUaNGRTs8IiIiAsdrIiKino5jPRF1F0yeE7VwzjnnoFevXnjuuedgs9k8E5U89dRT0Q6NiIiITuF4TURE1LNxrCei7oI9z4mIiIiIiIiIiIiIWmHPcyIiIiIiIiIiIiKiVpg8JyIiIiIiIiIiIiJqpcf3PHc6nTh69ChSUlIgk8miHQ4REcUJSZJQW1uLnJwcyOX8rrojOHYTEVE0cOwOHcduIiKKhkiM3T0+eX706FH069cv2mEQEVGcOnz4MHJzc6MdRkzh2E1ERNHEsbvjOHYTEVE0deXY3eOT5ykpKQBcL6JGo4lyNEREFC9sNhv69evnGYcoeBy7iYgoGjh2h45jNxERRUMkxu4enzx33zKm0Wg4iBMRUcT1tFuX169fj+effx7btm2D2WzG6tWrMWXKFACA3W7Hww8/jM8//xz79u2DVqvF5ZdfjmeffRY5OTlBX4NjNxERRVNPG7sjgWM3ERFFU1eO3WzkRkREREGrr6/H0KFD8eqrr7bZ1tDQgO3bt+ORRx7B9u3bsWrVKhiNRlxzzTVRiJSIiIiIiIioc3p85TkRERGFz4QJEzBhwgSf27RaLb7++muvda+88gouuOACHDp0CHl5eT6Pa2xsRGNjo+exzWYLX8BEREREREREIWLlOREREXUZq9UKmUyG1NRUv/ssWrQIWq3W88MJx4iIiIiIiKg7YPKciIiIuoQoinjwwQdxyy23BOx/umDBAlitVs/P4cOHIxglERERERERkW9MnhMREVHY2e12TJs2DZIkYfHixQH3TUxM9EwwxonGiIiIwmv9+vWYPHkycnJyIJPJ8PHHH3ttl8lkPn+ef/756ARMRETUjTB5TkTUCaJowsmTayGKpmiHQtRtuBPnBw8exNdff81kOBF1K6JJxMm1JyGaxGiHQhQRgSb7BgCz2ez18+abb0Imk+GGG26IcKRERBSsUqsVfzl8GGsqK7H25EmYRL6v6SqcMJSIKERmcwmMxjkAnADkMBiWQq+fGe2wiKLKnTgvLy/H2rVrkZ6eHu2QiIg8zCVmGOcY3UM3DEsN0M/URzssoi4VaLJvAMjOzvZ6/K9//Qvjxo3DoEGDujo0IiIKwfSyMqy0WLzWyQEsNRgwU8/3NeHG5DkRUQhE0dQicQ4AThiNc6HTFUGlyo1maERdqq6uDhUVFZ7H+/fvx86dO5GWlga9Xo8bb7wR27dvx5o1a+BwOHDs2DEAQFpaGhISEqIVNhERRJN4OnEOAE7AONcIXZEOqlxVVGMj6i4sFgs+++wzrFy5MuB+jY2NaGxs9Dy22WxdHRoREcFVcd46cQ643t7MNRpRpNMhV8X3NeHEti1ERCEQhHKc/vTt5oAgVPjanajH2Lp1K4YPH47hw4cDAObPn4/hw4fj0UcfxZEjR/DJJ5/AZDJh2LBh0Ov1np9NmzZFOXIiindCueBr6IZQIUQlHqLuaOXKlUhJScH1118fcL9FixZBq9V6fvr16xehCImI4lep1YqnDh3yu90BoELg+5pwY+U5EVEI1OoCuL5/bPkpXAG1Oj9KERFFxtixYyFJkt/tgbYREUWTukDta+iGOl8drZCIup0333wTt912G1TtVC0uWLAA8+fP9zy22WxMoBMRdSFfrVp86S1nnXS48RUlIgqBSpWLnJy5LdbIYTAsYcsWIiKibkqVq0LO3TmnV8gBwxIDW7YQnbJhwwYYjUbMmjWr3X0TExOh0Wi8foiIqGv4a9XiS72z9W121FmsPCciCpGr+tzlnHO+QFralVGMhoiIiNqTdGaSZ/mcL89B2hVpUYyGqHspKSnBeeedh6FDh0Y7FCIiamFDkPNKKADkq3lHXbix8pyIKESNjad7jfXqpY1iJERERBSMxsOnJzjslco6IooPdXV12LlzJ3bu3Ang9GTfh1r0zbXZbPjggw+CqjonIqLIuiTIu3uuz8jA+5WVKLVauzii+MJ3jEREIRLF0x84nE4xipEQERFRMFomz50ib2um+LB161aMGzfO89jdq7y4uBgrVqwAALz33nuQJAm33HJLNEIkIqIARmi1GJKUhN0NDQH3+6CqCh9UVQEAbszIwAf/93+RCK/HY+U5EVGIWlaeM3lORETU/TWaWiTPG5k8p/jgnuy79Y87cQ4Ac+bMQUNDA7Ra3k1JRNTdmEQRZT4S57dnZvo95sOqKjy8b19XhhU3mDwnIgoRK8+JiIhiCyvPiYiIKNaUCwIkH+ut7UwO+syhQzCJzFV0FpPnREQhaGgoh91+3POYyXMiIqLuTTwkQjx0erxm8pyIiIhiQYFaDVmrdQoA16WnBzxOAlAhCF0VVtxg8pyIqIPM5hJ8/73Ba92JE19FKRoiIiJqj7nEjC0DtgAt8uUnvzoZvYCIiIiIgpSrUuEstdrzWAFgicGA6Tk5uDjAZKIKAPktjqPQMHlORNQBomiC0TgbaHXT1LFjy2G1lkYnKCIiIvJLNIkwzja2HrphLjFDNPHOMSIiIureisvK8HOLCvLrMjIwU68HAGw891x8etZZGNdqzgo5XAn2XJUqkqH2SEyeExF1gCCUo82n71N27LgQZnNJZAMiIiKigIRywffQLQHWzdaIx0NEREQUrFKrFW9ZLF7rPqyqQqn19HuYSZmZ+Gb4cOy/8ELPup3nn+9JsFPnMHlORNQBanUB0KbbmJsEo3EuRNEUyZCIiIgoAHWB2u/QXXZTGcwl5sgGRERERBSkDTabz/UbfawfoFZDKXO96dH16tWlccUTvpJERB2gUuVi0KDnsG/f/X72cEAQKqBS5UY0LgqNKJpQVfUpGhqMkMsTYbdXQaFIQVbWbdBqR0Q7PCIiCgNVrgqGZQYYZxnbbpQA41wjdEU6qHJ5WzMRERF1L5f46Wk+ys96tVwOu8OBBicnRg8XJs+JiDrAbC4JkDgHAAXU6vyIxUOhM5tLYDTO8rnt6NGXkZVVjMLCFZENioiIuoSuSOeaNcvhY6MDECoEJs+JiIio2xmh1eIijQabW1SaF2dlYUSrHuduarkcNocDApPnYcO2LUREQXJNFuo72eoih8GwhFXnMaD93yVgsazkJLBERD2AucSMLf22+E6cA4ACUOerIxoTERERUbBuzMwEAJzbuze+Hz4cKwoL/e6bpFAAAASHvzc+1FFMnhMRBck1Wah/5523A3r9zAhFQ53R3u/SzWbb2MWREBFRVxJNou92LW5ywLDEwKpzIiIi6rZszc0AgAu1Wr8V525quSvVy8rz8GHbFiKiILkmC/WvV6/kCEVCndXe79JNoxnVxZEQEVFXEsqFgNvP23YeUoalRCgaIiIioo6znaoi15yqKg/EvcfOujoAQIFajVwViwQ6I6rJ8/Xr1+P555/Htm3bYDabsXr1akyZMgUAYLfb8fDDD+Pzzz/Hvn37oNVqcfnll+PZZ59FTk5ONMMmojjlmiz0eR89zxMBNOLw4b/A4XB9SFcqMyCXJyI9fbLXxJOiaIIglEOtLgipvYsommC1boIgVEAQ9nquZbdX+V1WKFKg012OxsbDaGgwwulsgt1u8fRmF4QKr2WlMguS1BjUud3LongQkmSHRjMKgrALdnuN13JS0lkQhF1QKHRIShqC2tqNXstAAlSqPJ+vWVdQqXJhMLwRsHVLVlYxJw0lIopx6oLA7Vh6pbCWiIiIiLo3d+W5plfg9y0lZjN+amgAAMzf68oXyAEsNRgwU6/v0hh7sqi+W6yvr8fQoUMxY8YMXH/99V7bGhoasH37djzyyCMYOnQoTp48iXvvvRfXXHMNtm7dGqWIiSjepadPOJU8T0Je3v0AmnHo0NMAgKNHX22z/6FDT3omnnRNUDkHgBOu/uhLO9TmxXX8bABSh+M+evTlDh8TiurqVe0ut6fla9aV9PqZOHz4JTQ0/Iy0tClISjLAbq+GQpGCrKxbmDgnIuoBVLkq5D2Uh0NPH/Le4PreG4dePASn4LqtWZmhhDxRjvTJ6dCOCHxLdEeIJhHWTVYIFQKEvYLnWvYqu99lRYoCust1aDzciAZjA5xNTtgtdk9vdqFC8FpWZikhNUpBndu9LB4UIdklaEZpIOwSYK+xey0nnZUEYZcAhU6BpCFJqN1Y67WMBECVp+qS14yIiIhOC6by3CSKmGNs26rOCWCu0YginY4V6CGKavJ8woQJmDBhgs9tWq0WX3/9tde6V155BRdccAEOHTqEvLw8n8c1NjaisbHR89jWYjZaIqLOam62AgBUqmzk5MzCli2+/y1qyWJZiYyMG1skzgHACaNxLnS6oqAq0F0TXIaWOI9FFstK5OTMi0AC2/X76Nfvt9DpxnXxtYiIKBo0IzUAgITcBGTPzAaa4Ummm181t9n/0JOHkFWchcIV/ifjCpa5xAzjbGNIw/fRl492+vrBqF5V3e5ye8L5mhEREZG3WnfyPEDlebkgwF+XcweACkFg8jxEMXWfotVqhUwmQ2pqqt99Fi1ahIULF0YuKCKKK83NNQCAXr20pyadDO7TsKtavfVQ5oDROBtyeVK7LU5c7WDiI3HuZrNt7PLkudMpAgDkcr6JICLqqezHXdXWyWcnI2dWDrbkbWn3GMtKC3Lm5XSqmlo0iSEnzmNROF4zIiIiasvTtiVA5XmBWg052mYdAFcf9Hx14FZ25F/MJM9FUcSDDz6IW265BRqNxu9+CxYswPz58z2PbTYb+vXrF4kQiSgOuCvPe/XSnpp0UoZgPhULwh6f60+e/BJA6C1OerJITNbJ5DkRUc/XZGkCACRkJbgmEA0ymV3xmwoknZUE9WA1mq3NaDI3ofew3kG3OHEIjrhJnLvZNtqYPCciIgozWxCV57kqFZYaDJhrNMLRatuiQYNYdd4JMZE8t9vtmDZtGiRJwuLFiwPum5iYiMTExAhFRkTxxp08Vyi0pyadXBZX7VQiJVKTdTJ5TkTU87mT58ospWsC0eC+90btd7Wo/a7We+XbpxdDbXHSk2lG+S9yIiIiotAEU3kOADP1ehTpdLh1925saNHG+sF9+5CmVHLS0BB1++S5O3F+8OBBfPPNNwGrzomIuprDcbryHHBNOqnTFcFq3QxBqIAg7EN9/U+oq/suIvGkpl6N5OSzYbe7PrQrleltlhWKFOh0l6Gx0YSGhl/gdIqw2yuhVg8GAAjCXq9lpTITkmT3ez5fy6J4CJJkh0ZzEQShDHZ7jddyUlIhBKEMCkUqkpIKUVu72WsZUKKurhSiWIHc3AeRn/9sRF4/Js+JiHo+u8U1piVkJUCVq4JhmSGu2qlESlZxFqvOiYiIukAwledu5sZGr8Q54HrLM4eThoasWyfP3Ynz8vJyrF27Funp6dEOiYjiXMu2LW4qVS5Uqqmex1ZrKXbsuCAC0chx5plLgppwNBbs2jUNolgRsecjSRKT50REcaBl2xYA0M/UQ1ekg3WzFUKFAGGfgPqf6lH3XV1E4km9OhXJZyfDXn3qi+p0ZZtlRYoCust0aDQ1ouGXBjhFJ+yVdqgHu/qVCnsFr2VlphKSXfJ7Pl/L4iERkl2C5iINhLJTrWhaLCcVJkEoE6BIVSCpMAm1m2u9lqEE6krrIFaIyH0wF/nP5kfk9SMiIoonkiR5Ks9T2qk8B9Amce7mBCcNDVVUk+d1dXWoqKjwPN6/fz927tyJtLQ06PV63Hjjjdi+fTvWrFkDh8OBY8eOAQDS0tKQkJAQrbCJKI75Sp63ptWOQFZWMSyWlV0ai8GwtMckzgFAJnO/EWjdoa3zrNZSHD/+Dpqba6FUZsBur4Lr7YNrOhW7vRqJibyFjYioJ2qdPAcAVa4KqqmnPzxaS63YccGOrg9GDpy55EyocnvGB9ddU3dBrBCh7sdJyIiIiLpCg9PpmQQ0mMrzS/x07JCDk4aGKqrJ861bt2LcuHGex+6JPouLi/H444/jk08+AQAMGzbM67i1a9di7NixkQqTiMijZc/zQAoLVyAnZx5OnPgMDofoaXGiVg9Cc7MVTU3H0Lv3OR1ucdLQ8CPUagOys2/vUYlzF1fyXJLCmzwvK5ve7hcZW7eeA4NhGfT6mWG9NhERRV/Lnuf+aEdokVWcBctKS5fGYlhq6DGJcwDuoRuSgz1wiIiIuoK76lwOIEkub3f/EVotirOysNJy+j2NDMBSg4FV5yGKavJ87NixkCT/b7QCbSMiiobWPc8D0WpHRGTSy55CJnMNSZLUHLZzWq2lQd4BIMFonAudrqgHfilBRBSfRJMI85tmNFe7xpX2EryFKwqRMy8HJz47AYfogL3aDnu1HSdWnwAAJA5IRM5vcjrc4qThxwaoDWpk357dsxLnAGQKGQAmz4mIiLpKy37nMpksqGNWFBbi7pwcjNzhuqtu23nnYXhKSpfF2NN1657nRETdTTBtWyg07rYt4aw8t9k2dGBvBwQhcj3XiYio65hLzDDOMnqt2zZsGwxvGKCf6b9Nl3aE1mvSy/rd9Z7kuW6sDv3n9++agGOUJ3nezOQ5ERFRV3BXnmuC6Hfe0oVaLZIVCtQ5HEH1Sif/2q/3JyIiDybPu05XJM81mks6sLcCajUnOyMiinWiSWyTOHczzjFCNIlBn0vWS+ZzmVzcrwkrz7u39evXY/LkycjJyYFMJsPHH3/cZp+ysjJcc8010Gq16N27N0aMGIFDhw5FPlgiIvLSsvK8o9xtXioEIawxxRsmz4mIOiDYnufUcV3RtkWrHYHevc8OYk85DIYlrDonIuoBhPIAHxCdgFAR/AdIr+S5ksnz1tyV510w1zeFUX19PYYOHYpXX33V5/a9e/di9OjROPPMM7Fu3Tr8+OOPeOSRR6Bib1wioqgLtfK8xGzGcbsdADDxp59QYjaHPbZ4wbYtREQd0JGe59Qx7srzUD6BV1auQVXV+1AqXbfiC0KFp4pcFI8AADSa0VCrz4RSme41gatanQ+t9iImzomIegh1gdr/Rjmgzg+wvZWWCXNWnvvACUNjwoQJEzBhwgS/2x966CFcffXVeO655zzrBg8eHPCcjY2NaGxs9Dy22WydD5SIiNpwV57bJQkmUQxq0k+TKGKO8fRdeE4Ac41GFOl0nDQ0BEyeExEFSZIkNDe7PhgweR5+pyvPO5Y83779Ythsm9vdz2b7H/T66dDrZ4YUHxERxQZVrgpnLD0Dv8z5pc02w1JDhybtZNuWwDhhaOxzOp347LPP8MADD6CoqAg7duzAwIEDsWDBAkyZMsXvcYsWLcLChQsjFygRUZz66oRr7pXS2lr037IFSw0GzNT7n78FAMoFAc5W6xxwtW9h8rzj2LaFiChINTXfAqeGIIejLrrB9EjunufBt22prFwTVOLczWicA1E0dTgyIiKKLVm3ZnmW065Nw4BnBmDk4ZEBJwv1xSt5rmDyvDVOGBr7jh8/jrq6Ojz77LO46qqr8O9//xvXXXcdrr/+enz77bd+j1uwYAGsVqvn5/DhwxGMmogoPphEEe8dP+557K4gN4mB528pUKvbJHwVAPLVwd99R6ex8pyIKAhlZdNhsaz0PP7++zNhMCxjFXMYhTJh6MmTn3fwKk4IQgVbtBAR9XAO4fRYcvZHZ4ec+PaqNmfuvA1OGBr7nE5XYci1116L3/3udwCAYcOGYdOmTXj99dcxZswYn8clJiYiMTExYnESEcWjckFA6xE2mAryXJUKSw0GzDEaPRXoSwwGVp2HiJXnRETtsFpLvRLnLhKrmMMslLYtOt3VHbyK3NMLnYiIei5ng+ujoixB1qmKcU4SGhgnDI19GRkZ6NWrF4YMGeK1vrCwEIcOHYpSVEREBLgqyFu/Ewm2gnymXo/3CgsBAP0TE9tt9UL+MXlORNQOm22Dny2uKmYKj9OV58G3bcnMnITExP5B728wLGXVORFRHHAKruS5IknRzp6Bsc95OzhhaMxLSEjAiBEjYGwxsRwA/PLLL+jfP/j3WEREFH65KhXOTU72PFagYxXko1NTAQCHGxvR6GzdBZ2CxbYtRETt0Ggu8bOFVczh5E6ed7R8rW/fu7Fv3x+RmDgImZlTAQCCsBdq9WDPckrKucjOvp2JcyKiOOFocI0lcnXnaoWYPA+ME4bGhrq6OlRUnC742L9/P3bu3Im0tDTk5eXh/vvvx0033YRLL70U48aNw5dffolPP/0U69ati17QREQEkyiittlVXDY9KwtPDhzYodYr2QkJSFYoUOdw4B8WC67Q6di6JQRMnhMRtUOrHYGMjOtRVbWqxVoZq5jDLJS2La79XW8m0tLGIz//2bDHRUREscddeS5P6mTynJOEBhSNCUNFk4iqT6vQYGyAPFEOe5UdihQFsm7LgnaENmJxxJKtW7di3Lhxnsfz588HABQXF2PFihW47rrr8Prrr2PRokX47W9/C4PBgI8++gijR4+OVshERHGvxGzGrBZ3Ba2wWCABWHGqFUswZDIZ0nv1Qp3DgRlGI+QAlhoMbOHSQUyeExEFYcCAR1FVtQoyWRIGD/4zMjImMXEedh1v29Jy/9OV60REFO/clecKdSfbtsiYPA8k0hOGmkvMMM4y+tx29OWjyCrOQuGK4JMK8WLs2LGQpMC/oxkzZmDGjBkRioiIiAIxiaJX4txtpcWCeTk5GKEN7stikyjiYGOj57ETwFyjEUWsQO8Q9jwnIgqCw9EAAEhMzEZu7l1MnHeB0CvPHV7HExERhavynAKL5IShokn0mzh3s6y0wFpq7fpgiIiIulC5IPjdttFm69R5HAAqApyf2mKmgYgoCE6nK3muUCRFOZKe6/SEoaG1bWHynIiI3JwN4Zkw1AuL0NvqxIShlWsqUfV+FZR6JQBAqBCgzld7llPOS0H2HdlQ5boq44Ty4D7o2zba2L6FiIhiWoFa7XfbKI2mQ+eRAWg5SisA5Ac4P7XFTAMRURDcledyOZPnXeV08jy0ti2eT/BERBT3HEJ4Jgz1wjkx2wh1wtDto7bDtilw5Vz1qmoceOgADG8YoJ+ph7oguA/6mlHBJxWIiIi6o1yVCrf16YN3jh/3Wl+clRV0yxb3ee7Mzsabx44BcH1iXmIwsGVLB/E+RiKiILDyvOudrhxn2xYiIuocd+U527Z0rVAmDK1cU9lu4rwl4xwjRJMIVa4KhjcMAffNKuakoUREFPtMooh3WyXOZQCeGjiww+e6NiMDAHCmWo0DI0dystAQMNNARBQEUTQBAOz2GoiiiT3PuwDbthARUbiEa8JQCiyUCUNPfn6yYxdxutq4qHJV0M/Uw/RXE+p/rEfatWlIOjMJ9mo7FCkKZN3CxDkREcWmUqsV7xw/jtrmZmQolfipvh7OVvtIcPUq72jVuK6X63NynSMCE5T0UMw0EBG1w2wuwb59fwAA1NfvxJYteTAYlkGvnxnlyHqazrVtcSffiYiIumTCUPY8byOUCUN1V+twdPHR4A+Qw9MLHYCnfU7ur3ORdnla8OchIiLqhqaXlWGlxdLufqH2Kv/mpOtLa1NTE/pv2YKlBgOrzzuI9zESEQUgiiYYjbNbrZVgNM71VKNTeLgrxzteec62LZG0fv16TJ48GTk5OZDJZPj444+9tq9atQpXXnkl0tPTIZPJsHPnzqjESUTxzdO2hT3Pu1YIE4ZmTspEYl5i0Psblho8k4YCgFM89btN5EdZIiKKbaVWa1CJcwB4dtCgDledm0QRTxw86HnsBDDXaIRJFDt0nnjHdxxERAEIQjl8f1p2QBAqIh1Oj8a2LbGhvr4eQ4cOxauvvup3++jRo/GnP/0pwpEREZ3mnjBUkRS+u5Kaazt2Z1Q8CHXC0Jw5OQAAVb4KuQ/mIvfBXKTfmO5Zlqlc5z1r9VnQz/SujnM2nkqeq/hRloiIYtsGW/BzgJyfktLh85cLQpv2Lw642r9Q8JhpICIKQK0ugOs+7dYfChVQq/OjEFHPdbrynG1burMJEyZgwoQJfrfffvvtAIADBw5EKCIiorbCNWGoucR8enmJGZrzNW2SufEslAlDAcBpd/1+0q5IQ/6zbd9P1W6shfV/VkhNbc/rqTxn8pyIiGLcJRpNUPvJEVrLlgK1GnLAK4EeavuXeMZ3HEREAahUuRg48JlWa+UwGJZw0tAwO5387uhEJmzbEusaGxths9m8foiIOsPd87wzE4aKJhHGOcbTKyTAONcI0cRbnd1CmTAUACS7a3+Z0ncj+cR+rrYujYcb22xj2xYiIuopRmi1uEqnC7iPDMBSg6HDLVsAIFelwlKDwfNYAWBJiOeKZ8w0EBG1IzV1DACgV68MFBS8Bq32IibOu4A7eS4Ie1FR8SDs9ioAQErK+cjImOz3NWfblti3aNEiLFy4MNphEFEP4mhwfbHamcpzoVyAr3udhQrBqwd3PAtlwlDgdKW6O/neWmKuK3kuHm77RQXbthARUU8yNycHX548iSylEpPT0pCuVKLabgcAnJeSgkkZGZ1Kds/U6zG/ogI2hwP/HTYMY1JTwxR5/GCmgYioHU1NxwAASUn5yMqaGuVoei6TydVDu7HxMEym5zzrLZY3UVFxDwyGN6DXz2xzHNu2xL4FCxZg/vz5nsc2mw39+vWLYkREFOvcleedmTBUXaCGr3ud1fm81dkjhAlDgdArzyVJgtToOpbJcyIi6glONLs+z56XkoJlhYVdco0UhQI2hwMpCn5mDgWT50RE7XAnzxMSsqMcSc9ltZbCal0bcB+jcQ50uqI2FejuCUZZeR67EhMTkZiYGO0wiKgHcVeed2bCUFWuCoalBhjnGl2V1QrAsMTAqvMW3JXnwl4BFQ9WwF7lqpRLOT8FGZMz/L5W7uS5XOk7Ae5Ontf8rwZlM8ugzFC6zt2iwt1eZUdCn4RwPRUiIqKoOHkqea7r1XWfZ5NOJc3rHR1tkUoAk+dERO1i8rzr2WwbgtjLCUGo8JE8Z9sWIiLy5pkwtBOV5wCgn6mHrkgHoUKAOl/NxHkrR147AgBoPNQI03Mmz3rLmxZUzKuAYZnB5wSr7glD/VWem99wTdTafLwZljctPvcp/b9Sv+cnIiKKFSdOtWhJUyq77Bq9mTzvFGYaiIjaweR519NoLgliLznU6vw2a93Jc8+949Sl6urqUFFR4Xm8f/9+7Ny5E2lpacjLy8OJEydw6NAhHD16FABgNLom28vOzkZ2Nv+GiCgyPBOGdqLy3E2Vq2LS3AdrqRXWdVb/O0iAcY4RuiJdm9fP0/PcR/LcWmrFic9OtB/AqQlcfZ2fiIgoVrjbtqR1YeW5+8wlZjPSe/XCCK22y67VE7FRHBFRO5g873pa7QhkZRUH3MdgWOpz0lC2bYmsrVu3Yvjw4Rg+fDgAYP78+Rg+fDgeffRRAMAnn3yC4cOHY+LEiQCAm2++GcOHD8frr78etZiJKP6EY8JQCsy2wdb+Tk7XBKuteXqe+5gwNKjzujl8n5+IiChWdHXleYnZjK11dQCAD6uqcMGOHZheVtYl1+qpmGkgImoHk+eRUVi4Ajk583DixGdwOETY7dWwWjdAFI3Izf2dz8lCAbZtibSxY8dCkvxPDDd9+nRMnz49cgEREfkQjglDKTDNJZr2d5L7nmA10IShQZ3XjRO4EhFRjOvKnucmUcSsU3cCt7TSYsG8nBxWoAeJ7yaJiNrR1OTqu5mQwJ6aXU2rHYGBAx9Hfv6zKCxchvT0KwAAcnmS32NOJ8/ZtoWIiFzCMWEoBaYdoUVWcVbAfQxLfU+wGmjC0GDO6zqYE7gSEVHs68rK83LB/91ZG20duNMrzrFMj4goAEmS0Nho9ixTZMlkrjcQkmT3uw/bthARUWusPI+MwhWFyJmXgxOfnYBDdMBebYd1gxWiUUTu73P9TubZ3oSh7vMef/c4mmuboUxXwl7tei+gHqSGOl8N7UVaJs6JiCjmdWXP8wK1/7uzRmk6cKdXnGOmgYgogCNH/gbANZjt2HExDIalftuHUPgFlzxn5TkREZ0mOSRITa4vvFl53vW0I7TQjjh92/cvv/4FR41HA772gSYM9XdeIiKinqgrK89zVSq8YTC0ad1SnJXFli0dwFIMIiI/RNGEiorftVjjhNE4F6JoilpM8aa95LkomtDUdBwA0NxcE6mwiIioG3MIDs8yJwyNPHcrFmeT0+8+gSYMJSIiihcOSYLV4Xrf0hU9zwFgpl6PwyNH4saMDADAZampWFFY2CXX6qn4bpKIyA9BKAfQ+oOfA4JQEY1w4pJc7kqeO51tk+dmcwm2bMlDY+N+AMCePdNhNpdEND4iIup+nA2nx257lf87l6hryBJcCXF3gtyXQBOGEhERxYuaUy1bgK5LngOuCvSbs1zziQhO/19uk29MnhMR+aFWF6DtP5MKqNX50QgnLvmrPBdFE4zG2QBafjCXeGcAERHh2IpjnuUtA7bAXGKOYjTxx50Qd7fO8SXQhKEUfuvXr8fkyZORk5MDmUyGjz/+2Gv79OnTIZPJvH6uuuqq6ARLRBRHdtfXAwBUMhksTU1deq3cxEQAgKmxsUuv0xPx3QoRkR8qVS769ft9izUKGAxLoFLlRi2meOMvee66K8DXh3LeGUBEFM9Ek4h9f9x3eoUTMM41QjSJ0QsqzsgTTrVtsfuubBNNIhrNrg/uzdZmn/tQeNXX12Po0KF49dVX/e5z1VVXwWw2e37efffdCEZIRBR/SsxmjNm5EwAgShLytmxBibnrvvB3J8/NTU1wSP6/4Ka2OGEoEVEAOt0VOHz4eahUgzBs2LdMnEeYv+S5664AGdom0HlnABFRPDPONLYdGhyAUCFAlauKSkzxxlN57qNti7nEDOPs078j4yzXsn6mPpIhxp0JEyZgwoQJAfdJTExEdnZ20OdsbGxEY4vqRZvNFnJ8RETxxiSKmG00trqPGphrNKJIp0OuKvzvWbITEqAA0CxJON7UBP2pZDq1j8lzIqIAnE7XhwKlMo2J8yjw1/NcpcpF//6P4uDBhS335p0BRERxzFpqxcl/n2y7QQ6o89WRDyhOuSvPW7dtEU2iV+LctZPrzgBdkY5fbkTZunXr0KdPH+h0Olx22WV46qmnkJ6e7nf/RYsWYeHChX63ExFFWqnVineOH0dtczMylEocFEXYJQmjNBrsEgTU2O1ey5PT09FfrUaBWt0lyepAygXBz33UQIUgdEk8CpkMmQkJONbUhG21tZjE5HnQmDwnIgpAklzJc5mMA0s0+Ks8B4C0tCIcPLgQvXploaDgb9BqL2LinIgojtk2+K58zZyaycRsBLkrz1u3bRHKBX8d13hnQJRdddVVuP766zFw4EDs3bsX/+///T9MmDABmzdvhkKh8HnMggULMH/+fM9jm82Gfv36RSpkIiIv08vKsNJi8bltVXV1wGU5gKUGA2bqI3cXVIFa7ec+aiBf3TVf+JeYzTh2qq/6NT//jGURfs6xjMlzIqIA3JXncjmT59EQKHnucLgmV0lM7IOsrKkRjYuIiLofzSUan+tzf88vViNJluB7wlB1gdpfxzXeGRBlN998s2f57LPPxjnnnIPBgwdj3bp1GD9+vM9jEhMTkciqRSLqBkqtVr+J82A40bXtUnzJVanw3KBBuH/f6Xla5ACWGAxdEoNJFDHHaPQ87uoWMT0NJwwlIgrA6XR9MyuXJ0Q5kvgUKHnudDYAAOTypIjGRERE3ZN2hBZ9buvjtS6rOAvaEdooRRSf5MpTbVta9TxX5arQ//H+rXYGDEsMrDrvZgYNGoSMjAxUVHASdiLq/jaEYc4Fd7uUSCkxm/FAi8Q5ADw7aFCXVYKXCwJaT+Md6eccy5g8JyIKgG1bostfz3MAcDhcyXOFgslzIiJyOWPxGZ7lYeuHoXBFYRSjiU+eti1NrT+mA+lXuXpo98rohcL3CzHy4EhOFtoNmUwmVFdXQ8/b+YkoBlyi8X3nWUd0ZbuU1lYcPYpZrSYLBYAF+/bBJIpdcs0CtbpNAjiSzznWRbVty/r16/H8889j27ZtMJvNWL16NaZMmeLZvmrVKrz++uvYtm0bTpw4gR07dmDYsGFRi5eI4g/btkQXK8+JiKgjpObTH0U1F3X+wzR1nKdti71tg3On4EqoJ2QkIGtqVkTjimd1dXVeVeT79+/Hzp07kZaWhrS0NCxcuBA33HADsrOzsXfvXjzwwAPIz89HUVFRFKMmIgrOCK0WQ3v3xg/19SGf4/qMDNxbUQGdQoEhSUnYWFuLBAB5KhWq7K7PohlKZcDlFIUCl+t0ONzYCGNDA5qcTljsdk+CukIQsKW2FkdP9R1vrSsnC81VqbDUYMAco9FTgT5So8HfTCbP8zg/JQWTMzLYxsWHqCbP6+vrMXToUMyYMQPXX3+9z+2jR4/GtGnTMHv27ChESETxjm1bosudPG9oqEBZ2UwolRmw26sAAKJ4AADQ2HgUomjiZKFEROSVPJcpZFGMJH6527b4qjx3NDhc+yTxBuhI2rp1K8aNG+d57J7os7i4GIsXL8aPP/6IlStXoqamBjk5Objyyivx5JNPsqc5EcWMwlPJ89EaDc5Uq5GuVOKQKMIuSbhIo0GZIKDGbvcsf37ihFcS+4OqqrDE8fLRoyEfK0fXVoLP1OvxptmMTafa3Gy02bCxRcubNy0WzKuo4ESiPkQ1eT5hwgRMmDDB7/bbb78dAHDgwIEIRURE5I1tW6LLZPorAKC5+Tgsljd97lNfvwNbtuTBYFgGvX5mJMMjIqJuxpM8lwMyGZPn0eCuPLdX2yGaRK9+5s4GV0JdkaSISmzxauzYsZCktncCuH311VcRjIaIKPyMDa67ku/Py8M1GRkB9y21WvHGsWORCKtD5ufmdmnVd6nV6kmc+yMBmMOJRNvocV/5NzY2wmazef0QEYWKbVuix2otRU3Nf4LcW4LROAeiaOrSmIiIqHtzJ89lvZg4j5aT35wEAAh7BGzpvwXmErNnm0M4VXmu7nEfQ4mIKEqckuRJnhuS2m/pGY4JRsNNDuDe3K69kzrY5+0EJxJtrce9a1m0aBG0Wq3np1+/ftEOiYhimCAcAADY7SeiG0gcstk2dPAIJwShov3diIiox5IcTJ5Hk2gSceSvR06vcALGuUaIJtcEaO7Kc7ZtISKicCi1WjF7zx40OJ2QAUgI4q6zcEwwGk5yAEsNhi6v9O7I8+ZEot563LuWBQsWwGq1en4OHz4c7ZCIKEaVlU3H8eNvAwAqK99DWdn06AYUZzSaSzp4hBxqdX6XxEJERLGBlefRJZQLQOtW5w5gz+w9KJtZBst7FgCuJLs7oU5ERBSK6WVluGDHDrxpcY0tEoDB332HErM54HEjtFoUZ0V/0uqi1FS8X1iIgyNHRqTHeEee98P793dxNLElqj3Pu0JiYiInNiGiTrNaS2GxrPRaZ7GsRE7OPGi1I6IUVXzRakcgK6u4ze/BNxkMhqWcNJSIKM4xeR5d6gI1IIMrg9FCzZc1Xo/rt9VjS94WGJYZoJ/JScmIiKhjSq1WrDyVNG8p2J7dKwoLMS8nB+8ePw5IEnITE7G5thapCgUKk5KwubYWSgB5KhWq7XYAQLpSGXA5RaHAZTodTI2N+KWhAaLTiUq7HYNPVXHvFQQMVqtxXkoKLtJqo9JTvOXzrm1uRrpSiT319fjXyZNe+620WDAvJwcjtNqIx9gd9bjkORFROPhrGWKzbWTyPIIKC1cgJ2cejh9/F83NtVAq02G3VwMAlMp0OJ1NSEo6AxkZk5g4JyIiJs+7A//zUrbZzzjHCF2RzmtSUSIiovYE6t/t7tndXnJ6hFYbl8nh1s/7L4cPt0meA8BGmy1sr49JFPFpVRWMDQ1IlMtRderLhtuysmLidxDV5HldXR0qKk73p92/fz927tyJtLQ05OXl4cSJEzh06BCOHj0KADAajQCA7OxsZGdnRyVmIooP/lqGaDSjIhwJabUj+IUFEREFxZM8VzB5Hg1CeQcnGHMCQoXA5DkREXVIoP7dcrBnd0f4ey2rTlXWd1aJ2YxZp/K5rb189CiKs7KworAwLNfqKlHteb5161YMHz4cw4cPBwDMnz8fw4cPx6OPPgoA+OSTTzB8+HBMnDgRAHDzzTdj+PDheP3116MWMxHFB612BPr0udVrXVZWMZO4RERE3Rgrz6NLXdDBZIUcUOczwUFERIGZRBGLTSbc98sveLCiAq8fPeqzGliGyEy+2ZOM0GpxY0ZGm/WLDh2CSezc/CQmUfSbOHdbabGg1Grt1HW6WlQrz8eOHQtJ8n9f3/Tp0zF9+vTIBURE1EJBwSs4fvwfAIBhwzYhNfWiKEdEREREbqJJhFAuQF2gPl257HD9h8nz6FDlqmB4wwDjrMAflAEAMsCw1MCqcyIiCihQ5bLbaI0Gt/Xpg0kZGUych+Cevn3xYVWV1zongGt++glLzjgj5NYq5UJwd6SFs0VMV2DPcyIiPySp2bOs1Y6MYiRERETUkrnEDOMco+uTndyVhNXP1LPyvBvQz9RDV6RD1ZoqNPzSAHmCHPZq163fynQlnE1OJJ2RhIxJGUycExFRQMFULgPAJpsN7w4ZwsR5iJLlvhuT7KivxwU7doTcWqUgyPY5owK04ekOmDwnIvLjdPJcAZmMH8KJiIi6A9Eknk6cA4ATMM51TTzJ5Hn3oMpVIfcuTuRNRESdE2zlcrCThJJvdU5nwO0rLRbMy8npcHV4rkqFNwyGgF+AFMfApKFMnhMR+eFOnstk/KeSiIiouxDKhdOJczeHa+JJtm0hIiLqOYKtXOYkoZ1ToFZDBsB/Y+3QW6vM1Oux8MABHG5sxE0ZGRigUqHabkeKQoFbYiBxDjB5TkTkF5PnRERE3Y+6QI02n/AUroknG3Y1AABkCibPiYiIYl0wlcucJLTzclUqLGvnde5MaxXhVGX7wwMG4P+Sk0M+T7QwI0RE5AeT50RERN2PKlcFzSgNbP+zuVYoAMMS18ST9T/UA2DlORERUU8xU6/HimPH8D+rFUWpqRiWnIxqu2sujfNSUjhJaJjM1OtRpNPhV2Vl+NZq9drmbq2yprIS71dVQa9UAnC1ynFX/FcIArKUSjRKruqGDKUSVad+TydO/bfO4YjU0wkrZoSIiPxg8pyIiKh76l3Y25M8H3lgpGfiScnBnudEREQ9jfNUQnZu3764LjMzytH0XLkqFdYNH45SqxWzjEb82NCA2/v0wYrCQozavh2bbLZOnf/iHTuwzGDATL0+TBFHhu/pVImIiMlzIiKibqplWxZ34hwAJwwlIiLqgdxtP9RypjEjYYRWi1k5OQCAWqcTK44e7XTiHHB13JtrNMIkip0+VyTx/zoiIj+YPCciIuqmFKcXnU2nZw9l8pyIiKjn8STPFYp29qRwMSQlAQC+s9lw5y+/hO28DrhavMQSZoSIiPxg8pyIiLpa5ZpKnPz8JBLzEyHsEmCvsSP7zmxkTuItyYG0rDz/5be/oJe2F+SJcsh7uWqDmDwnIiLqORpO9cpm5XnkuJPn5qamsJ5XAXj6pMcKZoSIiPxg8pyIiLrS9lHbYdvU9hbY6lXV0Fyswbkbz41CVLGh7sc6z/KxJcfa7sDCNCIioh7DPdGkrbk5ypHEj3+fOBH2c8oBLDEYYm6CV2aEiIj8YPKciIi6SuWaSp+JczfbJhsq11SyAt0H0STCus4acB9HrSNC0RAREVFXKjGbceJU0rzoxx+xNAYnnIw1JlHEnHZatdydnY1Kux2DT1WR7xUEZCqVsJ+a3DVdqUS13Q4AGKRWI1+txkVabcwlzgEmz4mIAACiaIIglEOtLoBKlQuAyXMiIuo6Jz8/2f4+X55k8tyHqk+r2t1HOCxANIlek4kSERFRbDGJIuYYjZ7HTrgmnCzS6WIyCRsrytvpSf6H3Fw8n58foWiij82CiCjumc0l2LKlP3744TJs2dIfZnMJACbPiYio6+iu1rW/z1Xt7xNvdt+xGxX3VLS7n/2wHVvytsBcYo5AVERERNQVygUBzlbrYnHCyVhTEKAnuQzAvbm5kQumG2DynIjimiiaYDTOATxDshNG41yIoonJcyIi6jKZkzKR2D/R73Z5mhzHlh9D5ZrKCEbVvVlLrTj+9vHgD5AA41wjRJPYdUERERFRlylQq9F6CvBYnHAy1uSqVHjDYGizXgZgWQz2LO8sJs+JKK4JQjng47tsQaiAJLn6czF5TkREXaHv3X0BACqDCgP/PBDZs7I9TRWdJ5yoXlWNXZN3Yfuo7VGMsvuwbfDfI94vByBUsDqN4tv69esxefJk5OTkQCaT4eOPP/a771133QWZTIaXXnopYvEREQVyRotEuQKxOeFkLJqp1+PwyJFYnJ+P3+XkYHF+Pg6NHBmX/eZDzght3boV77//Pg4dOoSmpiavbatWrep0YEREkaBWF8D1/anUYq0CanU+amu/B8DkOfUcHLuJuhep2TX26C7Rof/8/rCWWnHsjWNt9uPkoS6aSzQdP0gBqPNZnUaxKxxjd319PYYOHYoZM2bg+uuv97vf6tWrsWXLFuTk5HQqZiKicCgxmzHbaPT6pL5o0KC4TN5GS65KhbvirEWLLyFVnr/33nu4+OKLUVZWhtWrV8Nut2PXrl345ptvoNVqwx0jEVGXUalyodGMarFGAYNhCVSqXLZtoR6FYzdR9yM5XB8HZb1cNyQHqqw++WX7E4z2dNoRWiSfm+y9UgYY3jAgqzir7QFywLDEwElDKWaFa+yeMGECnnrqKVx33XV+9zly5Ah+85vf4J133oFSqWz3nI2NjbDZbF4/REThYhLFNolzAFiwbx9MItuxUWSFlBF65pln8OKLL2LevHlISUnByy+/jIEDB2Lu3LnQ8xsgIooxvXsPgc32PwDAyJEHoFK5vlll8px6Eo7dRN2Pu/LcnTwPVFnNyUNdMm/IRN32OvQe1hv6uXpkTMqAKlcF/Uw9cubl4MRnJyBLlEGdr4b2Ii0T5xTTIjV2O51O3H777bj//vtx1llnBXXMokWLsHDhwrDFQETUUrkgtEmcA6cnC2XbFoqkkCrP9+7di4kTJwIAEhISUF9fD5lMht/97ndYunRpWAMkIupqMpnCs5yY2NezzOQ59SQcu4m6n9bJc+0Irc8Kas3Fmrhv2eLmfs20I7XIvSvXKzmuHaHFwMcHYsCCAciamsXEOcW8SI3df/rTn9CrVy/89re/DfqYBQsWwGq1en4OHz4ctniIiHxNFApwslCKjpAyQjqdDrW1tQCAvn374ueff8bZZ5+NmpoaNDQ0hDVAIgpeZeUanDz5ORIT8yEIu2C31yA7+05kZk6Kdmjdliia0NR0ur/sL7/8GgpFMuz2KgiCEQDQ1HQcomjyVKQTxSKO3UTdjzsRjNPf4aJwRSFy5uVg92270VjeiD6398GQt4ZEJ8BuqPUXDkQ9WSTG7m3btuHll1/G9u3bIZMF/3eVmJiIxMTEsMRARNTaVydP+qw852ShFA0hJc8vvfRSfP311zj77LMxdepU3Hvvvfjmm2/w9ddfY/z48eGOkYiCsH37KNhsm9qsr65eBY3mYpx77sYoRNW9mc0lMBrnAHC2WPdam/3q63dgy5Y8GAzLoNfPjGCEROHDsZuo+/GXCNaO0CL98nQcLT+KpMFJ0Qit22LynOJJJMbuDRs24Pjx48jLy/Osczgc+P3vf4+XXnoJBw4cCMt1iIiCZRJFzDIafW47J4nviyjyQkqev/LKKxBPNeh/6KGHoFQqsWnTJtxwww14+OGHwxogEbWvsnKNz8S5m822CZWVa1iB3oIomtokzgOTYDTOhU5XxAp0iknhGrvXr1+P559/Htu2bYPZbMbq1asxZcoUz3ZJkvDYY49h2bJlqKmpwahRo7B48WIUFBSE+ykRxbxAiWCZ0rXO2RTsOBUfmDyneBKJz9233347Lr/8cq91RUVFuP3223HnnXeG5RpERB1RLgh+t2202TCiAxMmE4VDSMnztLQ0z7JcLscf//jHsAVERB138uTn7e6zf/9DSEjIglY7IgIRdX+CUI7gE+duDghCBZPnFJPCNXbX19dj6NChmDFjBq6//vo225977jn89a9/xcqVKzFw4EA88sgjKCoqwu7du6HiLZZEXiSH/0SwPME1NZHU5Oum5fjlq9UNUU8VrrG7rq4OFRUVnsf79+/Hzp07kZaWhry8PKSnp3vtr1QqkZ2dDYPBEFrgRESdUBCgp/kojf/J1Ym6SkjJc5vN5nO9TCZDYmIiEhISOhUUEXWMTnc1jh5dHHCfhoYfsWPHBcjKKkZh4YrIBNaNqdWhVMEqoFbnhz0WokgI19g9YcIETJgwwec2SZLw0ksv4eGHH8a1114LAHjrrbeQlZWFjz/+GDfffHNowRP1UAErzxNOVZ7bWXneUqAvHIh6mnCN3Vu3bsW4ceM8j+fPnw8AKC4uxooVKzodJxFROOWqVLivb1+8dOSI1/rirCxWnVNUhJQ8T01NDTiZSG5uLqZPn47HHnsMcrk85OCIKDiZmZOQmNgfjY0H293XYlmJnJx5rEDvMDkMhiWsOqeYFYmxe//+/Th27JjX7d9arRYXXnghNm/e7Dd53tjYiMbGRs9jf8kCop7GkzxXsPI8WGzbQvEkXGP32LFjIUnB/1vCPudEFG1n9e4NABiiVmNqZiYmpqczcU5RE1LyfMWKFXjooYcwffp0XHDBBQCA77//HitXrsTDDz+MyspKvPDCC0hMTMT/+3//L6wBE5FvOTlzsH//Q1CrC5GdPQuVle+jru47n/vabBvjPnnuatviW0bGLVAoXIO1Wj0IanU+tNqLmDinmBaJsfvYsWMAgKysLK/1WVlZnm2+LFq0CAsXLgzpmkSxjD3PO47Jc4on/NxNRPHKdKqwZnRqKh4fNCjK0VC8Cyl5vnLlSvz5z3/GtGnTPOsmT56Ms88+G0uWLMF///tf5OXl4emnn+YgThQhTmcTAECnG4v+/ecjNfUS7Nhxgc99NZpREYyse/LftkWB/PznmCinHqc7j90LFizw3EIOuCrP+/XrF9EYiKIhmLYtrDz3xuQ5xZPuPHYTEXUld/I8NzExypEQASHdl71p0yYMHz68zfrhw4dj8+bNAIDRo0fj0KFDnYuOiIImSa7kuUzm6n2o1Y5ARsaNPvaUITFRH8HIuieVKhdpaZNbrWVrFuq5IjF2Z2dnAwAsFovXeovF4tnmS2JiIjQajdcPUTwIlAj2tG2xM3neEpPnFE/4uZuI4hWT59SdhJQ879evH0pKStqsLykp8VSKVVdXQ6fTdS46IgqaJNkBAHL56YmD+va9x9eeEISKCEXVvSUnnwMA0OmuQmHh+xg58iD0+plRjoqoa0Ri7B44cCCys7Px3//+17POZrPhu+++w0UXXRTyeYlikbXUivL7ylE2swwVD1agbGZZm+UGYwMAtm3piEB94ol6Gn7uJqJ4xeQ5dSchtW154YUXMHXqVHzxxRcYMcLVN3nr1q3Ys2cPPvzwQwBAaWkpbrrppvBFSkQBudu2yGRKzzpXaxI5gJYfvBVQq/MjGlt3JUnNAIDevYcgK2tqlKMh6lrhGrvr6upQUXH6C7j9+/dj586dSEtLQ15eHu677z489dRTKCgowMCBA/HII48gJycHU6ZM6bLnRtTdlE0vg2Wlpf0dT7FttqHv3X291nHCUN8kByvPKX7wczcRxSOTKGKfIAAAFAEmTSaKlJCS59dccw2MRiOWLFkCo9EIAJgwYQI+/vhjDBgwAABw9913hy1IImqfu21Ly8pzlSoXBsNSGI2zAUgAZGxL0oI7eS6ThfRPIVFMCdfYvXXrVowbN87z2N2rvLi4GCtWrMADDzyA+vp6zJkzBzU1NRg9ejS+/PJLqFSq8D8pom7IWmrtUOIcACx/t2DgMwOhyj39d+Luec7Kc29s20LxhJ+7iSjelJjNmG00wl06cPkPP2CZwYCZeraepejpcMbIbrfjqquuwuuvv45FixZ1RUxEFILTlecJXuv1+pmoqVkHi+XvyM39HduStMDkOcWLcI7dY8eOhST5r4SVyWR44okn8MQTT3TqOkSxyrbB1vGDJECoELyS5+x57huT5xQv+LmbiOKNSRS9EueAqwRwrtGIIp0OuSzGoSjpcM9zpVKJH3/8sStiIaJOcPc8b9m2xa1XrzQAgFyujmhM3R2T5xQvOHYTRY7mkhAmvJUB6nzvMZo9z31j8pziBcduIoo35YIAXyUDDgAVp9q4EEVDSBmjX/3qVygpKcGzzz4b7niIyAertRTHj7+D5uZaKJUZsNurAMBrua5uFwDvti1u7nXu1i7kwuQ5xROO3USRoR2hRdJZSWjY1RD0Mfo5eq+qc+B02xb2PPfG5DnFE47dRBRPCtRqyIA2CXQFgHw1CwEpekLKGDU3N+PNN9/Ef/7zH5x33nno3bu31/a//OUvYQmOiICysumwWFYGvb/NVtpmnbuVi7u1C7kweU7xhGM3UeSo89Vo2NUA7VgtVPkqKNOVsFe77hBTpithr7LD8pYFcK1C2hVpbc7hbtvCynNvnuS5gslz6vk4dhNRPMlVqbDMYMCsU3M8AK52GUsMBrZsoagKKWP0888/49xzzwUA/PLLL17bZJwJlyhsrNbSDiXOAeD48XcwaNAir0lBWXnuG5PnFE84dhNFjmB03Vrc/6H+SLu8bWIcABp+bkDtd7UAfFdReyrP2fPcm8P1H1aeUzzg2E1E8WamXo+XDx/GTw0N+GO/fpjXty8T5xR1IWWM1q5dG+44iMgHm21DCEdJEIQKr+Q5K899Y/Kc4gnHbqLIEA4IaPjF1bJFkaLwu1+SIcmTPBf2te3jKVeemjA0hLYt1lIrTnx6Ao5GB5yNTiT0cb0PEPa6rqPMcFW/A4B6sBrqfDW0F2u9WseIJhFCuQB1gbpNS5loYtsWiiccu4koHjVJrrF+Qno6E+fULTBjRNSNaTSXhHCUDGp1vtcaVp77xuQ5ERGFk7nEDONso6dZ546LdsCwzAD9TH2bfet/rPcs752/F3U/1KFwRaFnnbvyvKNtW8qml8Gy0tLx4GXwxGouMcM4xwg4AcgBw1LfzyEamDwnIiLq2azNrs/p9Q5HlCMhcgk5Y7R161a8//77OHToEJqavBNyq1at6nRgRAQkJuqhUKTC4agJ+piMjOu9qs4BVp77w+Q5xRuO3URdRzSJXolzAIAEGOcaoSvSeVVvW0utqNtZ53W8ZaUFOfNyoB2hBXC653lHKs+tpdbQEuctYk06J+l04hwAnL6fQ7QweU7xhmM3EcWTErMZx+yuu+Mm/fQTlhoMmKnvHl/gU/wKKWP03nvv4Y477kBRURH+/e9/48orr8Qvv/wCi8WC6667LtwxEsUls7kERuNstPwUrtGMhkYzCnZ7NQBAqUyH3V6N48f/AUly3SJeVfURysqmo7Bwhec4Vp77xuQ5xROO3URdSygXvBPnbg5AqBC8Es+2DTaf57BttHmS557Kc3vgynPRJKLq0yrUbq1F/c/1AfdtlwMwzmyROG+xfs+cPUg+O9nT7qVl65fWy+JBEZJdgmaUBk2HmiBBQvKwZNg22GCvsSPprCQIuwQodAokDUlC7cZar2UkAKo8lc/zNxx0vd9pqGhAOtI793yJujmO3UQUT0yiiDktJgt1AphrNKJIp2P7FoqqkDJGzzzzDF588UXMmzcPKSkpePnllzFw4EDMnTsXen4jRNRpomhqkzgHAJttM4YMederstw1qegbXvtZLCuRkzMPWu0IAKw894fJc4onHLuJupa6QO17gwJQ53tv01yi8bmrZtTp9TLlqQlDA1Sem0vMMM4y+t0eioafGnyur/miBjVf1HToXNWrqju0viP23rsXddu9W90Q9TQcu4konpQLgq/v71EhCEyeU1TJQzlo7969mDhxIgAgISEB9fX1kMlk+N3vfoelS5eGNUCieCQI5fBXviYIFV5r/E0qarNt9Cyz8tw3Js8pnnDsJooAH51EBj07qE27E+0ILbKKs7zWZRVnearOgdNtW/z1PBdNYtgT57HGstICa6k12mEQdRmO3UQUTwrU6jZJSgWAfLWfAgWiCAkpY6TT6VBbWwsA6Nu3L37++WecffbZqKmpQUOD72oVIgqeWl0A1yfw1gl0RZvJQP1NKqrRjPIss/LcNybPKZ5w7CbqWv7atqScn+Jz/8IVhciZlwPbRhs0ozReiXPgdNsWf5XnQrkQVFzaMVroinSuY/a5jlGmK1GzrgZ139UFOjQmtGx1Q9TTcOwmoniSq1Jh0aBBeHDfPgCuxPkSg4FV5xR1IVWeX3rppfj6668BAFOnTsW9996L2bNn45ZbbsH48eODPs/69esxefJk5OTkQCaT4eOPP/baLkkSHn30Uej1eqjValx++eUoLy8PJWSimKJS5cJgWNZqrRwGw5I2k4FqtSOQlVXstS4rq9jTsgVg5bk/TJ5TPAnX2E1EvqkL1G0rz320bGlJO0KLfvf185n8lStPvU2XAMnRNoHut01MK4OeH4QBCwZgwIIBKFxWiMJlhch/Nh8FfysI6vjurmWrG6KehmM3EcWbiemu+Uw0cjkOjBzJyUKpWwgpY/TKK69AFEUAwEMPPQSlUolNmzbhhhtuwMMPPxz0eerr6zF06FDMmDED119/fZvtzz33HP76179i5cqVGDhwIB555BEUFRVh9+7dUPGbJ+rhsrJ+BaNxFgBg0KAX0KfPTW0S526FhSuQkzMPNttGaDSjvBLnQOcqz63WUpw48SkcjkY4nY1ISOgDABCEvQAApTIDdnsVAECtHgy1Oh9a7cV+Y+1OmDyneBKusZuIfFPlqpBxfQaqPnKNiVAAhiWGNi1bguWuPAdcrVsUakWb6xneMARs3dK6FUxL7tYxlpWWkOLrDgI9P6KegGM3EcWbOocDAKBTKllxTt1GhzJGNpvNdVCvXkhOTvY8vueee3DPPfd0+OITJkzAhAkTfG6TJAkvvfQSHn74YVx77bUAgLfeegtZWVn4+OOPcfPNN3f4ekSxxGT6m2d5374HoFSmQq+f6Xd/rXZEm6S5W6iV52VlxbBY3urQMS4yGAzLAsbbHTB5TvEg3GM3EflmLjGjalWV5/GgRYOgnxl6tZS75zlwqnWLj0Jz/Uw9jr5xFLVbaqEdq4UqXwVluhJylRzpE9PbTSy7W8ec+OwEZIkyNFubIewVoMx0nSMh0/X+oWW7F3u1vd1l8ZCIpiNNsK23tbmm5lINtGO0EMoEKFIVSCpMQu3mWq9lKAFVnsrv+YN9fkSximM3EcWr+lPJ82SFop09iSKnQxmj1NRUyGQ+ZkJqxXHqf/bO2L9/P44dO4bLL7/cs06r1eLCCy/E5s2b/SbPGxsb0djY6HnsfqNBFEtE0YR9+x5sscYJo3EudLqikCq6Q6k8t1pLQ0ycA4DUqXhbxmA2vw67vQYazSg0NR2CJAHJycNgs22A3V6DpKSzIAi7oFDokJQ0BLW1G72WgQSoVHme6viWlfINDfsBAIKwL+QYibq7SI7dRPFKNIkwzjF69Tzft2Af+tzSJ/TKc6V35blfru+B0e/3/ZAxKaPD19GO0HZJElo0idjSfwvQMnQFMOSdISG/JkTxgmM3UfdWarVig82GNIUCG2w21NjtuDM7G5MyM6MdWsyrY/KcuqEOJc/Xrl3rWZYkCVdffTXeeOMN9O3bN+yBHTt2DACQlZXltT4rK8uzzZdFixZh4cKFYY+HKJIEoRzenzYBwAFBqAgpGR1K5bnNtqHD1/EWerwAUFY2HRbLSs/j6upVPvfzt74j9u69D3V1O1BYuKLT5yLqbiI5dhPFK6Fc8DVsQ6gQQk+ey2WumbIcgGT3PWkoADjqXB8yFcnd60OmKlcFw1IDjHONgAOdbmNDFE/CPXavX78ezz//PLZt2waz2YzVq1djypQpnu2PP/443nvvPRw+fBgJCQk477zz8PTTT+PCCy/s7FMh6nGml5VhpaVty7NV1dUYkJiI94cMwQgt74wK1cFTrarqHA6YRJGtW6hb6FDyfMyYMV6PFQoFRo4ciUGDBoU1qM5YsGAB5s+f73lss9nQr1+/KEZE1HFqdQFcs461/LCsgFqdH9L5Qqk812guCelap4Uer6vqfWX7O4aRxbISOTnz/La+IYpVsTB2E8U6dYEakKNNlXWgyUKDIU+Qwyk4A1aeO+pPJc97d6/kOeBqK6Mr0kGoEKDOVzNxThSkcI/d7c01dsYZZ+CVV17BoEGDIAgCXnzxRVx55ZWoqKhAJitpiTxKrVafiXO3A42NuGDHDhRnZWFFYWEEI+sZSsxm/LaiAgCwq6EBeVu2YJnBwElDKeq6baPf7OxsAIDFYoG+xR+KxWLBsGHD/B6XmJiIxMTErg6PqEupVLlIT78W1dUfn1qjgMGwJOQq7mArz0XRhKqqT1Fbu9V1VUUqHI6akK6Zmno5ysvvhVKZBUlytVJq2TIl0HJNzbqQrtlZNttGJs+JiKjDPFXWs0+1bpGHp8paliADhFM9z/3orpXnbqpcFZPmRFEWaK4xALj11lu9Hv/lL39BSUkJfvzxR4wfP97nMWyXSvHo0+rqoPZbabFgXk4OK9A7wCSKmG30ngRdAjDXaESRTscKdIqqbps8HzhwILKzs/Hf//7Xkyy32Wz47rvvcPfdd0c3OKIuZjaXoLr6X57HgwYt6tTkm8FUnpvNJTAaZ/ndrlINQVpaERISXNUn7j7hSmU67PZq1NR8jcbGg579a2q+CjneaNFoRkU7BCIiilH6mXocW3kM1g1WDP7L4E5NFuomT5DDAUfMVp4TUexpamrC0qVLodVqMXToUL/7sV0qxSN9QkLQ+07bvRv7L7qoC6PpWcoFAb5KBRwAKgSByXOKqk4nz4OZyMSfuro6VJy6JQNwTRK6c+dOpKWlIS8vD/fddx+eeuopFBQUYODAgXjkkUeQk5Pj1Z+NqKcRRROMxjlo2bJl374F6NPnli6rPHdd03/i3LXPbmRlrfBZme1qs/JGSLF1F1lZxaw6p7jRmbGbiAI4NXSHq9LaPWmov57nTrvTU5XeXSvPiSg8unrsXrNmDW6++WY0NDRAr9fj66+/RkaG/0mI2S6V4tHkjAzc0yKHFciBxkasqazkJKJBqm9u9rleASBf3bk2eESd1aHkeev+aKIo4q677kLv3r291q9aFdwEflu3bsW4ceM8j92Db3FxMVasWIEHHngA9fX1mDNnDmpqajB69Gh8+eWXUPEbJ+rBwj1ZKNB+5bnrmu3z19ak85OLhkajuRRa7RgIQhkUilQkJRWitnaz1zKghEqVB7vddYudu1LevSyXq5CePpGJc+qxwj12E5F/jgZXFbg8SR6W88kTXOfx17bFXXUOsPKcqCeJxtg9btw47Ny5E1VVVVi2bBmmTZuG7777Dn369PG5P9ulUjzKValwXUYGVldVedaN0mjwQ20t6qS2Y/WXJ08yeR4Ef5OwygEsMRhYdU5R16HkubZVv6Zf/epXnbr42LFjIfn4B8ZNJpPhiSeewBNPPNGp6xDFEtdkoW1nHQt18k3gdOU54IAkOSCTeX/Adl2zff7amnR+ctH2yE79eL8mQ4a8E/IXCkTxItxjNxH55xRc45RcHZ7kuSzBVWnqr22Lu9+5rJfMsy8Rxb5ojN29e/dGfn4+8vPzMXLkSBQUFKCkpAQLFizo8msTxZL/690bq6uqMCU9HX8rKECuSoU1lZWYvGtXm32v0umiEGFsCTQJ65bhw9k3nrqFDiXPly9f3lVxENEpKlUuDIalLdqoyDs1WShwuvIcAJxOOxQK7+S565pvBGzdEqitiVY7AllZxbBYVoYco38yGAzLAABG41y4up51bgJVonjCsZsoctyV54qk8FSBt1d57qw/lazvLWc7JqIepDuM3U6n02tCUCJyEZ2usXewWu2piJ6UmYmLNRpsajFx7sUaDavOg7AhwGTD9U7/c74QRVK3nTCUKJ7p9TNx9OgbqK3dgoKCv3VqslCgZeW5u+9529ueWl5Tqx0LlSq/Q21NCgtXICdnHk6c+AwyWSKam60QhL1QKjMhSXYAbVumtLecknIeMjImeZLkOl0RBKECLrPpOgAAz+lJREFUanU+E+dERNTthL3y/FTPc6c9cOU5+50TUSCB5hpLT0/H008/jWuuuQZ6vR5VVVV49dVXceTIEUydOjWKURN1T+7kuUruPdZvPPdc3LRrF96vrMSktDR8es450Qgv5lyi0fhcLwd7nVP3weQ5Ubfl+kCcmNj5iXdkMqVn2V/fcwCeJHde3h+Qnj6xw9fRakd0ae9wlSqXSXMiIup2rKVWnPj0BOwnXONos9X3pFcd5W7F0l7Pc/Y7J6JAAs019vrrr2PPnj1YuXIlqqqqkJ6ejhEjRmDDhg0466yzohUyUbflTp6rFW3H3nNTUvB+ZSUyExLabCPfRmi1mJKRgY9b9JGXAVjKXufUjTB5TtRNORwNAACFonc7e7ZPJpNDJusFSWo+VXnu75p1p66Z3OlrEhERxYOy6WWwrPTu1bnz0p0wLDNAP1PfqXO727a01/OcledEFEh7c41x0nCi4PmrPAeA5FMJ9VqHo8028u+hvDx8XFWFZLkczw8ahEkZGUycU7fC5DlRN+V0upLncnlSWM4nkyVAkpoDVp6fTp6nhOWaREREkSaaRAjlAuTJcjjrnFAXqKHKDf0DmGgSYd1khb3aDvGACKFCgDrfdRux7XsbbOt89OqUAONcI3RFuk5d2922hZXnRERE3UMwyfM6Js87xP1lQz+VCnfl8k5z6n6YPCfqpk5XnocneS6XJ8DpbGDlORER9VjmEjOMc4xAy0JtOWBYGloVuLnEDONsI+C/YNM/ByBUCJ1KnnsmDLX7SZ6z8pyIiCiiAiXPU5g8D8l+UQQANDmdMIkiq86p2wnPbEZEFDZWayn2738UdvsJAEBzszUs55XJXH3X/FWeS5LE5DkREcUs0SS2TZwDgNNVBS6axI6fL9TEOQAo4KlQD5W757nfti2sPCciIooogZXnYVViNmOm0QgA2CuKyNuyBSVmc5SjIvLG5DlRN1JWNh07dlyAgwefBOCadGznzjEwm0s6fW653JU891d57nQ2wj1JKZPnREQUa4RyoW3i3O1UFXiHzxdq4lwOGJYYOlV1DrSoPPfTtsVZ73rCrDwnIiLqWqVWKx7dvx9l9fUAAJPY9kt5Js87xiSKmH0qce4mAZhrNPp8fYmihW1biAIQRRMEoRxyeTKczjqo1QVQqULvwSWKJlitm2C3V0MUD0AQKqBW5wMAbLbvYbOt83GUBKNxLnS6ok5du73Kc3fVORCeSUqJiIgiSV2gdpWF+Eqgh1AFri5QAzJ0OIE+4JkByL49u9OJc+B0z/P2JgyV92Y9DBERUVeZ9OOP+OzECa91f9y/H2UNDVhRWOhZ55kwtLk5ovHFqnJB8Pk2ywGgQhDYvoW6DSbPifwwm0tgNM5B68apBsNS6PUzQzzfbITaOFUQKjqVPD9ded7o+wqnkudyuRoyGSvYiIgotqhyVTAsNcA4y7uCCYrQqsBVuSoYlvk4XwBZxVkYsGBAh64TiLtti9+e5/XseU5ERNSVJv7wAz4/edLntpUWC+bl5GCEVguAlecdVaBW+6xTUADIV3eu9R1RODF5TuSDKJp8JM4BwBlSFbjrfKEmzgFA4alQD1Wwleds2UJERLFKP1OPfQ/vg/2Yq/WZLFmGPjf1QZO1CT/f8DOQAKjyVLBXubYrM5TtLvfK7IXmymakTUlDkiEJwl4B6sGuD3TCXgHKTCUS+iQgfWI6tCO0YX0+7rYt7VWes+c5ERFR+JVarX4T524bbTZP8tw9YWi90wmnJEEuk3V5jLHM3NiIvMREHGw8XeAnB7DEYGDVOXUrTJ4T+SAI5QjUOHX37luRkNAXKlUe7PYqAIBSmeF3ub7+J3SmcarBsKRTVedA+z3PmTwnIqKewNlwevyW6iRYSixhOe+Jj09AWazE2R+cHZbzBcNTee6n5zkrz4mIiLrOBput3X1GaTSeZXflOQA0OBxI7sWUmz/Ty8qw0uL9Hu1SjQbvDBnCxDl1O/xLJvJBrS6A/8apgM22ISJxDBjwDLKzb+904hxg5TkREfV8kiTBYeu6W6UtKy3ImZcT9gpzf+RKVp4TERFFyyUtEuO+FGdlearOAUAll3uyCHVMnvtVarW2SZwDwHqbDebGRibPqdvh7EJEPqhUuTAYlkY1hqysYgwYsCAsiXOAledERNTzWf9n7fJr2Da2X4UWLu31PG886rrNuemY77GdiIiIQjdCq8VZSUle64aoVHgsLw/fDx/uNVkoAMhkstOThrLvuU+lVituLSvzu31jENX+RJHGr8GI/NDrZ6K8/F44nfVddo2kpKFIS7sKACAIe6FUZiIhoQ/S0ydCqx0R1mux8pyIiHqysullsKwMT4uWQDSjAlehhZO757mvti1l08tQt9U1dh947ACEfQIKVxS22Y+IiIhCN0itxq6GBtyQkYEH+/XzqjT3JVmhgM3h4KShPvhq1dLaqHaq/YmigclzogCczuYuPb/BsCzsSXJ/WHlOREQ9lbXUGpHEeVZxVsRatgCnK89bt23x9Xwj3VKGiIgoHhgbGgAAd/ft227iHDjd95zJc2/+WrW01LoNDlF3weQ5kR9W6xYAje3uF6qsrOKIJc4BVp4TEVHPZdvg/xbf9BvToblIg9rNtYASUOWpYK+2AwCU6cqgluUqOdInpkc8MS1TupLn1V9Uo2xWGZKGJKFhZwOaqnyP5baNNibPiYiIwsTudGKfKAIADGp1UMekMHnuU3uTr3561lmYlJkZoWiIOobJcyIfysqmw2JZ6bUuNXU8kpLOQWJiLmprNwNQQqXKg91eDQBQKtODWpbLVV3SlqU9rDwnIqKeSnOJn1t85UDBiwVQ5cbmxFNHXz8KAGg63ARLSfuV9ZFsKUNERNTTlFqteOf4cdQ2NyNDqcReUUSzJEEJwPfsI22x8ty3NIX/yc0fystj4py6NSbPiVqxWkvbJM4BoKZmLc48c0XYJvCMNFaeExFRT6UdoUXapDScWHPi9EoZYFhqiNnEeeWaSjQeDP4OuEi3lCEiIupJAvXjtgPov2ULlhkMmKnXBzxPqMlzkyiiXBBQoFYjVxWb7138uX33bvz9+HGf227MyMBTgwZFOCKijmHynHo8q7UUJ058CoejEU5nI5KSDMjImOw3CW6zbfBzJicEoSJmk+esPCciolhhLbXixKcn4Gh0wF51qn1KhhLiQRGSXYJmlAbCLgH2Grtnufmka54SuVaOvAfzkH17dswmzgHg5Ocng9ovIS8BZ314FhPnREREIQqmH7cEYI7RiCKdLmBy2508r+1A8rzEbMYcoxFOAHIAS4NI0seKUqvVb+KcrVooVjB5Tj2ar/YrAFBRMQ8GwzLo9TPbbNNoLvFzNjnU6vwwRxg5rDwnIqJYUFZcBstbgT/AVq+q9rkMAE6rEwcePoDEPonQz4zdD566q3U4uvhou/s1HWrC3vv24tyN50YgKiIiop6nvX7cbk4AFYIQVPI82Mpzkyh6Eufua8wNIkkfKwK9tsm9mJKk2CCPdgBEXcVf+xUXCUbjHIiiqc0WrXYE0tOvabVWBoNhacxWnQPBVJ7XAmDynIiIosdaam03cR4UJ2Cca4RoEjt/rijJnJQJzcXB9TC3bbKhck1lF0dERETUM12iCW68lQPIb2fi0JRTCeFgk+flguBJnLs54ErS9wT+XttgXkui7oJf81CP5b/9ipsTu3ffivT0KRCEXbDba6DRjDq17LpVWiZLQf/+C5CdfXtMJ86B9ivPGxuPAACamo5FLCYiIqKWbBuCq/wKigMQKoSYbt1y7sZzUbmmEpaVFjgaHAFbuZz88iQyJ/HWZyIiolAo4ept7o8MrnYq7VWDuyvPVx0/jmS5HHdkZwc8psBHAlmBnpNYHqHV4ky1GntafBkQ7GtJ1F0weU49lv/2K6fZbBu8kuzV1au8tktSLQ4ceBiJiX18tniJJYEqz8vKpqOubhsA4MCBxyAI+1BYuCKS4REREUFzSXCVX0FRAOr82P/gmTkpE5mTMiGaRGzpvwVtytNO0V2li2xgREREPcC0n3/GB1VVXutGazQYpdGg2u5Kp5+XkoJJGRlBJXvfOuYqRjOKIh46cAAPHTiAN/z0MDeJIjZZrdAqFLC2qFT/VVZWj0osX6jRYI8g4LLUVEzNyAj6tSTqLti2hXqsxEQ91OozwnAmJ4zGuT5bvMQSmSwRAFBVtQZlZbNgtZYC8N3exmJZ6dlORNRRtbW1uO+++9C/f3+o1WpcfPHFKC3lvynUPu0ILTQXhSGBrgAMSwwxXXXemipXBcNSg6scrRXNxRpWnRMREXXQQ/v2tUmcA8Ammw2/zs3FssJCLCssxF25uUEle9dUVuJQY2Ob9XOMRphE71ZyJWYz8rZswU1lZV6JcwD4u8XSZv9Y5p489YbMzKBfS6LuhJXn1COZzSUwGmfDNSd2ODggCBUx3brFbF4GAGhsPACLpQQWSwmysoqRnHyOz/1tto3QakdEMkQi6iFmzZqFn3/+GW+//TZycnLw97//HZdffjl2796Nvn37Rjs86ub63NoHts02qAvVSL8mHfZqV9WXMl0J8ZAIyS5Bc5EGQpkAe43dazl9YjrUA9RQ56t7VOLcTT9TD12RDkKFAOGAgLqtddBdpWPinIiIqINKrVY8c+iQz23BTAzqy+cnfbdXa32+UqsVs4xGv+dxILTrh6rUasXrZjNq7HaM0miwSxDaLJ+VlIRdggCdQoEhSUnYWFvrtZwAIE+lQtWpav0MpdKzvK3WNb9aZZPvFrJE3R2T59TjiKIpzIlzAFBArc4P4/kiq7JyDRob274xsFhWQqtd7vMYjWZUV4dFRD2QIAj46KOP8K9//QuXXnopAODxxx/Hp59+isWLF+Opp55qc0xjYyMaW1Tp2Gxh7HtNMccpuvqSaM7XIP/Z2B17u4oqVwVVrgo66IDp0Y6GiGLB+vXr8fzzz2Pbtm0wm81YvXo1pkyZAgCw2+14+OGH8fnnn2Pfvn3QarW4/PLL8eyzzyInJye6gRN1kRKzOWDyOtTJLK/W6bD46NGA52vv2oCrJ3ikep5PLyvDSsvpydpXVVe3uxyqxw8exH5RxIrCwk6fiyiSmDynHkcQyuE/cS4LsM0fBQyGJTFddX7y5Od+tzkcNUhJGYna2i2edVlZxaw6J6KQNDc3w+FwQNWqUkatVuN///ufz2MWLVqEhQsXRiI86oZEk4iqT6tQu9VVldR4yPVFitQczi/BiYjiV319PYYOHYoZM2bg+uuv99rW0NCA7du345FHHsHQoUNx8uRJ3HvvvbjmmmuwdevWKEVM1HVMoojZAZLXnZnMclJmJi7WaLCpVSGI+3wmUWw3cQ4A5ycn49OqKvRLTMR/ampQ29zsVcmdKJPBYrd7EuwVgoAspRKNkuu9U8t9Ay2X1dfjUz/V8l1lpcWCeTk5GKHVRvS6RJ3B5Dn1OGp1gZ8tCgwfvhmieACCUIG6up8gSXZoNBdBEMpgt9d4LaenT4RaPQBqdX5MJ84BQKe7GkePLva5TaMZBUlqQm3tFiQnn4+CgteYOCeikKWkpOCiiy7Ck08+icLCQmRlZeHdd9/F5s2bkZ/vu4p4wYIFmD9/vuexzWZDv379IhUyRZG5xAzjLN8fIo+/exy68TroZ7adYIuIiII3YcIETJgwwec2rVaLr7/+2mvdK6+8ggsuuACHDh1CXl5eJEIkiphyQQhYTvfPwkJMzcoK+fwbzz0Xn1RW4tpduwAAP5x3Hs5JSfFcOxildXUoragIOYbubqPNxuQ5xRQmz6nHUalykZp6GWpqvvFabzAsgVY7Ii4Tw5mZk6DRXAybbZPXeneF+YkTnwAAtNqRcfn6EFF4vf3225gxYwb69u0LhUKBc889F7fccgu2bdvmc//ExEQkJiZGOEqKNtEk+k2cuxnnGqEr0vXI/uVERN2V1WqFTCZDamqq333Yco1iVbJc7nebAsBFYUjqXpOZCaVMBrskQadUetYXRKgVS3c3ShOGyeGJIsj/vxpEMUgUTTCZFkMQ9nutz8y8CXr9zChF1T2ce+5GnHXWp9DprvWsa2o6jrKyWTh5ch0AoLHxWJSiI6KeZPDgwfj2229RV1eHw4cP4/vvv4fdbsegQYOiHRp1I0J5ENVXDkCoCK5Ki4iIOk8URTz44IO45ZZboAmQ4Fq0aBG0Wq3nh3eMUayoczp9rpcBWBJiuxZfkk4l6YUW18tVqfCGwRCW88eq4qwsVp1TzGHlOfUYZnMJjMZZPrfJ5Uqf6+NNZuYkZGZOwrff9oYkNeDkyS+8tldVfYjt20fh3HM3RilCIupJevfujd69e+PkyZP46quv8Nxzz0U7JOpG1AVBVF8pAHU+q7SIiCLBbrdj2rRpkCQJixf7bvnoxpZrFKu21ta2WScD8N3w4WFN6qoVClgdDjQ4HF7rL27xpdQ9ej3O7t0b56Wk4IIdO8J27c54pF8/mO121NjtuEijQZkgoMZuR2FSEsoEAakKBQqTkrC5ttZrWQkgT6VC9ame6ulKpdeySi7HxPR0Js4pJjF5Tj2CKJr8Js4BVlS3VFm5BpLU4He7zbYJlZVrkJk5KYJREVFP8tVXX0GSJBgMBlRUVOD+++/HmWeeiTvvvDPaoVE3ospVQVekw8mv/E9UZVhiYMsWIqIIcCfODx48iG+++SZg1TnAlmsUm0yiiD/u29dm/XODBoU9qav2UXleYjZjTosJQ8/VaDBT75rb5Q2DIajJRLuKDMAyg8ETDxGdxuQ59QhVVZ8G3C6KhyMUSfd38uTnQezzJZPnRBQyq9WKBQsWwGQyIS0tDTfccAOefvppKJW8C4hOs5ZaIRxytWTRXKKB2uCqMLe8YQEA6K7mZKFERJHgTpyXl5dj7dq1SE9Pj3ZIRF2iXBDgq2nL+acm9Awnd7JtdWUl3rZYcEFyMub88ovX9ecajSjS6ZCrUmGmXo8inQ5/PnQILx092uZ8t2RkoLdCAQBQymSotNsx+FQP9b2CgEylEnbJNRVq66rv9pbPS0nBpIyMsLWsIeppmDynmFdWNh0Wy8qA+4iiEWZzSdz3PQcAne5qHD0a+DZMne6qCEVDRD3RtGnTMG3atGiHQd1Y2fQyWFZaPI9tG2xQD1Ij9ZJUT/L85OcnYS4xM4FORNRJdXV1qKio8Dzev38/du7cibS0NOj1etx4443Yvn071qxZA4fDgWPHXHftpqWlISEhIVphE4VdgVoNOeCVwFYAyA/zRJ4lZjPKRREA8LzJBADw9QncAaBCEDxJ61yVCr/Py8Nfjx5tE+Nz+flMbhNFCScMpZgiiiYcOPAMfvrpBuzZcw9++OGadhPnbkbjXIiiqYsj7P4yMydBo7nY73aN5mJWnRMRUZexllq9EudulpUWGOd4365snGuEaBIjFRoRUY+0detWDB8+HMOHDwcAzJ8/H8OHD8ejjz6KI0eO4JNPPoHJZMKwYcOg1+s9P5s2bYpy5EThlatS4U8tJrCXI7yThAKu1jBzgmy/4itxn6tSYanBAEWLfcIdIxF1DCvPKWYEmhC0NblcA6fT1mqtA4JQAZUqN/zBxZhzz92Iyso1sFhWQqFIRVJSIRob90Gnu4qJcyIi6lK2Da3H5xZa30vtAIQKgX3PiYg6YezYsZBOtXPwJdA2op6kxGzGAy16nvtq4dJZ/lrD+PKrrCyfSXF3C5cKQUC+Ws3EOVGUMXlOMaG9CUFbcyXO296QpVbnhzu0mJWZOYmJciIiijjNJQEmofNxL7U6P7y3UhMREVH8MYkiZhuNaP1VUcu+4+HgqzWMP3+3WPDUwIE+r52rUjFpTtRNMHlOMUEQyjt8TGbmVFRWfghXJzEFDIYlrDonIiKKMNEk4thbx1C7rRbKLCWkRgmyJBmkBu+Pr1nFWUi9JBXGuUb30A3DEgOrzomIiGJYqdWKDTYb0hQKbLDZUGO3487sbEzKzPTsYxJFlAsCkuVy1DmdKOhAtXWp1YpPT5xAo8OBKrsdKQoFbsvKwgitFgCwprIS71dVocnhaJM4B9r2He8sd9uVuUYjHO3sG+5rE1HXYPKcYoJaXdDhY3Jzf4/Bg1+AIFRArc5n4pyIiCjCzCVmGGcF7vuZenkqBj4zENoRrg+5uiIdhAoB6nw1E+dEREQxbHpZGVZa2s5zsqq6GhdrNNh47rkoMZsxx2j0qtSWA1hqMGCmPvCk4f7O//LRoyjOykK5IGCTLUC7OHTNhKEt2668euQIPqyqwsiUFHxXW+uVwO+Ka9P/Z+++w6Os8jaO3zOTDiQEAiEhhJYQwVVgMSpFAUUjAmKvqwFCE3YVWVlhFRAbVsS1UCOwvoiFBRXsIggCLgHBghgSBGEkBAimkE7mef9gMzKkkDIl5fu5rrmumafe8+Qhh/zmzDmA81E8R73g5xehyMiHdfDgk1XaPjQ0XkFBsfZ9AQCAexVYC85ZOJekzC8z5Rvma3/tF+FH0RwAgHouKSur3MJ2qS3Z2bpo2zZ9m5dXpke4TdLo5GStTE9Xcy8vRfr56XhxsSQpxNtbx4uLdayoSGt+/73C41d27lImuW4yztJhV/bk5Wnl8eMK8/XVcB8fvZeRIYmJQIH6hOI56o1mzU7PDu/jE6FmzS6Vt3crGUbx/9b1kq9vhAoKUhUY2NdeOAcAAJ6Rn5JftQ1tTAoKAEBDs+kcPb4laUdeXqXrP8nMdFKa8t0TGnrO3u211cxikST9WlCgPoGn5325MSREL0VFUTgH6gmK56g3CgoOSpKCgvrq/PPf8nAaAABQGf/oKn4N2cykoAAANDSXBVYyQXgdcXNIiMvP8c3/PkT49uRJ7Tx5UpKqNaY7AM8zezrAueTk5GjSpElq3769/P391adPHyUlJXk6FjygsPB08dzPL9LDSQAAwLn4Rfgp5JZz/FFqkmIWMikoAAANTWxQkG5yQ3G6pvoEBjpMWuoK1oICzTt82P66dHiagwUFLj0vAOeq8z3PR48erR9//FFvvPGGwsPD9X//938aNGiQfvrpJ7Vt29bT8eBGpT3PfX0pngMAUB+U5JRIkgL7B8q7lbe8W3nLKD79p2OzXs0UMjSEwjkAAA3UrI4d9Z/jxxVgNuvVqCi9d/y43j9xwmN57m3TRnk2m25u1crlhXNJSsnPd5gItdSKY8fks2ePlnbt6vIMAGqvThfP8/Pz9Z///Efvv/++Lr/8cknSo48+qjVr1mjevHl64oknyuxTWFiowsJC++vsKoyzhfqBnucAANQfhxcf1u+fnJ7IK3tTtmIWxigswbXjigIAgLoj59QpSVKoj49GhIeffuzZU6XJPKsrPjRUlzVvrtHJZScrN0taGBPj8vHNzxbt7y+zVG4BfVl6uiaGhys2KMitmQBUX50unp86dUolJSXyO2ssKH9/f3399dfl7jN79mzNmjXLHfHgZvn5+yVJJpOvh5MAAIDKFFgLtHfc3j8W2KTkcckKjgumpzkAAI1E0v86MxaWlMhaUKAIPz8t7dpVE8PDtTAtTZnFxeoaEKCDRUWK8ffXBU2a6MvMTMkwFOHrq605OfKWFOnnp4ziYklSS29vh+d+ZrOGtGxpL0LHBQfrjSNH9G1Ojjr7+6tXs2bqHRTkkTHGI/z89Ep0tCakpJS7fnN2NsVzoB6o08XzZs2aqXfv3nr88cfVtWtXhYaGasWKFdq6dauioqLK3WfatGmaPHmy/XV2drbatWvnrshwkd9+m6dTpzIkST/8cK1iYhYqLCzBw6kAAMCZCqwFytqSpawtWWW7WZVI+an5FM8BAGgEzuxhfri4WJHffKNF/+v9HRsUVGHRuLbDqUT4+Wlahw61OoYz+Zgrnmqwbz2YVBVAPZgw9I033pBhGGrbtq18fX31r3/9S3fccYfMFfwC8vX1VWBgoMMD9VtBgVUpKX89Y4lNycnjVFBg9VgmAADgKC0xTd9EfqM9t+3R4ZcOl93AIvlH+bs/GAAAcKukrKwyQ7MYksYmJ8vaiCbLtBYUaGw5w8iUCvPlW/VAfVDni+edO3fWV199pZMnT+rQoUPatm2biouL1alTJ09Hg4sVFFiVnv6ODh58XuV1X8vPT/VELAAAcJYCa4GSxySf/su4ApFTI+l1DgBAI7CpgrnnbJJS8/PdG8aDKpowtFRjuhZAfVanh205U5MmTdSkSRP9/vvv+vTTT/Xss896OhJcKC0tUcnJY1TxX+EW+fuXP3QPAABwr/yU/EoL55LkHeLtnjAAAMCjLqtgBACzpCj/xvMttMomDLWocV0LoD6r88XzTz/9VIZhKCYmRqmpqZoyZYrOO+88jRw50qO5srKSdPTocp06lSNv7xAVFx+XJHl7h6ig4FcZRrFathymoqLDysv7WU2a9FB+/m4VF2cqIOB85efvlsUSrICAbsrJ2SyLJVhBQf1UWPiLTKbTvbLy8/fZj1lcfFwWSzOFht6loKBYj71vdygosJ6jcC5FRk6Vn1+E+0IBAIAK+Uf7SyZVWkAP7MtQegAANAaxQUH6c9Om+vbkSfsyk6SFMTEembjTUyL8/LQwJkbjkpNVcsZyi6QFjexaAPVZnS+eZ2Vladq0abJarWrRooVuuukmPfnkk/L29lzvpT17Rig9fdk5t8vIWHXGqzcqWP6H9PTEcx7z8OGXFBoar65dl55z2/oqPz9F5+q+5u0d4p4wAIAGIyspS0eXH9WpnFPyDvFW8fFiSad7RBf8WiCj2FDLYS1VdLhIeT/nqUmPJsrfna/izGIFnB+g/N35sgRbFNAtQDmbc2QJtiioX5AKfymUyc8kScrfl28/ZvHxYlmaWRR6V6iCYsufFKuh8IvwU8yiGCWPLn9cz9D4hn8NAADAHy5v3lzfnjyp3s2a6Z7QUA0NCWmUxeKEsDDFBQcrNT9fTcxm5dpsivL3b5TXAqiv6nzx/NZbb9Wtt97q6Rh2WVlJVSqcu1J6+jKFh09ssD3Q/f2jda7ua4GBfd2WBwBQ/+0ZsUfpy9LPuV3Gqow/XrxRwfIzpCee+5iHXzqs0PhQdV3a9Zzb1mdhCWFKfytdmV9kqtWdrdTkT01kK7Sp5ZCWFM4BAGhkjhQVSZJuad1a4yMa97fGI/z8KJYD9VidnzC0rsnO3uTpCJKk7OzNno7gMn5+EYqJWVTh+tDQ+Ab7wQEAwPmykrKqVDh3pfRl6cpKyvJoBrf43+feIUNC1GFaB3V6tBOFcwAAGqG0wkJJUpiPj4eTAEDt1Pme53VNYOBlno4gqeH3vA4LS9DhwwuUk5OkNm1Gy8+vk2y2QrVsOYTCOQCgWrI3ZXs6giQpe3N2gy8k2/JPT4llDqB/BgAAjVlpz/M2FM8B1HMUz6spKChWgYF9Pdrzu7H0vLbZTje2rVvfrBYt4jycBgBQXwVeVjcmqmwME2ba8k4Xzy3+Fg8nAQAAnkTxHEBDQfG8Blq2HKrs7M3y8+uqoKC+8vZuqeLi02Ohenu3VEHBQRlGsVq2HKKiojTl5SWrSZMLlZ+/R8XFmQoI6Kr8/D2yWJorIKCrcnK2ymJprqCgviosPCCTyVeSlJ//i/2Yv//+uXJzv1Vw8OAGPVnomU6dOiFJKikp8HASAEB9FhQbpMB+gcr+2nM90BvLhJkleSWS6HkOAEBjll9SoqyS0/8nCPP19XAaAKgdiuc1UFSUJklq1eo6de78tFvOeexYrHbvvlmnTpU/YVlDk5aWqMLCQ5Kk3btvVEzMQoWFJXg4FQCgvmp1fStlf50tvxg/BV0WJO+W3irOKJYkebf0VsHBAhnFhloOaamitCLlJeepyYVNlL8nX8WZxQroGqD8PfmyNLcooGuAcrbmyNLcoqC+QSo8UCiTr0mSlP9Lvv2YJ3eeVOZnmbIEWySLtHfSXoXe1bCL6CU5p/9QPpV9ysNJAACAp5T2OvczmxVo4dtoAOo3iuc1UFR0RJLk49PGbecMCDhPkpST85327EmQxdJMoaF3NcjhWwoKrEpOHnvGEpuSk8cpODhOfn6Ne5ZuAEDNFKWf/iMu5NoQRc2Jcss5rS9ZlflZpkp+L1H666cnLD380mGFxoeq69KubsngTmmJaSpKO32df7zuR8UsjFFYQpiHUwEANm7cqOeee047duxQWlqaVq9ereuvv96+ftWqVZo/f7527NihEydOaOfOnerRo4fH8qL+SztjyBaTyeThNABQO3yntgZKi+e+vu77gzAzc9P/nhUqPf11HT78knbuvFh79oxwWwZ3yc9PkWQ7a2mJ8vNTPREHANAAlBbPfULdM+5mgbVAqZPKb7fSl6UrKynLLTncpcBaoOSxyX8ssEnJ45JVYGXoNQDwtNzcXHXv3l2vvvpqhev79eunZ555xs3J0JAkZWVpxv79eig1VY/8cnoIWhmGrAX8XwBA/UbP8xpwd8/zggKrUlLuLXddevoyhYdPbFA90P39o3X6c50zC+gW+fu7p6cgAKDhKS2ee4d6u+V8+Sn5la7P3pzdoIZvyU/JL+9zb+Wn5ssvws8jmQAApw0ePFiDBw+ucP3dd98tSTpw4ICbEqG+sxYUaM3x49qekyNJ+vbkSe3KzS2z3YHCQkV+840WxcQoIYxvowGonyie14C7i+ene2JXLDt7c4Mqnvv5RSg6ep5SUsb9b4lFMTELGLIFAFBjxemnxzd3V89z/2j/StcH9g10Sw538Y/2L+9zb/lHVX4dAAD1U2FhoQoLC+2vs7M9Nyk33CsxLU2jk5PPveH/GJLGJicrLjhYEX58oA6g/mHYlmoqKclTScnp/xi4q3h+uid2xQID+7olhzu1aXO3/Xls7G4mCwUA1Iq7h23xi/BTzOKYcteFxje8SUP9IvzUZX6XPxZYpJgFMfQ6B4AGavbs2QoKCrI/2rVr5+lIcIO1x45Vq3BeyiYpNb/yb+UBQF1F8byaiopOT/hlNvvJYnFPrzE/vwjFxCwud11oaHyD6nVeyjBO2Z/7+bX3YBIAQH1n2AwVHXVv8VySwhLCdOmhSxU1L0o+bU+fN3J6ZIOcLFSS2tzzR6eC2B9imSwUABqwadOmKSsry/44dOiQpyPBxUbs2aNhu3fXaF+zpCh/vo0GoH6ieF4NWVlJ2rdvqiTJbPZXYeFvbjt3WFiCLr30kKKi5snb+/Qfpx06zFLXrkvdlsGdziyem0yMLgQAqLniE8VSyenn3q3dM+Z5Kb8IP0WMj1DwlcGSJK8mDbdNM04Z9ud+kfQ4B4CGzNfXV4GBgQ4PNFxJWVlalp5eo31NkhbGxDBkC4B6q+H+BedkP/30Fx09utz++tSp3/XNN5GKiVnktiFF/PwiFBExXtnZX+vo0eUymwPccl5PcCyeWzyYBABQn2UlZem3f53+sNsUYFJRepFHhhIp7fFeOnxMQ3Rm8dzkZfJgEgBAfVY6GWVyXp58zWYdLz49b0mIt7f9eWd/f0X5+6tPUBBFWRexFhRoS1aWUvPz9f7x49Xa99rmzRXu66tezZppaEgIPyMA9RrF8yrIykpyKJz/wVBy8lgFB8e5dTLL0rHWSycubYj+KJ5bZDLxBzgAoPr2jNij9GV/9JIy8gx9E/mNYhbFuH1IEYrnAABPOXnypFJTU+2v9+/fr127dqlFixaKjIzUiRMndPDgQR0+fFiSlPy/Ma3btGmjNm3cM89XqepORmmStCgmRglhDBXmTIlpaRqTnCzjHNu18fZWenGxw3YWSQvOO4+COYAGg+J5FWRnb6pkrU35+akUz52stHjOkC0AgJrISspyKJzbGVLy2GQFxwW7tQe6d+jp4WIaS/GcgQEBoO7Yvn27Bg4caH89efJkSVJ8fLyWLl2qDz74QCNHjrSvv/322yVJM2fO1KOPPuq2nNaCgmpPRmlIGp2crL25uUorKlKPJk20Oz9fmcXFOj8gQLvz8xVssahbQIA25+Qo2GLR9SEhauLlpWh/fwq85bAWFFSpcC5JR4qL9XBkpJ4+eFAl+l/hnCFaADQwVCarIDDwskrWmuXvH+W2LBLFcwAAziV7U3bFK21Sfmq+W4vnpT3Pi9OL3XZOdzNKTv+ZbfIy8a0xAKhDBgwYIMOouBQ6YsQIjRgxwn2BKpCSn1/jfZ+1WiVJb5yxbFVGRrnbJv5v7G6zTo/FTa91Ry/99luVCuelQry9deDSS5Wan68oPpAA0ADRL6gKgoJiFRoaX84ak2JiFrq117lE8RwAgHMJvKySicvMkn+Uv/vCSPJp3XiGbWHIFgBATUT7u7dttul0r/V5VqusBQVuPXddZS0o0POHDlVrn76BgYrw89OA4GAK5wAaJIrnVdS161L17LlNbds+oNDQ0YqKmqdLLz3otslCz0TxHACAygXFBik0PrTsCpMUszDG7ZOGlg7bUny8WLZTNree213sw7YwzzcAoAYi/Py0OCbG7eedkJqqdt98o+cOHnT7ueua6vb+jw8NVWxQkIvSAEDdQGWyGoKCYhUUFOvpGPL1Pf21slOnMmSzFcls9vFwIuejeA4AqK2uS7sqfGK4jq44qlM5p9SsVzOFDA1xe+FckrxDThfPZUh77tkjs79ZJl+TitOL7b3gi9KK1PyK5io6XKScHTnyDvWWUWjI0syi0LtCFRR7+o/TrKQsHV1++j35d/7fvkeLZPY1y1Zok09rH3kFe8m7pbeC+gS57f3S8xwAUFsJYWF6+JdflF5crDtatVKkr68yik8PedbS21sHCwq04vhxl5z7H7/8IpOkByMjXXL8+qCy3v/Dg4N1TcuWivD1VWpBgfoGBlI4B9AoUJmsh7y8gnX6R3dKP/10jyyWJjKZfFVcnG4ff72oKE3Nm1+hoqLDysnZIW/vUBlGoSyWZgoNvcv+IUBWVpKOHl2uU6dy5O/f+X/7HpXZ7CubrVA+Pq3l5RUsb++WCgrq47YhaiieAwCcISg2yF509qQzJy89tuJYhdsdfeNoucsPv3TY3pO+3IlQK2KSYhbFKCzB9eO5UjwHADhD1qnTfwtObNtWfZs3L7P+yrS0ak8sWlVTfvlFP+fmalx4eKMsDEf4+emipk21/eRJh+XxoaFa2rWrh1IBgGdRmayHjhxZIun0fyiOH3+7wu2OHn2j3OWHD7+k0NB4GUaJjh79v2qc2aSYmEVuGaqG4jkAoKEosBYoeXTt/8ivVtG8lCElj0tWcFywy3ugUzwHANTWgt9+U8H/Jje9fNeucif0TAgLU1xwsN44ckTJeXka0Ly50oqKlJyXpwubNNGe/HxlFhera0CA9uTnq7nFoq4BAVqXmamPfv/9nBkS09OVmJ7eKAvGiWlpDoXzYS1aaHr79o3ygwQAKEVlsp4pKLAqOXl0rY+Tnr6sBnsZSk4ep+DgOJf3QKd4DgBoKPJTqjd+qNOVSPmp+a4vnpdQPAcA1Jy1oEATUlLsr22SxiUnK66ciSgj/Pw0rUOHah1/cvv2SkxL05jkZBlV2H5ZeromNoIe6NaCAm3JylJqfr4eOXDAYd1HJ07otS5dPBMMAOoIJgytZ/LzU869kUuVKD8/1eVnoXgOAGgo/KMrHj/ULUyyj6vuSvae5xaK5wCA6kvJz9fZU2qXSEqt5iSWlUkIC9PBSy/VO127alA5Q8Kc7cF9+5SUleW089c1iWlpivzmG922Z48ePnCgzIcKzr7+AFAfUTyvZ/z9oz0dQWZzE5efg+I5AKCh8IvwU8zimFofJzQ+1D7uebW4qZbNsC0AgNqI9vcvU6CwSIqqZBLLmojw89MtoaFact5552wiN2Zn6+KdOzVizx6nZqgLrAUF5+yFb5bzrz8A1DdUJusZP78IxcQsrvXQLaGh8ZJqNnxLdvbX8vUNc+nQLRTPAQANSVhCmILjgnV87XHl7MiRJJm8TSo+Viz/zqf/KC06UqTmA5qrKK1IOd/myLuVt4xiQ5ZmFoXeEWqf+DR8YriOrjiqUzmn5N/pf/seK5LZx6z8ffnKWJnheHKbm4ZtoXgOAKiFCD8/LYyJ0bjkZJXodOF8QUxMmSFbnHm+RTExVRrGpSEO4ZKSn3/O931Lq1Yuu/4AUF9QmayHwsISFBwcp+PH1yonZ4ckyWTyVnHxMfn7d5YkFRUdUfPmA1RUlKacnG/l7d1KhlEsi6WZQkPvUFBQrCQpPHyijh5doVOncuTv3+l/+x6T2eyj4uIMpacnSmc1qfv2Tda+fQ8qJmahyyYPpXgOAGho/CL8FDG+9h88B8UG2QvpZyuwFihjVYYcvvducfOwLRTPAQA1VDoZaGp+vqL8/V1euC0939asLH164oQS0yuenHtzdnaDKp5HV6FH+d8jXDvXGQDUB1Qm6yk/vwhFRIyv9XGCgmLthfTy+Pq21sGDT5WzxubSyUMpngNA/VRSUqJHH31U//d//6cjR44oPDxcI0aM0COPPCKTiaKqq/lF+ClmYYySxyWfHqjUJIXfG26ftNSVvc8pngMAnCHCz8+tvZ0j/Px0i5+fegcFVVo8//LECe3NzVV6cbF9KJO0oiJd0by5DhcVaUdOjkK9vRXi46NhLVvWi0K7SWd3lftDfGhovXgPAOBqVCZRKW/vlpWsPT15KMVzAECpZ555RvPmzdOyZct0/vnna/v27Ro5cqSCgoJ03333eTpeoxCWEKaMTzN0/N3jkiEdfuWwDr9yWDJLMQtjFJYQ5pLzGiVMGAoAqL8i/Py0OCZGo5OTy12/5vffy13+xtGjZZY9fvCg4kNDtbRrV6dmdKaKhm2Jb91aE9u2pXAOAP/DhKGoVGDgZZWstcjfP8ol56V4DgD105YtWzR8+HANGTJEHTp00M0336yrr75a27Ztq3CfwsJCZWdnOzxQc1lJWacL52ezScnjklVgLXDJeel5DgCo7xLCwnTo0kv1VIcOtT7WsvR0JWVl1T6Ui1Q0QesTnTpROAeAM1CZRKWCgmIVGhpfzsSiFsXELHBJr/OCAqsyMzdJkoqLj6ugwOrSyUkBAM7Tp08fLVy4UHv37lWXLl303Xff6euvv9acOXMq3Gf27NmaNWuWG1M2bNmbKvnwocR1k4dSPAcANAQRfn661EnF49Jx0pOysrT86FHlnDqlzv8b8uVoUZF8zWYV2mxq7eMjSdqXn69mFosGBQeriZeXol047nuEn5+e7tRJ//jlF0mun6AVAOoriuc4p65dlyo8fKKOH39Phw49JbPZXxdfvNclBe20tEQlJ49R6chreXm79c03kYqJWeSyyUkBAM4zdepUZWdn67zzzpPFYlFJSYmefPJJ3XXXXRXuM23aNE2ePNn+Ojs7W+3atXNH3AYp8LLAile6cPJQiucAgIaiKpNpVsUXv/+ub3Nyyh3apTIvHT5sf35LSIiaeXkps7hY5wcEaHd+voItFnULCNDmnBwFWyzqFxSkEyUluiwwsFq9xoe2bKl//PKLmpnN+uniiymcA0A5KJ6jSoKCYuXvH6lDh56SzVYgX99wp5+joMDqUDj/g+HSyUkBAM7zzjvvaPny5XrzzTd1/vnna9euXZo0aZLCw8MVHx9f7j6+vr7y9fV1c9KGKyg2SKHxoUpfdtakZxYpZkGMyyYNpXgOAGgozjX+eVV9eOJErbO8e/yPodhWZWSUu82ZE51WZ6z1nJISSVILb28K5wBQAYrnqDKLpdn/nhn66ae71LRprPLzd6u4OFMBAecrP3+3LJZgBQR0U07OZofnko/8/CJVXHy64ff2DinzvKgoTRXP9e26yUkBAM4zZcoUTZ06Vbfffrsk6YILLtCvv/6q2bNnV1g8h/N1XdpV4RPDdeKjE/r10V8lSS2Ht1RRVpF+TvhZxZnFCjg/QPm782UJtiigW4ByNuc4PJeP5Bfpp+LjxZIk7xDvSp8X7Ds9lnrxsWIVWAtcVqQHAMAdEsLCFBccrLXHj2tHTo4kydtk0rHiYvvQK0eKijSgeXOlFRXpraNH9X1enicjSzo91vrvRUUK8fFRiLe3jhefbq/Le364sFCSZDMMWQsKKKADQDkonqPK0tPftD8/duwtHTv2lv11RsYqF5/ddZOTAgCcJy8vT2az4/RTFotFNpvNQ4kar6DYIJ3ccdL+OmNVhjJWZTi8doXcH3P1TeQ3ilkUo7CEMJecAwAAd4jw89P4iKp14BoUHKyLd+50caKq+eD336u1/aGiIkV+840WxcQoIYy2GwDOdPbkykC5Cgqs2rt3jIfObnLZ5KQAAOcaNmyYnnzySX344Yc6cOCAVq9erTlz5uiGG27wdLRGp8BaoJR7UzxzckNKHpesAmuBZ84PAICbxQYFKT401GFZfGhomWV1lSFpXHKyrAW03QBwJnqeo0ry8z30x7ekrl3fVmjoLR47PwCg6l5++WVNnz5dEyZM0NGjRxUeHq5x48ZpxowZno7W6OSn5Hs2QImUn5rP8C0AgEZjadeumhgers3Z2ep7xuSdE8PDteLoUeWcOqVO/xvy5VhRkXzMZhXZbGrl4yNJ+iU/X78WFOjzrCyP5C+RlJqfz/AtAHAGiueoEn//aA+d2aygoN4eOjcAoLqaNWumuXPnau7cuZ6O0uj5R/t7NoBF8o/ycAYAANwsNijIXjSvbFllrAUFeuPIESXn5enCJk20Jz9fmcXF6hoQoD35+WpusahrQIDWZWbqo2oO0VIZi6Qof9puADgTxXNUiZ9fhGJiFis5ebQbz2pSTMxChmsBAKAG/CL8FLM4Rsmjk91/crMUsyCGXucAANRAhJ+fpnXocM7tJrdvr8S0NI1Orn1bb5a0ICaGXucAcBaK56iysLAEBQfH6ciRN5SXl6wmTS5Ufv4eFRdnKiCgq/Lz98hiaa6AgK7Kydnq8Fzylp9fpIqLT09O5u3dssLnNluRAgK6KCRkKIVzAABqISwhTMFxwTryxhHlJeepyYVNlL8nX8WZxQroGqD8PfmyNLcooGuAcrbmODyXt+QX6afijGJJkndL73M+9+/kL/8ofwX1DqJwDgB1xMaNG/Xcc89px44dSktL0+rVq3X99dfb1xuGoZkzZ2rRokXKzMxU3759NW/ePEVHe+rbx6iOhLAwxQUHa+3x49qblycfs1kZxafb5Zbe3ud83snfX1H+/uodFEThHADKQfEc1eLnF6EOHaZ5OgYAAKgivwg/dZjWwdMxAAAekpubq+7du2vUqFG68cYby6x/9tln9a9//UvLli1Tx44dNX36dMXFxemnn36SH8XUeiHCz0/jI+h4BgCuQPEcAAAAAIAGavDgwRo8eHC56wzD0Ny5c/XII49o+PDhkqR///vfCg0N1Xvvvafbb7/dnVEBAKhzzJ4OAAAAAAAA3G///v06cuSIBg0aZF8WFBSkSy65RFu3bq1wv8LCQmVnZzs8AABoiOp08bykpETTp09Xx44d5e/vr86dO+vxxx+XYRiejgYAAAAAQL125MgRSVJoaKjD8tDQUPu68syePVtBQUH2R7t27VyaEwAAT6nTxfNnnnlG8+bN0yuvvKI9e/bomWee0bPPPquXX37Z09EAAAAAAGiUpk2bpqysLPvj0KFDno4EAIBL1Okxz7ds2aLhw4dryJAhkqQOHTpoxYoV2rZtm4eTAQAAAABQv7Vp00aSlJ6errCwMPvy9PR09ejRo8L9fH195evr6+p4AAB4XJ0unvfp00cLFy7U3r171aVLF3333Xf6+uuvNWfOnAr3KSwsVGFhof11VlaWJDEGGwDArUrbHYYaq77Sa0bbDQBwp8bYdnfs2FFt2rTRunXr7MXy7Oxs/fe//9W9995b5ePQdgMAPMEdbXedLp5PnTpV2dnZOu+882SxWFRSUqInn3xSd911V4X7zJ49W7NmzSqznDHYAACekJOTo6CgIE/HqFdycnIk0XYDADyjobXdJ0+eVGpqqv31/v37tWvXLrVo0UKRkZGaNGmSnnjiCUVHR6tjx46aPn26wsPDdf3111f5HLTdAABPcmXbbTLq8Mfqb731lqZMmaLnnntO559/vnbt2qVJkyZpzpw5io+PL3efs3ue22w2nThxQi1btpTJZKpxluzsbLVr106HDh1SYGBgjY/jbOSqPrJVH7mqp67mkuputrqaS6p5NsMwlJOTo/DwcJnNdXqKkTrHZrPp8OHDatasGW23G9XVXBLZaoJc1VNXc0l1N1tdzSXRdp9tw4YNGjhwYJnl8fHxWrp0qQzD0MyZM7Vw4UJlZmaqX79+eu2119SlS5cqn4O22zPqai6JbDVBruqpq7mkuputruaS6nbbXad7nk+ZMkVTp07V7bffLkm64IIL9Ouvv2r27NkVFs/LG3utefPmTssUGBhY524wiVw1QbbqI1f11NVcUt3NVldzSTXL1pB6rbmT2WxWRESE045XV+8rclUf2aqPXNVTV3NJdTdbXc0l0XaXGjBgQKVfZzeZTHrsscf02GOP1fgctN2eVVdzSWSrCXJVT13NJdXdbHU1l1Q32+46/XF6Xl5emU8NLBaLbDabhxIBAAAAAAAAABqDOt3zfNiwYXryyScVGRmp888/Xzt37tScOXM0atQoT0cDAAAAAAAAADRgdbp4/vLLL2v69OmaMGGCjh49qvDwcI0bN04zZsxwexZfX1/NnDmzzJAwnkau6iNb9ZGreupqLqnuZquruaS6nQ2Vq6s/O3JVH9mqj1zVU1dzSXU3W13NJdXtbKhcXf3Zkav6yFZ95KqeuppLqrvZ6mouqW5nq9MThgIAAAAAAAAA4Al1esxzAAAAAAAAAAA8geI5AAAAAAAAAABnoXgOAAAAAAAAAMBZKJ4DAAAAAAAAAHAWiucAAAAAAAAAAJylXhfPZ8+erdjYWDVr1kytW7fW9ddfr+TkZIdtCgoKNHHiRLVs2VJNmzbVTTfdpPT0dPv67777TnfccYfatWsnf39/de3aVS+99JLDMVatWqWrrrpKrVq1UmBgoHr37q1PP/20SrmaNGkiPz8/+fr6atCgQUpJSXHIFRAQIIvFIovFosDAQJfmOjObr6+v/by9e/e25yrvmjVv3lwmk0m7du3y+DW7/vrrZTKZyn0sX77cZdcsKipKXl5eMpvNMplMeu+99xy2KSgo0Pjx4+Xn5yeTySQvLy8NGTLEfq9V5Zp9/fXX6tu3r1q2bCl/f3+dd955evHFF2t9zWp7n7kyV+k9dsMNN+j888+332euyHVmtsru/88++6zCeywpKcml18zf318+Pj7y8fFx+Dd39jXz9vaWj4+PmjRpYv+dVpVcZ9q8ebO8vLzUo0ePWl+zgoICXXrppfL29pbJZJK3t3e1f89WN5u77rOaXDNJMgxDM2bMUFhYmPz9/R1ySdKGDRsqvc8aMtpu2m7abtpu2m7abtru+oW2m7abtpu2m7abtrtRt91GPRYXF2csWbLE+PHHH41du3YZ1157rREZGWmcPHnSvs348eONdu3aGevWrTO2b99uXHrppUafPn3s6xMTE4377rvP2LBhg7Fv3z7jjTfeMPz9/Y2XX37Zvs39999vPPPMM8a2bduMvXv3GtOmTTO8vb2Nb7/9ttJcDzzwgNG0aVOjV69eRlhYmHHttdcaHTt2NPLz8+257r77buOBBx4wwsLCDIvF4tJcpdluvvlmo2nTpsaLL75oXHbZZYa/v7/Rvn17Iz8/v8w1u/32243mzZsbkoydO3fWiWv27rvvGp988onRq1cvIzY21hg9erTRsWNHY/HixS67ZmPGjDEmTpxozJgxw5BktGnTpsx91rRpU6NVq1bGvHnzjAsuuMBo2rSp/V6ryjX79ttvjTfffNP48ccfjf379xtvvPGGERAQYCxYsKDW16w295krc5X+u2zTpo3DfeaKXKXZznX/jxkzxggPD3e4z1q3bm107NjRsNlsLr1mTz31lHHvvfcaF1xwgSHJ2LJli8M91q5dO2PYsGFGaGio0bVrV+PCCy+0/06rSq5Sv//+u9GpUyfj6quvNrp3717h9arqNRs/frwRGBho3HvvvcZdd91lWCyWav+erW42d91nNblmhmEYTz/9tBEUFGS89957xnfffWdcd9119lyGYRiFhYVGWlqaw6P0d5nNZjvn8esz2m7abtpu2m7abtpu2u76hbabtpu2m7abtpu2uzG33fW6eH62o0ePGpKMr776yjAMw8jMzDS8vb2Nd999177Nnj17DEnG1q1bKzzOhAkTjIEDB1Z6rm7duhmzZs2qcL3NZjPatGljPPfcc/ZcH374oeHr62skJiaWyfXUU0+5PZdh/HHNvL29jRUrVjhcs48++sg477zzjDVr1hiSjGXLlrktW1WuWenPsnnz5sZjjz3mslxn2r9/vyGp3PvMYrHY85Vmq+xnWpVsN9xwg/GXv/ylwvWeus+cmeujjz4yOnbsaL9epf9ZdHUuw6j8/i/1/fffG5KMMWPGVHhcZ2Q70/bt2w1JxuLFiw3D+OMeW7ZsmT1f6T22YsWKCn+mFeW67bbbjEceecSYOXPmORuk6l6zJUuWGE2bNq3xfVbTbK6+z2pzzQzj9M/Q19fXWLFiRbn7FBUVGa1atarwd1lDRttN2+2KXGei7XZ+Ltrusmi7absbE9pu2m5X5DoTbbfzc9F2l0XbTdtdVfV62JazZWVlSZJatGghSdqxY4eKi4s1aNAg+zbnnXeeIiMjtXXr1kqPU3qM8thsNuXk5FS6zf79+3XkyBENGjTInisyMlKXXHKJ1q5dWyZXWFiYTCaTW3OVHlOSLrzwQm3dutV+zS688EKNGTNGb7zxhv70pz9Jkr7//nu3ZavKNTvvvPMUEhKirKwsjRw50mW5KnL2fVZSUmLPV3qfNW/evMKf6bmy7dy5U1u2bFH//v0r3MYT95kzc6Wnp2vMmDF65513FB4eXuHxXJGr9JhS2fv/zGu2d+9eSaevnSuznSknJ0eSFBQUJOmPe6x58+b2fKX3WFpaWoW/08rLtWTJEv3yyy+aOXNmlbLU5JpZLJYa/Z6tTTZX3me1vWbS6Z/lJZdcUuE1+eCDD5SRkVHh77KGjLabttsVuSpC203b7cxsZ6Ltpu1uTGi7abtdkasitN203c7MdibabtruqvKq1tZ1mM1m06RJk9S3b197o3PkyBH5+PioefPmDtuGhobqyJEj5R5ny5Ytevvtt/Xhhx9WeK7nn39eJ0+e1K233lrhNqXHb9WqlcaNG2fPFRoaqoMHD5aby2w2uy1XaGiowzULDw/XkSNH7Nfs/vvv1/jx43XRRRfpwIEDkqSMjAy3ZKvONSsuLlaHDh0UERHhslxnstlskqQePXo43Gel47KdmS80NFRFRUXl/kwryxYREaFjx47p1KlTevTRRzV69OgK87jzPnN2rqCgIF177bX2+ywkJESHDx92S65z3f9nXrPExEQFBQWpoKDApdlK2Ww2Pf7445KkqKgoe24fHx+dPHnSIV/p77LyfqeVlyslJUVTp07Vpk2b5OVVtV//NblmZ2Yrj7OzufI+q+01O1Nl1yQxMVFxcXHl/i5ryGi7abtdletMtN203a7KVoq2m7a7MaHtpu12Va4z0XbTdrsqWynabtru6mgwPc8nTpyoH3/8UW+99VaNj/Hjjz9q+PDhmjlzpq6++upyt3nzzTc1a9YsvfPOO2rdurUkafny5WratKn9sWnTJvv2//znP+tkLqnia1ZSUqKcnBxNmzbNI9mqes2sVquysrJ04YUXuiWXJM2YMUOS9PTTT1earTLnyrZp0yZt375d8+fP19y5c7VixYpzZnPHfebsXC+//HKV7jNX5JKq9jvDarXq008/VatWrdyWbeLEiWUmYKqu8nKVlJTozjvv1KxZs9SlS5dy93PGNfNENlfdZ864ZlVRep8lJCRUe9/6jrabttvVuSTabtpu12ej7abtbkxou2m7XZ1Lou2m7XZ9Ntpu2u5qqdYgL3XUxIkTjYiICOOXX35xWL5u3TpDkvH77787LI+MjDTmzJnjsGz37t1G69atjX/+858VnmfFihWGv7+/sXbtWofl2dnZRkpKiv2Rl5dn7Nu3z5BkhIaGOuS6/PLLjRtuuKFMriVLlhgmk8ltuW677TaHa3b55Zcb9913n/2amUwmw2Kx2B+ly+655546c80ee+wxw2w2O4xv5IpcpSZOnGiEhYWVGbep9JqdnS8yMtJo3ry5w8+0KtnO9PjjjxtdunRx2jWrzX3m7FzXXnutYTabHe4xSYbFYrHfZ67Kda77v/SaPfbYY0arVq1q/DujOtkM44/fZRs3bnS4z0pzvf/++w75SnOdma+iXL///rv9+pY+TCaTfdm6deuccs2WLFliBAUFVeua1Tabq+6z2uY6e3y30mt2ttL7rKioqML7pyGi7abtduU1K0Xb7dxctN203c7KRttdP9F203a78pqVou12bi7abtpuZ2VrzG13vS6e22w2Y+LEiUZ4eLixd+/eMutLB9RfuXKlfdnPP/9s6KwB9X/88UejdevWxpQpUyo815tvvmn4+fkZ7733XpVyTZgwwTCbzcZDDz1kX56VleUwoP6ZucqbUMLZuQzDMEpKSoyAgAAjMDDQfs1Kc505CcGcOXOMH374wfjhhx+MxYsXG5KMp556yjh06JBLslX3mtlsNqNt27ZuuWZn3mdffvllmX+cZ05cUpqv9D47M19Vsp1t1qxZRvv27SvM5a77zBW55s2bZ7/HPvjgA/v1WrlypXHo0CGn5zKMqt//K1euNGw2m9GxY0dj5MiRbrlmZ/4uK50gp/Q+O3vikpUrV9rvsbfeesuer7JcJSUl9utd+rj33nuNmJgY44cffnCYxb6m18wwKp64xNnZ3HGf1fSalU5c8vzzz5fJdfbEJaX32d///vdyj9UQ0XbTdtN203ZXNZdh0HbTdtN21wW03bTdtN203VXNZRi03bTdDa/trtfF83vvvdcICgoyNmzYYKSlpdkfZ35qOX78eCMyMtL48ssvje3btxu9e/c2evfubV//ww8/GK1atTL+8pe/OBzj6NGj9m2WL19ueHl5Ga+++qrDNpmZmZXmGjt2rBEYGGgsXbrU+PLLL42hQ4caHTt2NPLz8+25VqxYYSxfvtxo166dYTabjZ07dxo7d+40/vvf/zo9V2k2Pz8/o2nTpvZccXFxRvv27Y38/Pxyr9mf//xnh18onr5mX375pfHaa68ZkowePXq49GdZmi0wMNBYtGiR8cYbbxiSjPnz5xtbt2410tLS7NesadOmRuvWrY358+cbF154odG0aVP7vVaVbK+88orxwQcfGHv37jX27t1rLF682GjWrJnx8MMP1/qa1eY+c2WuM/9dnnmfueJ6lWar6v3//PPP2++x6v7OqOk1++CDD4zPP//cfp/9+9//Nnbu3GmkpaXZcw0bNsxo06aN0a1bN+PCCy+0/06rSq6zVWUG66pes7Zt2xoLFy40xo0bZ5jNZuPCCy80du7caeTk5Lgkm7vus5pcM8MwjKefftpo3ry58f777xvff/+9MXz4cHuuM33xxReGJGPPnj3nPGZDQdtN203bTdtN203bTdtdv9B203bTdtN203bTdjfmtrteF89LP8k4+7FkyRL7Nvn5+caECROM4OBgIyAgwLjhhhvsv3gN4/QPpLxjnPlJVf/+/cvdJj4+vlq5unbtaiQnJzvk8vHxqfDYzs5VWbbZs2dXeM3i4uIcGnFPX7Pg4GDDYrEYLVq0cPnPsrJskoyZM2fas40bN87w9fU1pNNfLRk8eLA9X1Wy/etf/zLOP/98+6eNPXv2NF577TWjpKSk1tesNveZK3Od+e9y27Zt9vvMFdersmzl3f8+Pj6G2Wyu0e8MZ12zM++zM6+Zl5eX4e3tbfj7+9vzVSXX2arSIFX1msXExJS73fr1612SzV33WU2umWGc/mR7+vTpRmhoqOHr62tceeWV9lxnuuOOO4w+ffqc83gNSUU/O9ru8nNVlo22u/rXrPR3amk22u6a/Sxpu2m7a5LNXfdZTa6ZYdB2V6ainx1td/m5KstG2139a1b6O7U0G213zX6WtN203TXJ5q77rCbXzDDc13abDMMwBAAAAAAAAAAA7MyeDgAAAAAAAAAAQF1D8RwAAAAAAAAAgLNQPAcAAAAAAAAA4CwUzwEAAAAAAAAAOAvFcwAAAAAAAAAAzkLxHAAAAAAAAACAs1A8BwAAAAAAAADgLBTPAQAAAAAAAAA4C8VzAJXasGGDTCaTMjMzPR0FAABUAW03AAD1C203UHdRPAcakPnz56tZs2Y6deqUfdnJkyfl7e2tAQMGOGxb2jjv27evVuc8cOCATCaTdu3aVavjAADQGNF2AwBQv9B2A40LxXOgARk4cKBOnjyp7du325dt2rRJbdq00X//+18VFBTYl69fv16RkZHq3LmzJ6ICAADRdgMAUN/QdgONC8VzoAGJiYlRWFiYNmzYYF+2YcMGDR8+XB07dtQ333zjsHzgwIF64403dNFFF6lZs2Zq06aN7rzzTh09erTCc+Tl5Wnw4MHq27evMjMz1bFjR0lSz549ZTKZ7J+0DxgwQJMmTXLY9/rrr9eIESOc9XYBAKj3aLsBAKhfaLuBxoXiOdDADBw4UOvXr7e/Xr9+vQYMGKD+/fvbl+fn5+u///2vBg4cqOLiYj3++OP67rvv9N577+nAgQMVNrSZmZm66qqrZLPZ9Pnnn6t58+batm2bJOmLL75QWlqaVq1a5fL3CABAQ0LbDQBA/ULbDTQeXp4OAMC5Bg4cqEmTJunUqVPKz8/Xzp071b9/fxUXF2v+/PmSpK1bt6qwsFADBw5UZGSkfd9OnTrpX//6l2JjY3Xy5Ek1bdrUvu7IkSO67bbbFB0drTfffFM+Pj6SpFatWkmSWrZsqTZt2rjxnQIA0DDQdgMAUL/QdgONBz3PgQZmwIABys3NVVJSkjZt2qQuXbqoVatW6t+/v338tQ0bNqhTp06KjIzUjh07NGzYMEVGRqpZs2bq37+/JOngwYMOx73qqqsUFRWlt99+296AAwCA2qPtBgCgfqHtBhoPiudAAxMVFaWIiAitX79e69evtzfK4eHhateunbZs2aL169friiuuUG5uruLi4hQYGKjly5crKSlJq1evliQVFRU5HHfIkCHauHGjfvrppyrlMJvNMgzDYVlxcbET3iEAAA0LbTcAAPULbTfQeFA8BxqggQMHasOGDdqwYYN9IhFJuvzyy/Xxxx9r27ZtGjhwoH7++WdlZGTo6aef1mWXXabzzjuvwklLnn76acXHx+vKK690aMhLPw0vKSlx2L5Vq1ZKS0uzvy4pKdGPP/7oxHcJAEDDQdsNAED9QtsNNA4Uz4EGaODAgfr666+1a9cu+yfgktS/f38tWLBARUVF9nHXfHx89PLLL+uXX37RBx98oMcff7zC4z7//PO66667dMUVV+jnn3+WJLVu3Vr+/v765JNPlJ6erqysLEnSFVdcoQ8//FAffvihfv75Z917773KzMx06fsGAKC+ou0GAKB+oe0GGgeK50ADNHDgQOXn5ysqKkqhoaH25f3791dOTo5iYmIUFhamVq1aaenSpXr33XfVrVs3Pf3003r++ecrPfaLL76oW2+9VVdccYX27t0rLy8v/etf/9KCBQsUHh6u4cOHS5JGjRql+Ph43XPPPerfv786deqkgQMHuvR9AwBQX9F2AwBQv9B2A42DyTh7cCQAAAAAAAAAABo5ep4DAAAAAAAAAHAWiucAAAAAAAAAAJyF4jkAAAAAAAAAAGeheA4AAAAAAAAAwFkongMAAAAAAAAAcBaK5wAAAAAAAAAAnIXiOQAAAAAAAAAAZ6F4DgAAAAAAAADAWSieAwAAAAAAAABwFornAAAAAAAAAACcheI5AAAAAAAAAABnoXgOAAAAAAAAAMBZKJ4DAAAAAAAAAHAWiucAAAAAAAAAAJyF4jkAAAAAAAAAAGeheA4AAAAAAAAAwFkongMAAAAAAAAAcBaK53CqTz75RD169JCfn59MJpMyMzM1YsQIdejQwb7NgQMHZDKZ9Pzzz3suKBq8s+87STKZTHr00Uc9kgcAAAAAAAD1C8XzBmz//v3661//qi5duiggIEABAQHq1q2bJk6cqO+//97p58vIyNCtt94qf39/vfrqq3rjjTfUpEkTp5/HZDLpr3/9a7nrli5dKpPJpO3btzv9vO7QoUMHmUwm+8PPz0/R0dGaMmWKTpw44el41bZhwwaZTCatXLnSYXlRUZGGDh0qs9ms119/3UPppC1btujRRx9VZmam289ts9n073//W5dccolatGihZs2aqUuXLrrnnnv0zTffuD2Ps3To0EFDhw51WFbZv1kAAAAAAIC6ysvTAeAaa9eu1W233SYvLy/ddddd6t69u8xms37++WetWrVK8+bN0/79+9W+fXunnTMpKUk5OTl6/PHHNWjQIPvyRYsWyWazOe08DV2PHj3097//XZJUUFCgHTt2aO7cufrqq6+0bds2D6erveLiYt1888366KOPtGjRIo0aNcpt587Pz5eX1x+/9rZs2aJZs2ZpxIgRat68udtySNJ9992nV199VcOHD9ddd90lLy8vJScn6+OPP1anTp106aWXujUPAAAAAAAAHFE8b4D27dun22+/Xe3bt9e6desUFhbmsP6ZZ57Ra6+9JrO58i8e5ObmVqvn+NGjRyWpTBHS29u7yseoa6p7DZyhbdu2+stf/mJ/PXr0aDVt2lTPP/+8UlJSFB0dXetzeOJ9SacL57feeqvWrl2rBQsWKCEhwa3n9/Pzc+v5KpKenq7XXntNY8aM0cKFCx3WzZ07V8eOHfNQsnM7deqUbDabfHx8PB0FAAAAAADApRi2pQF69tlnlZubqyVLlpQpnEuSl5eX7rvvPrVr186+bMSIEWratKn27duna6+9Vs2aNdNdd90lSdq0aZNuueUWRUZGytfXV+3atdMDDzyg/Px8+/4DBgxQfHy8JCk2NlYmk0kjRoywH/vssafPZhiGxo4dKx8fH61ataqWV8DR999/rxEjRqhTp07y8/NTmzZtNGrUKGVkZDhs9+ijj8pkMumnn37SnXfeqeDgYPXr10/S6SE2Hn30UYWHhysgIEADBw7UTz/9pA4dOtjfpySdOHFCDz74oC644AI1bdpUgYGBGjx4sL777rtavYc2bdpIkkOvaUn6+eefdfPNN6tFixby8/PTRRddpA8++MBhm9KhbL766itNmDBBrVu3VkREhCTp119/1YQJExQTEyN/f3+1bNlSt9xyiw4cOOBwjOLiYs2aNUvR0dHy8/NTy5Yt1a9fP33++edVfg+nTp3S7bffrvfff1/z5s3TmDFj7OtKr/3ZSrOfmef999/XkCFDFB4eLl9fX3Xu3FmPP/64SkpKzpnhzDHPH330UU2ZMkWS1LFjR/tQOaXnWrJkia644gq1bt1avr6+6tatm+bNm1fmmNu3b1dcXJxCQkLk7++vjh07nrM3/f79+2UYhvr27VtuxtatW9tfV+falA6Z8tlnn9nnHujWrVu5/6YyMzM1adIktWvXTr6+voqKitIzzzzj8C2RM+cnmDt3rjp37ixfX1/99NNPlb4/AAAAAACAhoCe5w3Q2rVrFRUVpUsuuaRa+506dUpxcXHq16+fnn/+eQUEBEiS3n33XeXl5enee+9Vy5YttW3bNr388suyWq169913JUkPP/ywYmJitHDhQj322GPq2LGjOnfuXKXzlpSUaNSoUXr77be1evVqDRky5Jz7FBQU6Pjx42WWnzx5ssyyzz//XL/88otGjhypNm3aaPfu3Vq4cKF2796tb775pkxh8pZbblF0dLSeeuopGYYhSZo2bZqeffZZDRs2THFxcfruu+8UFxengoICh31/+eUXvffee7rlllvUsWNHpaena8GCBerfv79++uknhYeHn/O9FRcX299bQUGBdu7cqTlz5ujyyy9Xx44d7dvt3r1bffv2Vdu2bTV16lQ1adJE77zzjq6//nr95z//0Q033OBw3AkTJqhVq1aaMWOGcnNzJZ0eamfLli26/fbbFRERoQMHDmjevHkaMGCAfvrpJ/s98Oijj2r27NkaPXq0Lr74YmVnZ2v79u369ttvddVVV53zPZ06dUp33HGHVq9erVdffVXjxo075z4VWbp0qZo2barJkyeradOm+vLLLzVjxgxlZ2frueeeq/JxbrzxRu3du1crVqzQiy++qJCQEElSq1atJEnz5s3T+eefr+uuu05eXl5as2aNJkyYIJvNpokTJ0o6/W2Lq6++Wq1atdLUqVPVvHlzHThw4JwfAJUOl/Tuu+/qlltusV9nZ0hJSdFtt92m8ePHKz4+XkuWLNEtt9yiTz75xP6zysvLU//+/fXbb79p3LhxioyM1JYtWzRt2jSlpaVp7ty5DsdcsmSJCgoKNHbsWPn6+qpFixZOywsAAAAAAFBnGWhQsrKyDEnG9ddfX2bd77//bhw7dsz+yMvLs6+Lj483JBlTp04ts9+Z25WaPXu2YTKZjF9//dW+bMmSJYYkIykpyWHb+Ph4o3379vbX+/fvNyQZzz33nFFcXGzcdttthr+/v/Hpp59W6T1KOufjzAzl5V+xYoUhydi4caN92cyZMw1Jxh133OGw7ZEjRwwvL68y1/TRRx81JBnx8fH2ZQUFBUZJSYnDdvv37zd8fX2Nxx577JzvrX379uW+n759+xrHjx932PbKK680LrjgAqOgoMC+zGazGX369DGio6Pty0p/Lv369TNOnTrlcIzyrs3WrVsNSca///1v+7Lu3bsbQ4YMOWf+s61fv96QZH9fr776arnblV77s5Vm379/f6WZx40bZwQEBDhci7PvO8M4fe/MnDnT/vq5554rc/zKzhMXF2d06tTJ/nr16tXl3vNVcc899xiSjODgYOOGG24wnn/+eWPPnj1ltqvOtSm9zv/5z3/sy7KysoywsDCjZ8+e9mWPP/640aRJE2Pv3r0Ox5w6daphsViMgwcPGobxx7/VwMBA4+jRo1V6X+3bty9zr0gyJk6cWKX9AQAAAAAA6gqGbWlgsrOzJUlNmzYts27AgAFq1aqV/fHqq6+W2ebee+8ts8zf39/+PDc3V8ePH1efPn1kGIZ27txZ46xFRUW65ZZbtHbtWn300Ue6+uqrq7zv8OHD9fnnn5d5lA7DUVH+0h7rpZMxfvvtt2W2Hz9+vMPrdevW6dSpU5owYYLD8r/97W9l9vX19bWPJV9SUqKMjAw1bdpUMTEx5Z6rPJdccon9/axdu1ZPPvmkdu/ereuuu84+VM6JEyf05Zdf6tZbb1VOTo6OHz+u48ePKyMjQ3FxcUpJSdFvv/3mcNwxY8bIYrFUeG2Ki4uVkZGhqKgoNW/e3CFv8+bNtXv3bqWkpFTpPZwtPT1dXl5eDj3na+rMzKXv/bLLLlNeXp5+/vnnWh+/vPNkZWXp+PHj6t+/v3755RdlZWVJ+mN8/7Vr16q4uLhax1+yZIleeeUVdezYUatXr9aDDz6orl276sorryzzs6uO8PBwh28dBAYG6p577tHOnTt15MgRSad7vF922WUKDg623zvHjx/XoEGDVFJSoo0bNzoc86abbrL3yAcAAAAAAGgsGLalgWnWrJmk8ocvWbBggXJycpSenu4wIWUpLy8v+1jYZzp48KBmzJihDz74QL///rvDutIiYk3Mnj1bJ0+e1Mcff6wBAwZUa9+IiAgNGjSozHKr1Vpm2YkTJzRr1iy99dZb9klNS5WX/+wC76+//ipJioqKcljeokULBQcHOyyz2Wx66aWX9Nprr2n//v0O43C3bNnyHO/qtJCQEIf3NmTIEMXExOjmm2/W4sWL9be//U2pqakyDEPTp0/X9OnTyz3O0aNH1bZt2wrflyTl5+dr9uzZWrJkiX777Tf7MDWS47V57LHHNHz4cHXp0kV/+tOfdM011+juu+/WhRdeWKX39Oyzz2ru3Lm6+eab9dlnn5U71ndV7d69W4888oi+/PJL+4dF5WWurc2bN2vmzJnaunWr8vLyypwnKChI/fv310033aRZs2bpxRdf1IABA3T99dfrzjvvlK+vb6XHN5vNmjhxoiZOnKiMjAxt3rxZ8+fP18cff6zbb79dmzZtqlHuqKioMkMRdenSRdLpMczbtGmjlJQUff/99xUWxM/+d+KMDz0AAAAAAADqG4rnDUxQUJDCwsL0448/lllXOgb62ZNBljqz13SpkpISXXXVVTpx4oQeeughnXfeeWrSpIl+++03jRgxwmFyweqKi4vTJ598omeffVYDBgyQn59fjY9VmVtvvVVbtmzRlClT1KNHDzVt2lQ2m03XXHNNufnP7HFcXU899ZSmT5+uUaNG6fHHH1eLFi1kNps1adKkWl2rK6+8UpK0ceNG/e1vf7Mf68EHH1RcXFy5+5xd7C/vff3tb3/TkiVLNGnSJPXu3VtBQUEymUy6/fbbHfJefvnl2rdvn95//3199tlnWrx4sV588UXNnz9fo0ePPmf+sLAwff755+rXr5+GDBmir776St27d7evL29CTEllJgHNzMxU//79FRgYqMcee0ydO3eWn5+fvv32Wz300EO1usZn2rdvn6688kqdd955mjNnjtq1aycfHx999NFHevHFF+3nMZlMWrlypb755hutWbNGn376qUaNGqUXXnhB33zzTbnfAClPy5Ytdd111+m6667TgAED9NVXX+nXX39V+/btq3xtqsNms+mqq67SP/7xj3LXlxbbS9Xm3wQAAAAAAEB9RfG8ARoyZIgWL16sbdu26eKLL67VsX744Qft3btXy5Yt0z333GNf/vnnn9c2pi699FKNHz9eQ4cO1S233KLVq1fLy8u5t+Tvv/+udevWadasWZoxY4Z9eXWGHymd3DE1NdWhB25GRkaZnvgrV67UwIEDlZiY6LA8MzPTPiFlTZw6dUrSH98o6NSpkyTJ29u73B74VbVy5UrFx8frhRdesC8rKChQZmZmmW1btGihkSNHauTIkTp58qQuv/xyPfroo1Uqnpdm/vTTT9W/f3/FxcVp06ZNio6OliR7D/7MzEz7UCjSH73+S23YsEEZGRlatWqVLr/8cvvy/fv3V/UtO6ioML1mzRoVFhbqgw8+UGRkpH35+vXry93+0ksv1aWXXqonn3xSb775pu666y699dZbVb42Z7rooov01VdfKS0tTe3bt6/ytSlV+q2EM9/b3r17JUkdOnSQJHXu3FknT56s1b0DAAAAAADQ0DHmeQP0j3/8QwEBARo1apTS09PLrD9zaI5zKR0j+8x9DMPQSy+9VPugkgYNGqS33npLn3zyie6++26n9RwuVV5+SZo7d26Vj3HllVfKy8tL8+bNc1j+yiuvlHu+s8/17rvv1moMa+l0MVeSvbd269atNWDAAC1YsEBpaWlltj927FiVjlte3pdffrlMr+aMjAyH102bNlVUVJQKCwur/B4k6YILLtCHH36okydP6qqrrrJfl86dO0uSw1jbubm5WrZsWZm8kuPPs6ioSK+99lq1cpRq0qSJJJX5sKC882RlZWnJkiUO2/3+++9lrl+PHj0kqdJrc+TIEf30009llhcVFWndunUym832bw5U9dqUOnz4sFavXm1/nZ2drX//+9/q0aOH2rRpI+n0tzG2bt2qTz/9tMz+mZmZ9g9rAAAAAAAAGjN6njdA0dHRevPNN3XHHXcoJiZGd911l7p37y7DMLR//369+eabMpvN5Y5vfrbzzjtPnTt31oMPPqjffvtNgYGB+s9//lOmx3VtXH/99VqyZInuueceBQYGasGCBU47dmBgoC6//HI9++yzKi4uVtu2bfXZZ59Vq6dyaGio7r//fr3wwgu67rrrdM011+i7777Txx9/rJCQEIcevkOHDtVjjz2mkSNHqk+fPvrhhx+0fPlye0/xqvjtt9/0f//3f5JOF1O/++47LViwQCEhIQ6TlL766qvq16+fLrjgAo0ZM0adOnVSenq6tm7dKqvVqu++++6c5xo6dKjeeOMNBQUFqVu3btq6dau++OKLMuOzd+vWTQMGDFCvXr3UokULbd++XStXrtRf//rXKr+vUr1799aqVas0bNgwXXXVVdq0aZOuvvpqRUZGKiEhQVOmTJHFYtHrr7+uVq1a6eDBg/Z9+/Tpo+DgYMXHx+u+++6TyWTSG2+8Ua0PhM7Uq1cvSdLDDz+s22+/Xd7e3ho2bJiuvvpq+fj4aNiwYRo3bpxOnjypRYsWqXXr1g4fVixbtkyvvfaabrjhBnXu3Fk5OTlatGiRAgMDde2111Z4XqvVqosvvlhXXHGFrrzySrVp00ZHjx7VihUr9N1332nSpEn2bypU9dqU6tKlixISEpSUlKTQ0FC9/vrrSk9Pdyj8T5kyRR988IGGDh2qESNGqFevXsrNzdUPP/yglStX6sCBA7X6pgQAAAAAAEBDQPG8gRo+fLh++OEHvfDCC/rss8/0+uuvy2QyqX379hoyZIjGjx/vMOZ0Rby9vbVmzRrdd999mj17tvz8/HTDDTfor3/9a5X2r6q//OUvysnJ0YQJExQYGKjnnnvOacd+88039be//U2vvvqqDMPQ1VdfrY8//ljh4eFVPsYzzzyjgIAALVq0SF988YV69+6tzz77TP369XMYq/2f//yncnNz9eabb+rtt9/Wn//8Z3344YeaOnVqlc+1a9cu3X333ZJOTyoZEhKiG2+8UY8//rjDBKDdunXT9u3bNWvWLC1dulQZGRlq3bq1evbs6TBETWVeeuklWSwWLV++XAUFBerbt6+++OKLMuOo33ffffrggw/02WefqbCwUO3bt9cTTzyhKVOmVPl9nenqq6/WG2+8oTvuuEODBw/WunXrtHr1ak2YMEHTp09XmzZtNGnSJAUHB2vkyJH2/Vq2bKm1a9fq73//ux555BEFBwfrL3/5i6688soKx36vTGxsrB5//HHNnz9fn3zyiWw2m/bv36+YmBitXLlSjzzyiB588EG1adNG9957r1q1aqVRo0bZ9+/fv7+2bdumt956S+np6QoKCtLFF1+s5cuXVzrJZkxMjObOnauPPvpIr732mtLT0+Xn56c//elPWrRokRISEuzbent7V+nalIqOjtbLL7+sKVOmKDk5WR07dtTbb7/tcH0CAgL01Vdf6amnntK7776rf//73woMDFSXLl00a9YsBQUFVftaAgAAAAAANDQmo6ZdNoFGLjMzU8HBwXriiSf08MMPezoOoA4dOuhPf/qT1q5d6+koAAAAAAAA9R5jngNVkJ+fX2ZZ6bjpAwYMcG8YAAAAAAAAAC7HsC1AFbz99ttaunSprr32WjVt2lRff/21VqxYoauvvlp9+/b1dDwAAAAAAAAATkbPc6AKLrzwQnl5eenZZ5/VpEmTtGnTJt1///36z3/+4+loAOBSGzdu1LBhwxQeHi6TyaT33nvvnPts2LBBf/7zn+Xr66uoqCgtXbrU5TkBAMBptN0AADgPxXOgCv785z/riy++0PHjx1VUVKRDhw5p7ty5atq0qaejAXYHDhxgvHM4XW5urrp3765XX321Stvv379fQ4YM0cCBA7Vr1y5NmjRJo0eP1qeffuripAAAQKLtBgDAmZgwFAAAVInJZNLq1at1/fXXV7jNQw89pA8//FA//vijfdntt9+uzMxMffLJJ25ICQAAStF2AwBQOw1+zHObzabDhw+rWbNmMplMno4DAGgkDMNQTk6OwsPDZTY3ni96bd26VYMGDXJYFhcXp0mTJlW4T2FhoQoLC+2vbTabTpw4oZYtW9J2AwDchrb7D7TdAID6wB1td4Mvnh8+fFjt2rXzdAwAQCN16NAhRUREeDqG2xw5ckShoaEOy0JDQ5Wdna38/Hz5+/uX2Wf27NmaNWuWuyICAFAp2m7abgBA/eLKtrvBF8+bNWsm6fRFDAwM9HAaAEBjkZ2drXbt2tnbIVRs2rRpmjx5sv11VlaWIiMjabsBAG5F2111tN0AgLrAHW13gy+el35lLDAwkEYcAOB2je2ry23atFF6errDsvT0dAUGBpbbc02SfH195evrW2Y5bTcAwBNou2m7AQD1iyvb7sYzkBsAAHC53r17a926dQ7LPv/8c/Xu3dtDiQAAQGVouwEAqBjFcwAAUKGTJ09q165d2rVrlyRp//792rVrlw4ePCjp9Ne277nnHvv248eP1y+//KJ//OMf+vnnn/Xaa6/pnXfe0QMPPOCJ+AAANDq03QAAOA/FcwAAUKHt27erZ8+e6tmzpyRp8uTJ6tmzp2bMmCFJSktLs/8xLkkdO3bUhx9+qM8//1zdu3fXCy+8oMWLFysuLs4j+QEAaGxouwEAcB6TYRiGp0O4UnZ2toKCgpSVlcXYawAAt6H9qTmuHQDAE2h/ao5rBwDwBHe0P/Q8BwAAAAAAAADgLB4tnm/cuFHDhg1TeHi4TCaT3nvvPYf1JpOp3Mdzzz3nmcAAgHNKSkrSnDlztHbtWq1fv15Wq9XTkQAAAAAAAKrNy5Mnz83NVffu3TVq1CjdeOONZdanpaU5vP7444+VkJCgm266yV0RAQDVMGLECC1btsxhmdls1sKFC5WQkOChVAAAAAAAANXn0eL54MGDNXjw4ArXt2nTxuH1+++/r4EDB6pTp04V7lNYWKjCwkL76+zs7NoHBQCcU1JSUpnCuSTZbDaNGzdOcXFxioiI8EAyAAAAAACA6qs3Y56np6frww8/PGfPxdmzZysoKMj+aNeunZsSAkDjtmnTpgrXlZSUKDU11Y1pAAAAAAAAaqfeFM+XLVumZs2alTu8y5mmTZumrKws++PQoUNuSggAjVdSUpIOHjxY6TZNmjRxUxoAAAAAAIDa8+iwLdXx+uuv66677pKfn1+l2/n6+srX19dNqQAA5Y1zXp7c3Fw3pAEAAAAAAHCOelE837Rpk5KTk/X22297OgoA4AwVjXN+NovFoqioKDckAgAAAAAAcI56MWxLYmKievXqpe7du3s6CgDgDJWNc36mG2+8Ue+8846SkpJcnAgAAAAAAMA5PNrz/OTJkw4TyO3fv1+7du1SixYtFBkZKUnKzs7Wu+++qxdeeMFTMQEAFbjsssuqtN27776rd999V5IUHx+vpUuXujAVAAAAAABA7Xm05/n27dvVs2dP9ezZU5I0efJk9ezZUzNmzLBv89Zbb8kwDN1xxx2eigkAqEBYWFi191m2bBk90AEAAAAAQJ3n0eL5gAEDZBhGmceZPRLHjh2rvLw8BQUFeS4oAKBcKSkp5S6/8MILK92PbxMBAAAAAIC6rl6MeQ4AqJuio6NlMpkcllksFj3wwAOV7vfuu+/KarW6MhoAAAAAAECtUDwHANRYRESEQy9zi8WiBQsWaMSIEerTp0+F+9lsNoc5LwAAAAAAAOoaiucAgBobMWKEvvvuO/vrG264QQkJCZKkzZs3a8mSJeXuZ7FYFBUV5ZaMAAAAAAAANUHxHABQI0lJSVq2bJnDspUrVzpMBjpixAgtXrzYYWgXk8mkBQsWKCIiwm1ZAQAAAAAAqoviOQCgRjZt2lTu8s2bNzu8TkhI0K+//mp/nZSUZO+dDgAAAAAAUFdRPAcA1Mhll11W7vK+ffuWWdauXTs1adJEkhQcHOzSXAAAAAAAAM5A8RwAUCOxsbFlCuXx8fGKjY0td3t/f39JUl5ensuzAQAAAAAA1BbFcwBAjd12222SpB49emjbtm1aunRphdsGBARIkvLz890RDQAAAAAAoFYongMAaiw7O1uSdNFFF1XY47xUac9ziucAAAAAAKA+8PJ0AABA/VVaPA8MDDznthaLRZK0c+dOlZSUKDo6WhERES7NBwAAAAAAUFP0PAcA1FhVi+eJiYn66aefJEmTJk3SFVdcofbt2ysxMdHlGQEAAAAAAGqC4jkAoMaqUjy3Wq0aO3ZsmeU2m03jxo2T1Wp1WT4AAAAAAICaongOAKixqhTPU1JSZLPZyl1XUlKi1NRUl2QDAAAAAACoDYrnAIAaq0rxPDo6WmZz+c2NxWJRVFSUS7IBAAAAAADUBsVzAECNVaV4HhERoYULF9onDD3T7NmzmTQUAAAAAADUSRTPAQA1VtUJQxMSEnTgwAH16dPHYflDDz3EpKEAAAAAAKBOongOAKixqhbPJSktLU1btmxxWGYYhsaOHcukoQAAAAAAoM6heA4AqLHqFM83bdpU7nKbzcakoQAAAAAAoM6heA4AqJHCwkIVFRVJqlrx/LLLLit3udlsZtJQAAAAAABQ51A8BwDUSE5Ojv1506ZNz7l9bGys4uPjHZaZTCYtXLiQSUMBAAAAAECdQ/EcAFAjpUO2NG3aVBaLpUr7LF261GHc8++++04JCQkuyQcAAAAAAFAbFM8BADVSnfHOz9S7d2/5+flJkpo1a+b0XAAAAAAAAM7g0eL5xo0bNWzYMIWHh8tkMum9994rs82ePXt03XXXKSgoSE2aNFFsbKwOHjzo/rAAAAelxfOaFMADAgIkSSkpKU7NBAAAAAAA4CweLZ7n5uaqe/fuevXVV8tdv2/fPvXr10/nnXeeNmzYoO+//17Tp0+391gEAHhOTXueJyYm6sSJE5Kka665RomJiU7PBgAAAAAAUFtenjz54MGDNXjw4ArXP/zww7r22mv17LPP2pd17ty50mMWFhaqsLDQ/rq0uAMAcK7S36+nTp2S1Wqt0qSfVqtVY8eOtb+22WwaN26c4uLimDQUAAAAAADUKXV2zHObzaYPP/xQXbp0UVxcnFq3bq1LLrmk3KFdzjR79mwFBQXZH+3atXNPYABoZD7++GNJ0s6dO9W+ffsq9SBPSUmRzWZzWFZSUqLU1FSXZAQAAAAAAKipOls8P3r0qE6ePKmnn35a11xzjT777DPdcMMNuvHGG/XVV19VuN+0adOUlZVlfxw6dMiNqQGgcbBarVq+fLn9dWkPcqvVWul+0dHRMpsdmx6LxaKoqCiX5AQAAAAAAKipOls8L+2ZOHz4cD3wwAPq0aOHpk6dqqFDh2r+/PkV7ufr66vAwECHBwDAuVJSUmQYhsOyqvQgj4iI0MKFC2UymSRJJpNJCxYsYMiWOu7VV19Vhw4d5Ofnp0suuUTbtm2rdPu5c+cqJiZG/v7+ateunR544AEVFBS4KS0AAKDtBgDAOeps8TwkJEReXl7q1q2bw/KuXbvq4MGDHkoFAJBO9yAvLYCXqmoP8oSEBPsQL127dlVCQoJLMsI53n77bU2ePFkzZ87Ut99+q+7duysuLk5Hjx4td/s333xTU6dO1cyZM7Vnzx4lJibq7bff1j//+U83JwcAoHGi7QYAwHnqbPHcx8dHsbGxSk5Odli+d+9etW/f3kOpAADS6R7ksbGx9tcWi6VaPcj79u0rSTpw4ECZMdBRt8yZM0djxozRyJEj1a1bN82fP18BAQF6/fXXy91+y5Yt6tu3r+6880516NBBV199te64445z9ngDAADOQdsNAIDzeLR4fvLkSe3atUu7du2SJO3fv1+7du2y9yyfMmWK3n77bS1atEipqal65ZVXtGbNGk2YMMGDqQEAktSyZUtJ0kMPPaQDBw5Uqwd5x44d5eXlpby8PP3222+uiohaKioq0o4dOzRo0CD7MrPZrEGDBmnr1q3l7tOnTx/t2LHD/gf3L7/8oo8++kjXXntthecpLCxUdna2wwMAAFQfbTcAAM7l0eL59u3b1bNnT/Xs2VOSNHnyZPXs2VMzZsyQJN1www2aP3++nn32WV1wwQVavHix/vOf/6hfv36ejA0AjZ7VatWePXskSS1atKj2mOXe3t7q3LmzpNNfLT7XRKPwjOPHj6ukpEShoaEOy0NDQ3XkyJFy97nzzjv12GOPqV+/fvaf84ABAyr96vfs2bMVFBRkf7Rr186p7wMAgMaCthsAAOfyaPF8wIABMgyjzGPp0qX2bUaNGqWUlBTl5+dr165dGj58uOcCAwCUmJiodu3a6cCBA5JO9zwfMWJEtY/j5+cn6fS3jNq3b28fBx3124YNG/TUU0/ptdde07fffqtVq1bpww8/1OOPP17hPtOmTVNWVpb9cejQITcmBgCgcaPtBgCgYl6eDgAAqD+sVqtGjx5dZvmyZcs0ceJEh3HQz3Wc77//3v7aZrNp3LhxiouLq3YvdrhOSEiILBaL0tPTHZanp6erTZs25e4zffp03X333fb75IILLlBubq7Gjh2rhx9+WGZz2c/tfX195evr6/w3AABAI0PbDQCAc9XZCUMBAHVPSkpKhes2b95creMYhuGwrKSkRKmpqTXOBufz8fFRr169tG7dOvsym82mdevWqXfv3uXuk5eXV+aPbIvFIkllfuYAAMC5aLsBAHAuep4DAKosOjq6wnV9+/at1nFMJpPDH2QWi0VRUVG1ygfnmzx5suLj43XRRRfp4osv1ty5c5Wbm6uRI0dKku655x61bdtWs2fPliQNGzZMc+bMUc+ePXXJJZcoNTVV06dP17Bhw+x/iAMAANeh7QYAwHkongMAquXsorck3XLLLVUeskWSIiIiNH78eM2bN0/S6cL5ggULGLKlDrrtttt07NgxzZgxQ0eOHFGPHj30ySef2CciO3jwoENvtUceeUQmk0mPPPKIfvvtN7Vq1UrDhg3Tk08+6am3AABAo0LbDQCA85iMBv49rOzsbAUFBSkrK0uBgYGejgMA9UpSUpKWL1+unJwchYSE6IcfftDHH39cZrv169drwIAB1Tr2unXrNGjQIIWGhmrNmjXVKr7XB7Q/Nce1AwB4Au1PzXHtAACe4I72h57nAIByjRgxQsuWLTvndjUdbmXDhg2STk9gdemll2rhwoVKSEio9nEAAAAAAABcgQlDAQBlJCUlValwLklPP/10tYdbsVqteuqpp+yvbTabxo0bJ6vVWq3jAAAAAAAAuArFcwBAGZs2barythdddFG1j5+SkiKbzeawrKSkRKmpqdU+FgAAAAAAgCtQPAcAlHHZZZdVaTuz2VyjIVuio6MdJqqSaj78CwAAAAAAgCtQPAcAlBEbG6trr7220m1MJpMWLlxY7SFbJCkiIkILFiywv7ZYLFqwYEGNjgUAAAAAAOAKTBgKACjXxIkT9dFHH6lVq1YaPny4WrZsqYyMDElSr169NHTo0FoVu0ePHq37779feXl52rBhg/r16+es6AAAAAAAALVG8RwAUK4TJ05Ikrp3765Fixa55BzNmjVTXl6eAgMDXXJ8AAAAAACAmmLYFgBAuX7//XdJUnBwsMvO0aRJE0lSbm6uy84BAAAAAABQExTPAQDlKu153qJFC5edg+I5AAAAAACoqyieAwDK5Y7iucVikSQtWrRISUlJLjsPAAAAAABAdVE8BwCUy9XF88TERO3atUuS9M477+jiiy/WiBEjXHIuAAAAAACA6qJ4DgAolyvHPLdarRo9enSZ5cuWLaMHOgAAAAAAqBMongMAyuXKnucpKSkVrtu8ebPTzwcAAAAAAFBdFM8BAOVyZfE8Ojq6wnV9+/Z1+vkAAAAAAACqi+I5AKBcriyeR0REaPHixWWWx8fHKzY21unnAwAAAAAAqC6K5wCAMgzDcOmY55KUkJCgQ4cOafjw4ZKka6+9VkuXLnXJuQAAAAAAAKqL4jkAoIyTJ0/q1KlTklzT87xURESEbr75ZklSYWGhy84DAAAAAABQXR4tnm/cuFHDhg1TeHi4TCaT3nvvPYf1I0aMkMlkcnhcc801ngkLAI3I7t27JUleXl7KyMhw6bkiIiIkSVar1aXnAQAAAAAAqA6PFs9zc3PVvXt3vfrqqxVuc8011ygtLc3+WLFihRsTAkDjk5iYqD59+kiSTp06pfbt2ysxMdFl5zuzeG4YhsvOAwAAAAAAUB1enjz54MGDNXjw4Eq38fX1VZs2bap8zMLCQoev/mdnZ9c4HwA0NlarVWPGjHEoYhuGoXHjxikuLs5e6Hamtm3bSjr9gWpWVpaaN2/u9HMAAAAAAABUV50f83zDhg1q3bq1YmJidO+9955z+IDZs2crKCjI/mjXrp2bkgJA/ZeSklJu7++SkhKlpqa65Jz+/v72cdUZugUAAAAAANQVHu15fi7XXHONbrzxRnXs2FH79u3TP//5Tw0ePFhbt26VxWIpd59p06Zp8uTJ9tfZ2dkU0AF4VFJSkpYvX66cnByFhITo119/VXFxsfr27avdu3crMzPT4fmwYcPUvn17RUdHu6Snd2Wio6NlMpnKFNAtFouioqJcdt7WrVvrxIkT2rlzp/70pz+57DwAAAAAAABVVaeL57fffrv9+QUXXKALL7xQnTt31oYNG3TllVeWu4+vr698fX3dFREAKjVixAgtW7as3HWrVq2q9LnZbNbChQuVkJDg2pBniIiI0LPPPqspU6bYl5nNZi1YsMBlhfzExET9/PPPkqT4+HgVFRW59T0DAAAAAACUp84P23KmTp06KSQkxGVDBwCAMyUlJVVYOK8Km82mcePGuXUok8TERP3jH/9wWPb000+7rJhttVo1duxY++vS8dUZvgUAAAAAAHhavSqeW61WZWRkKCwszNNRAOCcNm3aVOtjuHKs8bMtXbpUo0ePLjNky7Rp01xWzE5JSZHNZnNY5s73DAAAAAAAUBGPDtty8uRJhwLJ/v37tWvXLrVo0UItWrTQrFmzdNNNN6lNmzbat2+f/vGPfygqKkpxcXEeTA0AVXPZZZfV+hiuHmu8VN++fbVly5Zy15UWs10xbEt0dLTMZrNDAd1d7xkAAAAAAKAyHi2eb9++XQMHDrS/Lp3oMz4+XvPmzdP333+vZcuWKTMzU+Hh4br66qv1+OOPM6Y5gHohNjZW0dHRSklJqfExbrzxRt1///0KDg5Wt27dtHnzZvn4+CgyMlLHjx+XJIWEhFT6vFmzZho0aJAOHTqk5ORkFRUVKT093V6g3rhxo7755psKM5jNZpcVsyMiIrRw4UKNHTvWXkC/9NJL9fLLL9vfx0UXXaRhw4a5ffJUAAAAAADQuJmMs7+f38BkZ2crKChIWVlZCgwM9HQcAI1M//79tXHjRl1zzTWKiIhQy5YtdfDgQRUXF6t3797as2ePMjMz7c8/+eSTOjfe94MPPqjnnnvOpecYMGCAvvrqqwrXm0wmLVq0qF5NJEr7U3NcOwCAJ9D+1BzXDgDgCe5ofzza8xwAGrrk5GRJ0uOPP66LLrqo0m2TkpK0ePFid8SqMrPZrPvvv9+l50hKSqq0cC6dnkh07NixiouLowc6AAAAAABwi3o1YSgA1BdJSUm69957lZ6eLklq0qTJOfdxxgSjzmQ2m7Vw4UKXF6ur+r5tNhsTiQIAAAAAALeheA4ATjZixAhdfPHFmj9/vn3Z+eefr8TExEr3c8YEo84yb948/frrr24ZJqU67/u1115zYRIAAAAAAIA/UDwHACdKSkrSsmXLyiwvHXaksvHMY2NjFR8f78p452Q2m7V48WKNHz/ebcOjVOd9v/vuu0pKSnJxIgAAAAAAAMY8BwCnqmwIktJhRyorSi9dulQTJ07UihUrJEkRERHaunWrmjdvrq5du2rr1q3y9vZWZGSkMjIyJEktW7as9HmzZs10xRVXyGq1au/evSooKNCxY8fUuXNnSdK+ffvUuXNn9erVS7179/bImOJnvu+cnBy1bNlSGzZs0H//+98y227evFmxsbFOOa/VatWaNWuUnJwsX19fHT9+XM2aNdNdd93ltHMAAAAAAID6ieI5ADhRZUOQmM1mRUVFnfMYsbGxjbJwe/b7TkpK0sUXX1xmu+PHjzvlfImJiRo9enS561566SXFx8dr6dKlTjkXAAAAAACofxi2BQBqwWq1at68eZo0aZIeeughzZ8/X76+vmW2M5lMbpl8syGJjY3VzTffXGb57NmzKx3+piqsVmuFhfNSy5YtY4gYAAAAAAAaMXqeA0ANVdZzuVS/fv101113aejQoRTOa2DChAlauXKlwzKbzaaXXnpJzz33XI2Pm5KSUqXtnDlEDAAAAAAAqF/oeQ4ANVCVnsuStGXLFgrntdC0adNylz///PNau3ZtjY8bHR1dpe369u1b43MAAAAAAID6jeI5ANRAVXsul04Sipo5efJkheuGDRumESNG1Oi4ERERWrx4caXbxMfH0+scAAAAAIBGjGFbAKAGqtpzuaqThKJ80dHRMplMMgyj3PXLli3TxIkTa1TkTkhI0BNPPKEDBw7o5ptvVufOnZWRkaFmzZrpjjvuoHAOAAAAAEAjR89zAKiBqvRcZpLQ2ouIiNCiRYsq3Wbz5s01Pn5hYaEk6eGHH9bTTz+tRYsWac6cORTOz/Lqq6+qQ4cO8vPz0yWXXKJt27ZVun1mZqYmTpyosLAw+fr6qkuXLvroo4/clBYAANB2AwDgHPQ8B4AaSkhI0BtvvKGvvvpKcXFx6tGjhzIyMiRJvXr1YqxzJ0lISFBoaKiGDRtW7vrajEuek5MjSWrWrFmNj9HQvf3225o8ebLmz5+vSy65RHPnzlVcXJySk5PVunXrMtsXFRXpqquuUuvWrbVy5Uq1bdtWv/76q5o3b+7+8AAANEK03QAAOA/FcwCoBZvNJkkaPXq0br75Zg+nabiGDh2q+Ph4LVu2zGF56bjka9eu1TvvvKOwsDBJUmpqqn24nNTUVIWGhtp7mYeEhOj48eOS/hhTvbSIjrLmzJmjMWPGaOTIkZKk+fPn68MPP9Trr7+uqVOnltn+9ddf14kTJ7RlyxZ5e3tLkjp06FDpOQoLC+0/H0nKzs523hsAAKCRoe0GAMB5KJ4DQC3k5+dLkvz9/T2cpOFbunSpJk6cqPvvv19bt27VNddcoyeeeEJdunSp8gSuFfnzn/+sRYsWKSEhwUlpG4aioiLt2LFD06ZNsy8zm80aNGiQtm7dWu4+H3zwgXr37q2JEyfq/fffV6tWrXTnnXfqoYceksViKXef2bNna9asWS55DwAANCa03QAAOBdjngNALVA8d6/Y2Fj9/e9/lyQlJyerXbt2tS6cS5JhGBo3bpysVmutj9WQHD9+XCUlJQoNDXVYHhoaqiNHjpS7zy+//KKVK1eqpKREH330kaZPn64XXnhBTzzxRIXnmTZtmrKysuyPQ4cOOfV9AADQWNB2AwDgXPQ8B4BayMvLk0Tx3J1iYmIkSfv373fqcUtKSpSamso49bVks9nUunVrLVy4UBaLRb169dJvv/2m5557TjNnzix3H19fX/n6+ro5KQAAkGi7AQCoDMVzAKiF0p7nAQEBHk7SeHz99dcuOa7FYrGPk47TQkJCZLFYlJ6e7rA8PT1dbdq0KXefsLAweXt7O3zNu2vXrjpy5IiKiork4+Pj0swAADRmtN0AADgXw7YAQC3k5uZKkrKysjycpHGwWq269957nX5cs9msBQsW0Ov8LD4+PurVq5fWrVtnX2az2bRu3Tr17t273H369u2r1NRU+2S6krR3716FhYXxxzcAAC5G2w0AgHPR8xwAaigxMVE5OTmSpIEDB2rhwoVMOOli5xrfPDY2VldccYX27dunzp07S5L27dunVq1aqbi4WJLUsmVLZWRkSJI6deqkqKgo9e7dm8J5BSZPnqz4+HhddNFFuvjiizV37lzl5uZq5MiRkqR77rlHbdu21ezZsyVJ9957r1555RXdf//9+tvf/qaUlBQ99dRTuu+++zz5NgAAaDRouwEAcB6K5wBQA1arVWPHjrW/ttlsGjdunOLi4ijCulB0dHSF60wmk1atWsX1d7LbbrtNx44d04wZM3TkyBH16NFDn3zyiX0isoMHD8ps/uOLbO3atdOnn36qBx54QBdeeKHatm2r+++/Xw899JCn3gIAAI0KbTcAAM5jMgzD8HQIV8rOzlZQUJCysrIUGBjo6TgAGoj169friiuuKHf5gAED3B+oEUlMTNTo0aMdlplMJi1atKhO9fyn/ak5rh0AwBNof2qOawcA8AR3tD8eHfN848aNGjZsmMLDw2UymfTee+9VuO348eNlMpk0d+5ct+UDgIpER0fLZDI5LGPCSfdISEjQoUOHNG/ePD3wwAOaN2+eDh48WKcK5wAAAAAAoP6r8bAt27dv1zvvvKODBw+qqKjIYd2qVauqdIzc3Fx1795do0aN0o033ljhdqtXr9Y333yj8PDwmsYFAKdr1aqVjh49Kul04ZwJJ90nIiJC48eP93QMAAAAAADQgNWo5/lbb72lPn36aM+ePVq9erWKi4u1e/duffnllwoKCqrycQYPHqwnnnhCN9xwQ4Xb/Pbbb/rb3/6m5cuXy9vbuyZxAcCpEhMTFRkZaS+cS9Ls2bPp+QwAAAAAANCA1Kh4/tRTT+nFF1/UmjVr5OPjo5deekk///yzbr31VkVGRjotnM1m0913360pU6bo/PPPr9I+hYWFys7OdngAgLNYrVaNGTNGZ08XMW3aNFmtVg+lAgAAAAAAgLPVqHi+b98+DRkyRJLk4+Oj3NxcmUwmPfDAA1q4cKHTwj3zzDPy8vLSfffdV+V9Zs+eraCgIPujXbt2TssDACkpKWUK55JUUlKi1NRUDyQCAAAAAACAK9SoeB4cHKycnBxJUtu2bfXjjz9KkjIzM5WXl+eUYDt27NBLL72kpUuXlpmUrzLTpk1TVlaW/XHo0CGn5AEA6fR8D+VhslAAAAAAAICGpUbF88svv1yff/65JOmWW27R/fffrzFjxuiOO+7QlVde6ZRgmzZt0tGjRxUZGSkvLy95eXnp119/1d///nd16NChwv18fX0VGBjo8AAAZ7BarfrHP/5R7rqpU6cyWSgAAAAAAEAD4lWTnV555RUVFBRIkh5++GF5e3try5Ytuummm/TII484Jdjdd9+tQYMGOSyLi4vT3XffrZEjRzrlHABQHSkpKRWuCwkJcWMSAAAAAAAAuFqNiuctWrSwPzebzZo6dWqNTn7y5EmHMYL379+vXbt2qUWLFoqMjFTLli0dtvf29labNm0UExNTo/MBQG1ER0dXuK5v375uTAIAAAAAAABXq9GwLdnZ2eU+cnJyVFRUVOXjbN++XT179lTPnj0lSZMnT1bPnj01Y8aMmsQCAJeKiIjQlClTyiyPj49XbGysBxIBAAAAAADAVWrU87x58+aVTuIZERGhESNGaObMmTKbK67PDxgwQIZhVPm8Bw4cqE5MAHC67t27SzrdC/3OO+/UkCFDKJwDAAAAAAA0QDUqni9dulQPP/ywRowYoYsvvliStG3bNi1btkyPPPKIjh07pueff16+vr765z//6dTAAOBJVqtVknTppZfq0Ucf9WwYAAAAAAAAuEyNiufLli3TCy+8oFtvvdW+bNiwYbrgggu0YMECrVu3TpGRkXryyScpngNoUEqL5xERER5OAgAAAAAAAFeq0ZjnW7ZssY9TfqaePXtq69atkqR+/frp4MGDtUsHAHXMb7/9Jklq27ath5MAAAAAAADAlWpUPG/Xrp0SExPLLE9MTFS7du0kSRkZGQoODq5dOgCoY+h5DgAAAAAA0DjUaNiW559/Xrfccos+/vhj+0R527dv188//6yVK1dKkpKSknTbbbc5LykA1AEUzwEAAAAAABqHGhXPr7vuOiUnJ2vBggVKTk6WJA0ePFjvvfeeOnToIEm69957nRYSAOqC/fv3Ky0tTZJkNtfoizsAAAAAAACoJ6pdPC8uLtY111yj+fPna/bs2a7IBAB1TmJiosaMGWN/3atXLy1atEgJCQkeTAUAAAAAAABXqXbXSW9vb33//feuyAIAdZLVatWYMWNkGIZ9mWEYGjdunH0YFwAAAAAAADQsNRp34C9/+Uu5E4YCQEOUkpLiUDgvVVJSotTUVA8kAgAAAAAAgKvVaMzzU6dO6fXXX9cXX3yhXr16qUmTJg7r58yZ45RwAFAXREdHy2QylSmgWywWRUVFeSgVAAAAAAAAXKlGxfMff/xRf/7znyVJe/fudVhnMplqnwoA6pCIiAgtWrRIo0ePti8zm81asGCBIiIiPJgMAAAAAAAArlKj4vn69eudnQMA6rSEhAQ9++yz2rt3r6ZPn66xY8dSOAcAAAAAAGjAajTmOQA0RoWFhZKkoUOHUjgHAAAAAABo4GrU81yStm/frnfeeUcHDx5UUVGRw7pVq1bVOhgA1DVZWVmSpJycHA8nAQAAAAAAgKvVqOf5W2+9pT59+mjPnj1avXq1iouLtXv3bn355ZcKCgpydkYA8LjExERlZmZKkq6++molJiZ6NhAAAAAAAABcqkbF86eeekovvvii1qxZIx8fH7300kv6+eefdeuttyoyMtLZGQHAo6xWq8aOHWt/bbPZNG7cOFmtVg+mAgAAAAAAgCvVqHi+b98+DRkyRJLk4+Oj3NxcmUwmPfDAA1q4cKFTAwKAp6WkpMhmszksKykpUWpqqocSAQAAAAAAwNVqVDwPDg62j/nbtm1b/fjjj5KkzMxM5eXlOS8dANQB0dHRMpsdf11aLBZFRUV5KBEAAAAAAABcrUbF88svv1yff/65JOmWW27R/fffrzFjxuiOO+7QlVde6dSAAOBpEREReuyxx+yvLRaLFixYoIiICA+mAgAAAAAAgCt51WSnV155RQUFBZKkhx9+WN7e3tqyZYtuuukmPfLII04NCAB1wTXXXKNHHnlEISEh2rlzJ4VzAAAAAACABq5axfPs7OzTO3l5qWnTpvbXEyZM0IQJE5yfDgDqiNzcXElSy5YtKZwDAAAAAAA0AtUqnjdv3lwmk+mc25WUlNQ4EICaS0pK0qZNm9SiRQtt2rRJmZmZGjlypIYOHerpaPXeyZMnJUlNmzb1cBIAAAAAAAC4Q7WK5+vXr7c/NwxD1157rRYvXqy2bdvW6OQbN27Uc889px07digtLU2rV6/W9ddfb1//6KOP6q233tKhQ4fk4+OjXr166cknn9Qll1xSo/MBDdmIESO0bNmyMstXrVqlPn36aPPmzR5I1XBQPAcAAAAAAGhcqlU879+/v8Nri8WiSy+9VJ06darRyXNzc9W9e3eNGjVKN954Y5n1Xbp00SuvvKJOnTopPz9fL774oq6++mqlpqaqVatWNTon0BAlJSWVWzgvtWXLFs2ZM0eTJ092Y6qG5eDBg5KkrKwsWa1Whm4BAAAAAABo4MyePPngwYP1xBNP6IYbbih3/Z133qlBgwapU6dOOv/88zVnzhxlZ2fr+++/d3NSoG7btGnTObf5+9//riuuuMINaRqexMRETZkyRZK0a9cuRUZGKjEx0cOpAAAAAAAA4EoeLZ5XR1FRkRYuXKigoCB17969wu0KCwuVnZ3t8AAaui5dulRpu/Xr1+vCCy90cZqGxWq1asyYMQ7LDMPQuHHjZLVaPZQKAAAAAAAArlbr4nlVJhCtjbVr16pp06by8/PTiy++qM8//1whISEVbj979mwFBQXZH+3atXNpPqAuaNKkSZW3/eGHH7R27VoXpmlY1qxZI8MwyiwvKSlRamqqBxIBAAAAAADAHapVPL/xxhsdHgUFBRo/fnyZ5c40cOBA7dq1S1u2bNE111yjW2+9VUePHq1w+2nTpikrK8v+OHTokFPzAHVRdHR0tT7I+uSTT1yYpuEYMWKEJkyYUO46i8WiqKgoNycCPOPVV19Vhw4d5Ofnp0suuUTbtm2r0n5vvfWWTCaTw2TgAADA9Wi7AQBwjmoVz8/s0R0UFKS//OUvCg8PL7PcmZo0aaKoqChdeumlSkxMlJeXV6VjDfv6+iowMNDhATR0ERERGjZsmP21xWLR4sWLNXDgwHK3v+aaa9wVrd6qbBJWk8mkBQsWMGkoGoW3335bkydP1syZM/Xtt9+qe/fuiouLq/SDbEk6cOCAHnzwQV122WVuSgoAACTabgAAnMmrOhsvWbLEVTmqzGazqbCw0NMxgDqnW7du+uCDD3TzzTfrxRdfVEREhBISEnThhRfqhx9+sG/Xp08fDR061INJ64fKJmF9++23dcstt7gxDeA5c+bM0ZgxYzRy5EhJ0vz58/Xhhx/q9ddf19SpU8vdp6SkRHfddZdmzZqlTZs2KTMz042JAQBo3Gi7AQBwHo9OGHry5Ent2rVLu3btkiTt379fu3bt0sGDB5Wbm6t//vOf+uabb/Trr79qx44dGjVqlH777TeKVkA5CgoKJJ0ewuXMHtHff/+9brrpJknS8OHDtXnzZo/kq28q6nFjNpvVu3dvN6cBPKOoqEg7duzQoEGD7MvMZrMGDRqkrVu3VrjfY489ptatWyshIaFK52GybwAAnIO2GwAA5/Jo8Xz79u3q2bOnevbsKUmaPHmyevbsqRkzZshisejnn3/WTTfdpC5dumjYsGHKyMjQpk2bdP7553syNlAnlRbP/fz8yqwr/TfWunVrt2aqz2JjY8vM4WAymbRw4UKGa0Gjcfz4cZWUlCg0NNRheWhoqI4cOVLuPl9//bUSExO1aNGiKp+Hyb4BAHAO2m4AAJyrWsO2ONuAAQNkGEaF61etWuXGNED9lp+fL6n84nnTpk0lSTk5OW7NVN9Nnz5dq1atUkBAgF544QUNHTqUwjlQiZycHN19991atGiRQkJCqrzftGnTNHnyZPvr7Oxs/ggHAMANaLsBAKicR4vnAJynsp7npcXzkydPujVTfVf6YUN4eLjGjx/v4TSA+4WEhMhisSg9Pd1heXp6utq0aVNm+3379unAgQMOExjbbDZJkpeXl5KTk9W5c+cy+/n6+srX19fJ6QEAaHxouwEAcC6PDtsCwHkqK543a9ZMEsXz6tq/f78k6dSpU7JarR5OA7ifj4+PevXqpXXr1tmX2Ww2rVu3rtyx/8877zz98MMP9vlMdu3apeuuu04DBw7Url276JEGAICL0XYDAOBc9DwHGgh6njtXYmKiRo8eLUk6cOCAIiMjtWjRoipPogQ0FJMnT1Z8fLwuuugiXXzxxZo7d65yc3M1cuRISdI999yjtm3bavbs2fLz89Of/vQnh/2bN28uSWWWAwAA16DtBgDAeSieA/VcUlKS1qxZo927d0tSuT2kKZ5Xj9Vq1ZgxYxyWGYahcePGKS4ujnHP0ajcdtttOnbsmGbMmKEjR46oR48e+uSTT+wTkR08eFBmM19kAwCgrqDtBgDAeUxGZTN2NgDZ2dkKCgpSVlaWAgMDPR0HcKoRI0Zo2bJlZZbHx8dr6dKl9tfffvutevXqpYiICB06dMiNCeun9evX64orrqhw3YABA9wbCPUS7U/Nce0AAJ5A+1NzXDsAgCe4o/3h42agnkpKSiq3cC5Jy5YtU1JSkv11ac/z0gkwUbno6GiZTKYyyy0Wi6KiojyQCAAAAAAAAO5G8RyopyZMmFDp+s2bN9ufnzlsSwP/solTpKWllSmSm81mLViwgCFbAAAAAAAAGgmK50A9lJSUpO3bt1e6Td++fe3PmzVrJkkqKSlRYWGhS7PVdyNGjNDFF1+slJQU+7LLL79cv/76K5OFAgAAAAAANCIUz4F6aNOmTZWuj4+PV2xsrP11QECA/TmThlasoqFwNm7cqLS0NA8kAgAAAAAAgKdQPAfqocsuu6zc5aNHj9a2bdscJguVTo/VXVpAp3heseeff77CdWcOgwMAAAAAAICGz8vTAQBUX2xsrDp27Kj9+/fbl8XHx2vRokUV7tO0aVPl5eUxaWgF1q5dq3feeafC9WcOgwMAAAAAAICGj57nQD3VokULSdKoUaPK7W1+tjMnDYWj+Ph4DRs2rNL1Zw6DAwAAAAAAgIaPnudAPWQYhpKTkyVJDz74oLp27XrOfUonDaV47igpKUn//ve/K1y/Zs0aDR061I2JAAAAAAAAUBdQPAfqgaSkJC1fvlw5OTkKCQnRwYMH7UVwX1/fKh2DnuflW758eYXrbrvtNgrnAAAAAAAAjRTFc6COGzFihJYtW1bh+qioKC1atEgJCQmVHofieVnnurZ///vf3ZgGAAAAAAAAdQljngN1WFJSUqXFXen0EC5jx46V1WqtdLvS4nl1Jwy1Wq1av379OY9f35zr2jLOOQAAAAAAQONG8RyowzZt2lSl7Ww2m1JTUyvdpiY9zxcuXKjIyEhdccUVat++vRITE6u8b11X2bWdN2/eOSdgBQAAAAAAQMNG8Ryowy677LIqbWc2mxUVFVXpNtWdMNRqtWr8+PEyDEPS6QL9uHHjGkwP9IqurdlsZpxzAAAAAAAAUDwH6jp/f/9K15tMJi1cuFARERGVblfa8/zdd9/VU089dc4ieEpKir1wXqqkpOScPdzri9jYWHXr1s1hWVWvJQAAAAAAABo+JgwF6qjyJrPs16+f+vbtq4yMDElSr169NHTo0CoVe5cvXy5J+vnnn/Xwww/r4Ycf1uLFiyucaDQ6OrrMMpPJdM4e7vVJnz599NNPP2nAgAG67bbbqnwtAQAAAAAA0PBRPAfqoIoms9yyZYtWrFhR7QLv2rVrdejQoTLLx44dq7i4uDLHs1qtWrNmTZntTSZTtc5b15VOnnr99ddr/PjxHk4DAAAAAACAuoTiOVDHWK1W3XfffeWuK50YtLrF848++qhKx7NarZo6daq9l7qzzl9TSUlJmj9/vjIzM9W3b1/t3r27zPPzzz9fu3fvVnBwsLp166bNmzc7PPfx8VFkZKSOHz8uSQoJCbE//+9//ytJOnbsmFveDwAAAAAAAOoPjxbPN27cqOeee047duxQWlqaVq9ereuvv16SVFxcrEceeUQfffSRfvnlFwUFBWnQoEF6+umnFR4e7snYgMskJiZq9OjRFa6vysSg5bn22ms1b968So93rnPX5vw1cfawNatWrTrn85p68sknZbVatXTp0lofCwAAAAAAAA2DR4vnubm56t69u0aNGqUbb7zRYV1eXp6+/fZbTZ8+Xd27d9fvv/+u+++/X9ddd522b9/uocSA61itVo0ZM6bSbWo6meXQoUPVp08fbdmypdzjWa3WcxbOJalz585as2aN2rVrpy+++EI5OTkOPbl9fX2Vnp5uL7CnpqYqNDRUhYWFkhx7fVf2fM+ePeUOG+NKy5Yt08SJExUbG+vW8wIAAAAAAKBu8mjxfPDgwRo8eHC564KCgvT55587LHvllVd08cUX6+DB/2/vzsOjqu89jn9mhmwQkrCGxEkQSBRQEWUrIEIwNZWl4L0WihYDhbCltyqtCy6g0isoVFGLrBEoD4vLg5Tt0logVwwIYauAbBEoTE3Y2oQEIYHkd//wZsqEJCRhlizv1/PM85AzZ8755Jtf5ke+OTm/U4qOjvZGRMBrjh07JmNMmc/PmTOnzMU9KyItLU2fffaZ8xdV+/fv19133+08d0UzTpgwocoZqru0tDSa5wAAAAAAAJBUw+55npOTI4vForCwsDL3yc/Pd17lKkkXL170QjLg1gUHB5f5nMVi0YABA275HIMHD5bValVRUZEaN27s3B4bG3vLx64Nevbs6esIAAAAAAAAqCasvg5QUVeuXNHzzz+vYcOGKSQkpMz9pk2bptDQUOcjKirKiymBqsvLyyvzuQULFrhlkU6LxaL69etLki5fvuzcbrfbtXDhwls+fk2WmJjIVecAAAAAAABwqhFXnl+9elVDhgyRMabURQ+vN2nSJE2cONH58cWLF2mgo0Yo7V7+FotFO3bscGtTNygoSHl5eS7Nc0kaPny4877nSUlJuv/++9WpUyd17drVbee+Fa+88ooyMzOVnZ2t7t2769ChQ8rOzla7du106NAhhYWFqV27dtq+fbvLv/38/BQdHa0LFy5Ikpo0aeLy78DAQPXv35/GOQAAAAAAAFxU++Z5ceP873//uzZv3lzuVefSDwsWBgQEeCkd4B4Oh0MvvPDCDdvfeusttzd1g4KCJP2wKO/1du7cKemH76F58+bJYrFIkhYuXFihxUQ9xWKxaMGCBbd0v3cAAAAAAACgsqp187y4cX7s2DFt2bJFTZo08XUkwCOOHTumoqKiG7Z37tzZ7eeqV++Hb/tVq1Zp8eLF6tevn86cOaOkpCRJP6wb8OGHHzqb1aNGjVJCQoJ+//vfa9asWTccb9iwYWrQoIEkyc/PT+fOnVObNm0kSd9++62aNWumq1evSrrxqu+b/btTp04aMGCAW25ZAwAAAAAAAFSGxRhjfHXyvLw8ZWRkSJLuu+8+vf3224qLi1Pjxo0VERGhxx57THv27NG6desUHh7ufF3jxo3l7+9foXNcvHhRoaGhysnJuelV64CvOBwOtWzZ0qWBbrPZdPLkSbc2jlNSUip0FXlp5/ZWRqC2YP6pOmoHAPAF5p+qo3YAAF/wxvzj0wVDd+3apfvuu0/33XefJGnixIm67777NHnyZP3jH//QmjVr5HA41LFjR0VERDgf27Zt82VswO3sdrvefPNN58dWq1Xz5s1za1Pa4XBozJgxFdq3sLDQ+Yut6zPOnz9fNptN0g+Nc3dnBAAAAAAAAKoLn962pU+fPirvwncfXhQPeFVKSoqee+4558el3cLlVpV1a5jSWCwWxcTE3LC9+BYuGRkZiomJoXEOAAAAAACAWsunV54D+OGK8KSkpBt+WTR27Fg5HA63nSc2NlZWa8W+5YsXCy2N3W5Xnz59aJwDAAAAAACgVqvWC4YCnpSenq6tW7eqcePG2rp1q7KzszVy5EgNGDDAuY/D4dCxY8cUHBysvLw8xcbGVrhpnJ6errVr1yo/P1/nz59Xw4YN9cQTT6hLly6SpHXr1unjjz9WQUFBqX9lUXzrFHc1qYtvuzJ27FgVFhaWu29RUZFbzw0AAAAAAADUNDTPUSeNGDFCS5YsuWH7qlWr1KNHD6WlpSklJUVjxoxxudWJ1WrV/PnzNWrUqCod/91331ViYqKOHTt203v322y2Um+dciuuv+3K+++/r1WrVumBBx5QWlqaSwPfE+cGAAAAAAAAahKa56hz0tPTS21sF9u2bZs6d+6sPXv23HBFeFFRkUaPHq1PP/1UYWFhio6O1vnz5yVJTZs21fnz53Xu3DmtXbu2zOOXd+5iFovFY4tx2u122e127d+/X6tWrVJERIQeffRRrVq1ShILgQIAAAAAAAASzXPUQVu3br3pPrt37y73+Y0bN7orTqmefPLJm17dfqsaNmwoScrNzVWXLl20atUqDRo0SH/4wx9onAMAAAAAAKDOY8FQ1Dm9evXydYSbeuyxxzx+juLm+enTp3X27FlJqtQ93QEAAAAAAIDajOY56pwuXbroZz/7ma9jlKlHjx4ui5Z6SlpamiTp4MGDmjdvniTpn//8p8fPCwAAAAAAANQENM9RJ02dOlWSFBgYqEWLFmnQoEE+zTN+/HglJiZq7dq1zqa2JzkcDr377rs3bP/www81YsQIj58fAAAAAAAAqO5onqNOys3NlfTDIp8jRozQ6tWrlZiY6JFzJSYmauHChaU+Z7VatXDhQn3wwQdavHixV644l6Rjx46pqKio1OeWLFmi9PR0r+QAAAAAAAAAqisWDEWdVNw8L77vtyQtXrxYycnJmj9/vrKzs9WuXTudOnVKd955p+655x5t3rxZkmS327V9+3b5+fkpOjpaFy5ckCQ1adLE5d+BgYHq37+/unTpIklKSEjQ0qVLtWfPHrVp00adOnVS9+7dfXKP8djYWFmt1jIb6Glpac7cAAAAAAAAQF1E8xx10u7duyVJ33//vRwOh7OB3aVLlzKbxrd6VbjdbtekSZNu6RjuYrfbNW/ePCUlJZX6fM+ePb2cCAAAAAAAAKheuG0L6pwRI0bo2WeflST9/e9/V3R0tFJSUnycyvssFkup23v06MFV5wBczJ49W7fffrsCAwPVrVs37dy5s8x9FyxYoF69eqlRo0Zq1KiR4uPjy90fAAC4H3M3AADuQfMcdUp6erqWLFniss0YozFjxsjhcPgolfc5HA6NGTOm1Od27NhRp2oBoHwfffSRJk6cqClTpmjPnj269957lZCQoLNnz5a6f2pqqoYNG6YtW7Zo+/btioqK0sMPP6x//OMfXk4OAEDdxNwNAID70DxHnbJ169ZStxcVFSkjI8PLaXynvAVDCwsL61QtAJTv7bffVlJSkkaOHKn27dtr7ty5ql+/vj788MNS91+2bJkmTJigjh07qm3btlq4cKGKioq0adOmMs+Rn5+vixcvujwAAEDVMHcDAOA+NM9Rp/Tq1avU7VarVTExMV5O4zvFC4aWxmaz1alaAChbQUGBdu/erfj4eOc2q9Wq+Ph4bd++vULH+P7773X16lU1bty4zH2mTZum0NBQ5yMqKuqWswMAUBcxdwMA4F40z1GndOnSRXfffbfLNovFovnz5zsXDa0L7Ha75s+fL5vN5rLdZrNp3rx5daoWAMp2/vx5FRYWKjw83GV7eHi4srKyKnSM559/XpGRkS4/xJc0adIk5eTkOB+nT5++pdwAANRVzN0AALhXPV8HALytc+fOOnDggOLi4jRkyBANGDCgTjaLR40apYSEBGVkZKhBgwa6dOmSYmJi6mQtAHjG9OnTtXLlSqWmpiowMLDM/QICAhQQEODFZAAAoDTM3QAAuKJ5jjonMzNTkjR8+HCNHDnSx2l8y2630ywHUKamTZvKZrPpzJkzLtvPnDmjFi1alPvamTNnavr06frrX/+qDh06eDImAAD4f8zdAAC4F7dtQZ1T/OeKERERPk4CANWbv7+/OnXq5LJgWPECYt27dy/zdW+99ZamTp2qjRs3qnPnzt6ICgAAxNwNAIC7ceU56pzi5vnNrrwAAEgTJ05UYmKiOnfurK5du2rWrFm6dOmS8y93nnzySd12222aNm2aJOnNN9/U5MmTtXz5ct1+++3O99zg4GAFBwf77PMAAKCuYO4GAMB9aJ6jTrl27ZrOnj0riSvPAaAihg4dqnPnzmny5MnKyspSx44dtXHjRudCZKdOnZLV+u8/ZJszZ44KCgr02GOPuRxnypQpevXVV70ZHQCAOom5GwAA97EYY4yvQ3jSxYsXFRoaqpycHIWEhPg6DnwsMzNTkZGRslqtKigokM1m83UkALUU80/VUTsAgC8w/1QdtQMA+II35h+f3vP8iy++0MCBAxUZGSmLxaLVq1e7PL9q1So9/PDDatKkiSwWi/bt2+eTnKg9ihcLbd68OY1zAAAAAAAAAGXy6W1bLl26pHvvvVe//OUv9R//8R+lPv/AAw9oyJAhSkpK8kFC1Abp6elau3at8vPznb+AqVevnhwOh+x2u2/DAQAAAAAAAKiWfNo8f+SRR/TII4+U+fzw4cMlSSdPnvRSItQ2I0aM0JIlS27Y7nA4FB0drQULFmjUqFE+SAYAAAAAAACgOqt1C4bm5+crPz/f+fHFixd9mAbe5nA4tHbtWu3atUvnzp3T2rVry9zXGKMxY8YoISGBK9ABAAAAAAAAuKh1zfNp06bptdde83UMeFl6erpmzJihTz75pFKvKyoqUkZGBs1zAAAAAAAAAC58umCoJ0yaNEk5OTnOx+nTp30dCR42YsQIde3atdKNc0myWq2KiYnxQCoAAAAAAAAANVmtu/I8ICBAAQEBvo4BL0lPTy/1nuYVYbFYNH/+fK46BwAAAAAAAHCDWtc8R92ydevWSu0fFxenNm3aqFOnThowYACNcwAAAAAAAACl8mnzPC8vTxkZGc6PT5w4oX379qlx48aKjo7WP//5T506dUrfffedJOnIkSOSpBYtWqhFixZez1u8GOWRI0cUEBCg8+fPS5KaNm3q/HebNm0UExOjHj160Jj1EIfDoW3btikjI0NfffVVhV9ntVr1xz/+ka8LAAAAAAAAgJvyafN8165diouLc348ceJESVJiYqIWL16sNWvWaOTIkc7nf/7zn0uSpkyZoldffdWrWVNSUjR69OhKvWbEiBGKjY3V4cOH1bFjRx08eFDZ2dm66667dPDgQTVq1Ejt27dXWlqaGjVqpMGDB6tBgwaKjY2lwVuGmTNn6tlnn73pfm3atFFkZKS+/PJLGWNks9k0b9486goAAAAAAACgQizGGOPrEJ508eJFhYaGKicnRyEhIVU6hsPhUFRUlJuTlc1qtWr+/PkaNWqU185ZE8yYMUPPPfdchfffuXOnIiIilJGRoZiYGBrnALzKHfNPXUXtAAC+wPxTddQOAOAL3ph/uOd5BRw7dsyr5ysqKtLo0aNVUFCggQMH0vTVD7/AqEzjXJLS0tL09NNPUz8AAAAAAAAAlWb1dYCaIDY21ifnnTBhgqKjo5WSkuKT81cnVfkFRs+ePT2QBAAAAAAAAEBdQPO8Aux2uxYuXOiTcxtjNGbMGDkcDp+cv7qo7C8wEhMT1aVLFw+lAQAAAAAAAFDbcduWCho1apSeeuopXbp0SY899pjatGmjCxcuSJKaNGmiCxcu6MiRI9q6davbz11UVKSf/OQnio+P1xNPPFEnm8J2u119+vRRamqqy/Y2bdooLi5OnTp1kt1uV0ZGhnr27FknawQAAAAAAADAfWieV9CCBQt06dIlSdKqVas0f/58TZ8+/Yb9HA6Hli5dqiNHjqhPnz7KzMzUkSNH1KFDBx06dEjZ2dlq166dDh06pLCwMLVr106bNm3Shg0byj3/wYMHdfDgQb377rtKTEzU4sWLPfFpVlspKSkujfOBAwfqlVdeoUkOAAAAAAAAwCMsxhjj6xCe5I5VVx0Oh1q2bKmioiLnNpvNppMnT7ptMcqUlBQlJSWpol+OnTt31vrGscPh0LZt25SRkaGXX37ZpTburj8AuJs3Vv2uragdAMAXmH+qjtoBAHzBG/MP9zyvgGPHjrk0ziWpsLBQGRkZbjvHqFGjdOrUKc2ZM6dC+6elpbnt3NVRSkqKoqOjNXToUL300ks3/FLB3fUHAAAAAAAAgOvRPK+A2NhYWa2upbLZbIqJiXHreex2u8aNG6e33nrrpvt+9dVXSk9Pd+v5qwuHw3HTq/CtVqvb6w8AAAAAAAAAxWieV4Ddbtf8+fNls9kk/dA4nzdvnsduGfLss89qxowZslgsZe7z0UcfqWvXrhoxYoRHMvjSsWPHbnr7mp/97GfcsgUAAAAAAACAx9A8r6BRo0bp5MmT2rJli06ePKlRo0Z59Hy//e1vderUKX388cd6/vnny9xvyZIlte4K9NjY2Jvu85vf/MYLSQAAAAAAAADUVfV8HaAmsdvtXr3a2W6362c/+5maNm2qN998s8z9/uu//kv333+/zpw547yVSWZmpvr27avvvvtOu3fvVnh4uJo2baqBAwfWiIVGLRZLmVefJyYm1ojPAQAAAAAAAEDNRfO8BrjZldg7duzQjh07bti+dOnSG7ZNnTpViYmJWrx4sbviuV1Zt21JTExUcnIyjXMAAAAAAAAAHsdtW2oAu92uhQsXuu141f1WL2Ut0Pq73/2OxjkAAAAAAAAAr+DK8xpi1KhRSkhI0O9//3vNmjXrlo+XlpamLl26KD09XcuWLVNubq7atGkjSTp79qwCAgKUn5+v5s2bS5K+/fZbNWzYUPHx8WrQoIFiY2M9dgsbu92uGTNmOO9r7ukFWgEAAAAAAACgJIsp68bStcTFixcVGhqqnJwchYSE+DrOLXM4HIqKirrl4/Tv319NmzbVkiVLqvR6q9Wq+fPne2zh1GPHjumOO+5QUFCQjh49SuMcQI1T2+Yfb6J2AABfYP6pOmoHAPAFb8w/XHlewxTfwmX06NG3dJz169ff0uuLioo0evRoff7557p69aruuusuHTx4UI0aNVL79u2VlpamRo0a6YEHHtA///lP9erVq1K3XMnNzZUkNWrUiMY5AAAAAAAAAK+jeV4DFd/CZd26ddq9e7ckyc/PT+fOnXPeeiUrK0t9+vRRZmamVq5cqa+//tojWT766CNJ0qpVq0p9PiUlxfnv9u3b60c/+pEkqWnTpjp//nyZ/87MzHS+zuFw0EAHAAAAAAAA4FU0z2sou92ucePGVWjf+Ph4de3a1cOJbu6bb77RN998U6nXfPfdd4qOjtaCBQs8dosYAAAAAAAAACjJ6usA8LwuXbooMTHRZVtiYuIN26orY4zGjh0rh8Ph6ygAAAAAAAAA6giuPK8jFi9erOTkZKWlpalnz57O+48nJydrxYoVys3NVevWrSVJ586dk7+/vwoKCtSsWTNJ0v79+7VixQqf5S8sLFRGRga3bwEAAAAAAADgFTTP65AuXbrcsGhnadvK8tBDD93yQqVVZbPZFBMT45NzAwAAAAAAAKh7aJ6jwooXKl26dKmOHDmiDh066NChQ8rOzla7du106NAhhYWFqV27dtq+fbvOnDmjrVu33vJ5rVar5s2bx1XnAAAAAAAAALyG5jkqxW63a9KkSRXe3+FwaN26dTp69Kj8/f114cIFSVKTJk1u+u/WrVsrJiZG3bt3p3EOAAAAAAAAwKt82jz/4osvNGPGDO3evVuZmZn67LPPNHjwYOfzxhhNmTJFCxYsUHZ2tnr27Kk5c+YoNjbWd6FRKXa7XePGjfN1DAAAAAAAAACoFKsvT37p0iXde++9mj17dqnPv/XWW3rvvfc0d+5c7dixQw0aNFBCQoKuXLni5aQAAAAAAAAAgLrEp1eeP/LII3rkkUdKfc4Yo1mzZunll1/WoEGDJEl//OMfFR4ertWrV+vnP/95qa/Lz89Xfn6+8+OLFy+6PzgAAAAAAAAAoFbz6ZXn5Tlx4oSysrIUHx/v3BYaGqpu3bpp+/btZb5u2rRpCg0NdT6ioqK8ERcAAAAAAAAAUItU2+Z5VlaWJCk8PNxle3h4uPO50kyaNEk5OTnOx+nTpz2aEwCA2m727Nm6/fbbFRgYqG7dumnnzp3l7v/JJ5+obdu2CgwM1D333KMNGzZ4KSkAAJCYuwEAcJdq2zyvqoCAAIWEhLg8AABA1Xz00UeaOHGipkyZoj179ujee+9VQkKCzp49W+r+27Zt07BhwzRq1Cjt3btXgwcP1uDBg3XgwAEvJwcAoG5i7gYAwH2qbfO8RYsWkqQzZ864bD9z5ozzOQAA4Flvv/22kpKSNHLkSLVv315z585V/fr19eGHH5a6/7vvvquf/OQnevbZZ9WuXTtNnTpV999/v/7whz94OTkAAHUTczcAAO7j0wVDy9OqVSu1aNFCmzZtUseOHSX9sPjnjh07NH78+AofxxjjfC0AAN5SPO8Uz0M1UUFBgXbv3q1JkyY5t1mtVsXHx5e5/sj27ds1ceJEl20JCQlavXp1mecpudh3Tk6OJOZuAIB3MXf/G3M3AKAm8Mbc7dPmeV5enjIyMpwfnzhxQvv27VPjxo0VHR2tp59+Wr/73e8UGxurVq1a6ZVXXlFkZKQGDx5c4XPk5uZKEguHAgB8Ijc3V6Ghob6OUSXnz59XYWFhqeuPHD58uNTXZGVlVXq9kmnTpum11167YTtzNwDAFy5cuMDczdwNAKhBPDl3+7R5vmvXLsXFxTk/Lv5td2JiohYvXqznnntOly5d0pgxY5Sdna0HHnhAGzduVGBgYIXPERkZqdOnT6thw4ayWCxVznrx4kVFRUXp9OnT1eo+6uSqPLJVHrkqp7rmkqpvtuqaS6p6NmOMcnNzFRkZ6cF0tcOkSZNcrnjLzs5Wy5YtderUqRrbvKguqvP3Vk1DLd2LeroPtXSfnJwcRUdHq3Hjxr6OUu0xd3sO39PuQy3di3q6D7V0H2/M3T5tnvfp06fcy+otFotef/11vf7661U+h9Vqld1ur/LrS6qui5CSq/LIVnnkqpzqmkuqvtmqay6patlq+g+PTZs2lc1mq9T6Iy1atKj0eiUBAQEKCAi4YXtoaGi1HQ81TXX+3qppqKV7UU/3oZbuY7VW26XBboq5u/bge9p9qKV7UU/3oZbu48m5u+b+rwAAAHiUv7+/OnXqpE2bNjm3FRUVadOmTerevXupr+nevbvL/pL0+eefl7k/AABwH+ZuAADcq9ouGAoAAHxv4sSJSkxMVOfOndW1a1fNmjVLly5d0siRIyVJTz75pG677TZNmzZNkvTUU0+pd+/e+v3vf6/+/ftr5cqV2rVrl+bPn+/LTwMAgDqDuRsAAPeheV5BAQEBmjJlSql/muZL5Ko8slUeuSqnuuaSqm+26ppLqt7ZvGHo0KE6d+6cJk+erKysLHXs2FEbN250Lix26tQplz+R69Gjh5YvX66XX35ZL774omJjY7V69WrdfffdFT5nXa+5O1FL96GW7kU93Ydauk9tqSVzd81GLd2HWroX9XQfauk+3qilxZR303EAAAAAAAAAAOog7nkOAAAAAAAAAEAJNM8BAAAAAAAAACiB5jkAAAAAAAAAACXQPAcAAAAAAAAAoIQa3TyfNm2aunTpooYNG6p58+YaPHiwjhw54rLPlStXlJycrCZNmig4OFj/+Z//qTNnzjif/9vf/qZhw4YpKipKQUFBateund59912XY6xatUo//vGP1axZM4WEhKh79+7685//XKFcDRo0UGBgoAICAhQfH69jx4655Kpfv75sNptsNptCQkI8muv6bAEBAc7zdu/e3ZmrtJqFhYXJYrFo3759Pq/Z4MGDZbFYSn0sW7bMYzWLiYlRvXr1ZLVaZbFYtHr1apd9rly5onHjxikwMFAWi0X16tVT//79nWOtIjX78ssv1bNnTzVp0kRBQUFq27at3nnnnVuu2a2OM0/mKh5jjz76qO666y7nOPNEruuzlTf+//KXv5Q5xtLT0z1as6CgIPn7+8vf39/le65kzfz8/OTv768GDRo439Mqkut6aWlpqlevnjp27HjLNbty5Yp+9KMfyc/PTxaLRX5+fpV+n61sNm+Ns6rUTJKMMZo8ebIiIiIUFBTkkkuSUlNTyx1ndcHs2bN1++23KzAwUN26ddPOnTvL3f+TTz5R27ZtFRgYqHvuuUcbNmzwUtLqrzK1XLBggXr16qVGjRqpUaNGio+Pv2nt65LKjstiK1eulMVi0eDBgz0bsIapbD2zs7OVnJysiIgIBQQE6I477uB7/f9VtpazZs3SnXfeqaCgIEVFRemZZ57RlStXvJS2+vriiy80cOBARUZGlvp/+tKkpqbq/vvvV0BAgGJiYrR48WKP56yumLvdh7nbfZi73Yu5232Yu92jWszdpgZLSEgwixYtMgcOHDD79u0z/fr1M9HR0SYvL8+5z7hx40xUVJTZtGmT2bVrl/nRj35kevTo4Xw+JSXF/PrXvzapqanm22+/NUuXLjVBQUHm/fffd+7z1FNPmTfffNPs3LnTHD161EyaNMn4+fmZPXv2lJvrmWeeMcHBwaZTp04mIiLC9OvXz7Rq1cpcvnzZmWv48OHmmWeeMREREcZms3k0V3G2xx57zAQHB5t33nnH9OrVywQFBZmWLVuay5cv31Czn//85yYsLMxIMnv37q0WNfvkk0/Mxo0bTadOnUyXLl3M6NGjTatWrczChQs9VrOkpCSTnJxsJk+ebCSZFi1a3DDOgoODTbNmzcycOXPMPffcY4KDg51jrSI127Nnj1m+fLk5cOCAOXHihFm6dKmpX7++mTdv3i3X7FbGmSdzFX9ftmjRwmWceSJXcbabjf+kpCQTGRnpMs6aN29uWrVqZYqKijxaszfeeMOMHz/e3HPPPUaS2bZtm8sYi4qKMgMHDjTh4eGmXbt2pkOHDs73tIrkKvavf/3LtG7d2jz88MPm3nvvLbNeFa3ZuHHjTEhIiBk/frx54oknjM1mq/T7bGWzeWucVaVmxhgzffp0ExoaalavXm3+9re/mZ/+9KfOXMYYk5+fbzIzM10exe9lRUVFNz1+Tbdy5Urj7+9vPvzwQ3Pw4EGTlJRkwsLCzJkzZ0rdPy0tzdhsNvPWW2+Zb775xrz88svGz8/P7N+/38vJq5/K1vLxxx83s2fPNnv37jWHDh0yI0aMMKGhocbhcHg5efVT2VoWO3HihLnttttMr169zKBBg7wTtgaobD3z8/NN586dTb9+/cyXX35pTpw4YVJTU82+ffu8nLz6qWwtly1bZgICAsyyZcvMiRMnzJ///GcTERFhnnnmGS8nr342bNhgXnrpJbNq1SojyXz22Wfl7n/8+HFTv359M3HiRPPNN9+Y999/39hsNrNx40bvBK5GmLvdh7nbfZi73Yu5232Yu92nOszdNbp5XtLZs2eNJPO///u/xhhjsrOzjZ+fn/nkk0+c+xw6dMhIMtu3by/zOBMmTDBxcXHlnqt9+/bmtddeK/P5oqIi06JFCzNjxgxnrvXr15uAgACTkpJyQ6433njD67mM+XfN/Pz8zIoVK1xqtmHDBtO2bVuzdu1aI8ksWbLEa9kqUrPir2VYWJh5/fXXPZbreidOnDCSSh1nNpvNma84W3lf04pke/TRR80vfvGLMp/31ThzZ64NGzaYVq1aOetV/EsaT+cypvzxX+zrr782kkxSUlKZx3VHtuvt2rXLSDILFy40xvx7jC1ZssSZr3iMrVixosyvaVm5hg4dal5++WUzZcqUmzaCK1uzRYsWmeDg4CqPs6pm8/Q4u5WaGfPD1zAgIMCsWLGi1NcUFBSYZs2alfleVtt07drVJCcnOz8uLCw0kZGRZtq0aaXuP2TIENO/f3+Xbd26dTNjx471aM6aoLK1LOnatWumYcOG5c7xdUVVannt2jXTo0cPs3DhQpOYmMgP4NepbD3nzJljWrdubQoKCrwVscaobC2Tk5NN3759XbZNnDjR9OzZ06M5a5qK/AD+3HPPmbvuustl29ChQ01CQoIHk1VPzN3uw9ztPszd7sXc7T7M3Z7hq7m7Rt+2paScnBxJUuPGjSVJu3fv1tWrVxUfH+/cp23btoqOjtb27dvLPU7xMUpTVFSk3Nzccvc5ceKEsrKyFB8f78wVHR2tbt26ad26dTfkioiIkMVi8Wqu4mNKUocOHbR9+3ZnzTp06KCkpCQtXbpUd999tyTp66+/9lq2itSsbdu2atq0qXJycjRy5EiP5SpLyXFWWFjozFc8zsLCwsr8mt4s2969e7Vt2zb17t27zH18Mc7cmevMmTNKSkrSxx9/rMjIyDKP54lcxceUbhz/19fs6NGjkn6onSezXS83N1eSFBoaKunfYywsLMyZr3iMZWZmlvmeVlquRYsW6fjx45oyZUqFslSlZjabrUrvs7eSzZPj7FZrJv3wtezWrVuZNVmzZo0uXLhQ5ntZbVJQUKDdu3e71MdqtSo+Pr7M+mzfvt1lf0lKSEgod4zVBVWpZUnff/+9rl69WqV5sDapai1ff/11NW/eXKNGjfJGzBqjKvVcs2aNunfvruTkZIWHh+vuu+/WG2+8ocLCQm/FrpaqUssePXpo9+7dzj8PP378uDZs2KB+/fp5JXNtwvzzA+Zu92Hudh/mbvdi7nYf5m7f8sT8U+9WQ1UXRUVFevrpp9WzZ09nszcrK0v+/v4KCwtz2Tc8PFxZWVmlHmfbtm366KOPtH79+jLPNXPmTOXl5WnIkCFl7lN8/GbNmmns2LHOXOHh4Tp16lSpuaxWq9dyhYeHu9QsMjJSWVlZzpo99dRTGjdunDp37qyTJ09Kki5cuOCVbJWp2dWrV3X77bfLbrd7LNf1ioqKJEkdO3Z0GWfF90O/Pl94eLgKCgpK/ZqWl81ut+vcuXO6du2aXn31VY0ePbrMPN4cZ+7OFRoaqn79+jnHWdOmTfXdd995JdfNxv/1NUtJSVFoaGiZ9xpzV7ZiRUVFmjp1qiQpJibGmdvf3195eXku+Yrfy0p7Tyst17Fjx/TCCy9o69atqlevYm//VanZ9dlK4+5snhxnt1qz65VXk5SUFCUkJJT6XlbbnD9/XoWFhaXW5/Dhw6W+pnicl9y/rHrWFVWpZUnPP/+8IiMjb/gPZl1TlVp++eWXSklJcVmfAj+oSj2PHz+uzZs364knntCGDRuUkZGhCRMm6OrVqxX+5WVtVJVaPv744zp//rweeOABGWN07do1jRs3Ti+++KI3ItcqZc0/Fy9e1OXLlxUUFOSjZN7F3O0+zN3uw9ztXszd7sPc7VuemLtrzZXnycnJOnDggFauXFnlYxw4cECDBg3SlClT9PDDD5e6z/Lly/Xaa6/p448/VvPmzSVJy5YtU3BwsPOxdetW5/4vvvhitcwllV2zwsJC5ebmatKkST7JVtGaORwO5eTkqEOHDl7JJUmTJ0+WJE2fPr3cbOW5WbatW7dq165dmjt3rmbNmqUVK1bcNJs3xpm7c73//vsVGmeeyCVV7D3D4XDoz3/+s5o1a+a1bMnJyTcsfFxZpeUqLCzU448/rtdee0133HFHqa9zR818kc1T48wdNauI4nHG1S/wtunTp2vlypX67LPPFBgY6Os4NUpubq6GDx+uBQsWqGnTpr6OUysUFRWpefPmmj9/vjp16qShQ4fqpZde0ty5c30drcZJTU3VG2+8oQ8++EB79uzRqlWrtH79eucv5wHUXMzdVcfc7X7M3e7D3F3NVfmGL9VIcnKysdvt5vjx4y7bN23aZCSZf/3rXy7bo6Ojzdtvv+2y7eDBg6Z58+bmxRdfLPM8K1asMEFBQWbdunUu2y9evGiOHTvmfHz//ffm22+/NZJMeHi4S64HH3zQPProozfkWrRokbFYLF7LNXToUJeaPfjgg+bXv/61s2YWi8XYbDbno3jbk08+WW1q9vrrrxur1epyX2FP5CqWnJxsIiIibrhfcnHNSuaLjo42YWFhLl/TimS73tSpU80dd9zhtprdyjhzd65+/foZq9XqMsYkGZvN5hxnnsp1s/FfXLPXX3/dNGvWrMrvGZXJZsy/38u++OILl3FWnOtPf/qTS77iXNfnKyvXv/71L2d9ix8Wi8W5bdOmTW6p2aJFi0xoaGilanar2Tw1zm41V8n7qhfXrKTicVZX7hWYn59vbDbbDfeqe/LJJ81Pf/rTUl8TFRVl3nnnHZdtkydPNh06dPBQypqhKrUsNmPGDBMaGmrS09M9mLDmqGwt9+7dW+r7Q/H/nzIyMryUvHqqyth88MEHzUMPPeSybcOGDUaSyc/P91TUaq8qtXzggQfMb3/7W5dtxYtiFxYWeipqjaMK3De1V69e5qmnnnLZ9uGHH5qQkBDPBauGmLvdh7nbfZi73Yu5232Yuz3HV3N3jW6eFxUVmeTkZBMZGWmOHj16w/PFC9l9+umnzm2HDx++YSG7AwcOmObNm5tnn322zHMtX77cBAYGmtWrV1co14QJE4zVajXPP/+8c3tOTo7LQnbX5yptIUd35zLmh0UK6tevb0JCQpw1K851/eJ/b7/9ttm/f7/Zv3+/WbhwoZFk3njjDXP69GmPZKtszYqKisxtt93mlZpdP842b958Q1Ps+gVDi/MVj7Pr81UkW0mvvfaaadmyZZm5vDXOPJFrzpw5zjG2Zs0aZ70+/fRTc/r0abfnMqbi4//TTz81RUVFplWrVmbkyJFeqdn172XFC9MWj7OSC4Z++umnzjG2cuVKZ77ychUWFjrrXfwYP368ufPOO83+/ftNXl7eLdfMmLIXDHV3Nm+Ms6rWrHjB0JkzZ96Qq+SCocXj7De/+U2px6qtunbtan71q185Py4sLDS33XZbuYuODRgwwGVb9+7dWXTMVL6Wxhjz5ptvmpCQkHIX9a2LKlPLy5cv3/D+MGjQINO3b1+zf//+Ov0DY7HKjs1JkyaZli1buvyAOGvWLBMREeHxrNVdZWt5//33m+eee85l2/Lly01QUJC5du2aR7PWJBX5Afy5554zd999t8u2YcOG1dkFQ5m73YO5232Yu92Ludt9mLs9w1dzd41uno8fP96Ehoaa1NRUk5mZ6Xxcf7XwuHHjTHR0tNm8ebPZtWuX6d69u+nevbvz+f3795tmzZqZX/ziFy7HOHv2rHOfZcuWmXr16pnZs2e77JOdnV1urjFjxpiQkBCzePFis3nzZjNgwADTqlUrc/nyZWeuFStWmGXLlpmoqChjtVrN3r17zd69e82OHTvcnqs4W2BgoAkODnbmSkhIMC1btjSXL18utWb333+/SyPP1zXbvHmz+eCDD4wk07FjR49+LYuzhYSEmAULFpilS5caSWbu3Llm+/btJjMz01mz4OBg07x5czN37lzToUMHExwc7BxrFcn2hz/8waxZs8YcPXrUHD161CxcuNA0bNjQvPTSS7dcs1sZZ57Mdf335fXjzBP1Ks5W0fE/c+ZM5xir7HtGVWu2Zs0a8/nnnzvH2R//+Eezd+9ek5mZ6cw1cOBA06JFC9O+fXvToUMH53taRXKVNGXKFHPvvfeW+XxlanbbbbeZ+fPnm7Fjxxqr1Wo6dOhg9u7da3Jzcz2SzVvjrCo1M8aY6dOnm7CwMPOnP/3JfP3112bQoEHOXNf761//aiSZQ4cO3fSYtcnKlStNQECAWbx4sfnmm2/MmDFjTFhYmMnKyjLGGDN8+HDzwgsvOPdPS0sz9erVMzNnzjSHDh0yU6ZMMX5+fmb//v2++hSqjcrWcvr06cbf3998+umnLuM+NzfXV59CtVHZWpaUmJhoBg0a5KW01V9l63nq1CnTsGFD86tf/cocOXLErFu3zjRv3tz87ne/89WnUG1UtpZTpkwxDRs2NCtWrDDHjx83f/nLX0ybNm3MkCFDfPUpVBu5ubnO/wdLMm+//bbZu3ev+fvf/26MMeaFF14ww4cPd+5//PhxU79+ffPss8+aQ4cOmdmzZxubzWY2btzoq0/BZ5i73Ye5232Yu92Ludt9mLvdpzrM3TW6eV58BWHJx6JFi5z7XL582UyYMME0atTI1K9f3zz66KPOhqcxPwzQ0o5x/RWivXv3LnWfxMTESuVq166dOXLkiEsuf3//Mo/t7lzlZbv+t18la5aQkODSPPd1zRo1amRsNptp3Lixx7+W5WWTZKZMmeLMNnbsWBMQEOD8U7BHHnnEma8i2d577z1z1113Oa/yve+++8wHH3xQ5p/oeGuceTLX9d+XO3fudI4zT9SrvGyljX9/f39jtVqr9J7hrppdP86ur1m9evWMn5+fCQoKcuarSK6SKtIIrmjN7rzzzlL327Jli0eyeWucVaVmxvxwRfkrr7xiwsPDTUBAgHnooYecua43bNgw06NHj5serzZ6//33TXR0tPH39zddu3Y1X331lfO53r173/C+/PHHH5s77rjD+Pv7m7vuususX7/ey4mrr8rUsmXLluXOZ3VdZcfl9fgB/EaVree2bdtMt27dTEBAgGndurX57//+b662+n+VqeXVq1fNq6++atq0aWMCAwNNVFSUmTBhwg23sqyLtmzZUu7PAomJiaZ37943vKZjx47G39/ftG7d2uVnzbqGudt9mLvdh7nbvZi73Ye52z2qw9xtMcYYAQAAAAAAAAAAJ6uvAwAAAAAAAAAAUN3QPAcAAAAAAAAAoASa5wAAAAAAAAAAlEDzHAAAAAAAAACAEmieAwAAAAAAAABQAs1zAAAAAAAAAABKoHkOAAAAAAAAAEAJNM8BAAAAAAAAACiB5jmAcqWmpspisSg7O9vXUQAAAAAAAACvoXkO1CJz585Vw4YNde3aNee2vLw8+fn5qU+fPi77FjfFv/3221s658mTJ2WxWLRv375bOg4AAAAAAABQndA8B2qRuLg45eXladeuXc5tW7duVYsWLbRjxw5duXLFuX3Lli2Kjo5WmzZtfBEVAAAAAAAAqNZongO1yJ133qmIiAilpqY6t6WmpmrQoEFq1aqVvvrqK5ftcXFxWrp0qTp37qyGDRuqRYsWevzxx3X27Nkyz/H999/rkUceUc+ePZWdna1WrVpJku677z5ZLBbnFe59+vTR008/7fLawYMHa8SIEe76dAEAAAAAAACPoXkO1DJxcXHasmWL8+MtW7aoT58+6t27t3P75cuXtWPHDsXFxenq1auaOnWq/va3v2n16tU6efJkmQ3u7Oxs/fjHP1ZRUZE+//xzhYWFaefOnZKkv/71r8rMzNSqVas8/jkCAAAAAAAAnlbP1wEAuFdcXJyefvppXbt2TZcvX9bevXvVu3dvXb16VXPnzpUkbd++Xfn5+YqLi1N0dLTzta1bt9Z7772nLl26KC8vT8HBwc7nsrKyNHToUMXGxmr58uXy9/eXJDVr1kyS1KRJE7Vo0cKLnykAAAAAAADgOVx5DtQyffr00aVLl5Senq6tW7fqjjvuULNmzdS7d2/nfc9TU1PVunVrRUdHa/fu3Ro4cKCio6PVsGFD9e7dW5J06tQpl+P++Mc/VkxMjD766CNn4xwAAAAAAACorWieA7VMTEyM7Ha7tmzZoi1btjib4ZGRkYqKitK2bdu0ZcsW9e3bV5cuXVJCQoJCQkK0bNkypaen67PPPpMkFRQUuBy3f//++uKLL/TNN99UKIfVapUxxmXb1atX3fAZAgAAAAAAAJ5H8xyoheLi4pSamqrU1FTnAp6S9OCDD+p//ud/tHPnTsXFxenw4cO6cOGCpk+frl69eqlt27ZlLhY6ffp0JSYm6qGHHnJpoBdfhV5YWOiyf7NmzZSZmen8uLCwUAcOHHDjZwkAAAAAAAB4Ds1zoBaKi4vTl19+qX379jmvPJek3r17a968eSooKHDe79zf31/vv/++jh8/rjVr1mjq1KllHnfmzJl64okn1LdvXx0+fFiS1Lx5cwUFBWnjxo06c+aMcnJyJEl9+/bV+vXrtX79eh0+fFjjx49Xdna2Rz9vAAAAAAAAwF1ongO1UFxcnC5fvqyYmBiFh4c7t/fu3Vu5ubm68847FRERoWbNmmnx4sX65JNP1L59e02fPl0zZ84s99jvvPOOhgwZor59++ro0aOqV6+e3nvvPc2bN0+RkZEaNGiQJOmXv/ylEhMT9eSTT6p3795q3bq14uLiPPp5AwAAAAAAAO5iMSVvSgwAAAAAAAAAQB3HlecAAAAAAAAAAJRA8xwAAAAAAAAAgBJongMAAAAAAAAAUALNcwAAAAAAAAAASqB5DgAAAAAAAABACTTPAQAAAAAAAAAogeY5AAAAAAAAAAAl0DwHAAAAAAAAAKAEmucAAAAAAAAAAJRA8xwAAAAAAAAAgBJongMAAAAAAAAAUML/AXaOtL39BntFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data untuk grafik garis\n",
    "x = df['Date']\n",
    "y1 = df['Beras']\n",
    "y2 = df['Beras Kualitas Bawah I']\n",
    "y3 = df['Beras Kualitas Bawah II']\n",
    "y4 = df['Beras Kualitas Medium I']\n",
    "y5 = df['Beras Kualitas Medium II']\n",
    "y6 = df['Beras Kualitas Super I']\n",
    "y7 = df['Beras Kualitas Super II']\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 10))\n",
    "\n",
    "# Grafik garis 1\n",
    "axs[0, 0].plot(x, y1, marker='.', color='b')\n",
    "axs[0, 0].set_title('Grafik Harga Beras')\n",
    "axs[0, 0].set_xlabel('Waktu')\n",
    "axs[0, 0].set_ylabel('Harga')\n",
    "\n",
    "# Grafik garis 2\n",
    "axs[0, 1].plot(x, y2, marker='.', color='r')\n",
    "axs[0, 1].set_title('Grafik Harga Beras Kualitas Bawah I')\n",
    "axs[0, 1].set_xlabel('Waktu')\n",
    "axs[0, 1].set_ylabel('Harga')\n",
    "\n",
    "# Grafik garis 3\n",
    "axs[0, 2].plot(x, y3, marker='.', color='g')\n",
    "axs[0, 2].set_title('Grafik Harga Beras Kualitas Bawah II')\n",
    "axs[0, 2].set_xlabel('Waktu')\n",
    "axs[0, 2].set_ylabel('Harga')\n",
    "\n",
    "# Grafik garis 4\n",
    "axs[1, 0].plot(x, y4, marker='.', color='y')\n",
    "axs[1, 0].set_title('Grafik Harga Beras Kualitas Medium I')\n",
    "axs[1, 0].set_xlabel('Waktu')\n",
    "axs[1, 0].set_ylabel('Harga')\n",
    "\n",
    "# Grafik garis 5\n",
    "axs[1, 1].plot(x, y5, marker='.', color='m')\n",
    "axs[1, 1].set_title('Grafik Harga Beras Kualitas Medium II')\n",
    "axs[1, 1].set_xlabel('Waktu')\n",
    "axs[1, 1].set_ylabel('Harga')\n",
    "\n",
    "# Grafik garis 6\n",
    "axs[1, 2].plot(x, y6, marker='.', color='c')\n",
    "axs[1, 2].set_title('Grafik Harga Beras Kualitas Super I')\n",
    "axs[1, 2].set_xlabel('Waktu')\n",
    "axs[1, 2].set_ylabel('Harga')\n",
    "\n",
    "# Grafik garis 7\n",
    "axs[2, 0].plot(x, y6, marker='.', color='k')\n",
    "axs[2, 0].set_title('Grafik Harga Beras Kualitas Super II')\n",
    "axs[2, 0].set_xlabel('Waktu')\n",
    "axs[2, 0].set_ylabel('Harga')\n",
    "\n",
    "# Menambahkan layout yang lebih rapi\n",
    "plt.tight_layout()\n",
    "\n",
    "# Menampilkan plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA PREPROCESSING**\n",
    "\n",
    "Langkah selanjutnya adalah mempersiapkan data sebelum dilakukan eksperimen. Proses ini akan menghapus nilai-nilai yang hilang (missing values) yang dapat mengganggu proses pelatihan data. Dataset time series juga diubah menjadi bentuk model yang sesuai dalam proses Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghilangkan missing values\n",
    "def preprocess_data(df, var):\n",
    "    df = df.filter([var])\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Mengubah date time series menjadi model yang sesuai dalam proses pelatihan\n",
    "def create_dataset(dataset, time_step=3):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i + time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.2015 - val_loss: 0.7053\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0849 - val_loss: 0.4547\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1012 - val_loss: 0.5364\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0875 - val_loss: 0.5442\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0926 - val_loss: 0.5222\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0835 - val_loss: 0.5105\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0875 - val_loss: 0.4990\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0858 - val_loss: 0.4878\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0769 - val_loss: 0.4614\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0871 - val_loss: 0.4610\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0780 - val_loss: 0.4068\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0695 - val_loss: 0.4276\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0641 - val_loss: 0.2642\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0513 - val_loss: 0.1536\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0286 - val_loss: 0.0423\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7930e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5902e-04 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2547e-04 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7772e-04 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0147e-04 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9362e-04 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2745e-04 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6410e-04 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0192e-04 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0126e-04 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8197e-04 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6021e-04 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0666e-04 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8930e-04 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0099e-04 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8740e-04 - val_loss: 0.0017\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0679e-04 - val_loss: 0.0018\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1652e-04 - val_loss: 0.0022\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2171e-04 - val_loss: 0.0020\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1224e-04 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2196e-04 - val_loss: 0.0022\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6852e-04 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0797e-04 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7631e-04 - val_loss: 0.0024\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5510e-04 - val_loss: 0.0021\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5448e-04 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5682e-04 - val_loss: 0.0025\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7204e-04 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0040e-04 - val_loss: 0.0032\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2267e-04 - val_loss: 0.0027\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3792e-04 - val_loss: 0.0022\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1879e-04 - val_loss: 0.0031\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8249e-04 - val_loss: 0.0023\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 1\n",
      "MAE: 0.12414414296384707\n",
      "MSE: 0.037903727483090295\n",
      "RMSE: 0.1946887965012119\n",
      "R2: 0.8499130845781118\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.2013 - val_loss: 0.6601\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0887 - val_loss: 0.4544\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0872 - val_loss: 0.5465\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0933 - val_loss: 0.5315\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0890 - val_loss: 0.5104\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0939 - val_loss: 0.5208\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0917 - val_loss: 0.4985\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0797 - val_loss: 0.4952\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0850 - val_loss: 0.4872\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0862 - val_loss: 0.4853\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0805 - val_loss: 0.4263\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0879 - val_loss: 0.4704\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0705 - val_loss: 0.3505\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0669 - val_loss: 0.3249\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0498 - val_loss: 0.1528\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0252 - val_loss: 0.0245\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4359e-04 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9321e-04 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8535e-04 - val_loss: 0.0020\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3311e-04 - val_loss: 0.0022\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4641e-04 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6980e-04 - val_loss: 0.0024\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4985e-04 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8134e-04 - val_loss: 0.0027\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8085e-04 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7811e-04 - val_loss: 0.0034\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2851e-04 - val_loss: 0.0026\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9241e-04 - val_loss: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8314e-04 - val_loss: 0.0033\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1582e-04 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0081e-04 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6255e-04 - val_loss: 0.0033\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6283e-04 - val_loss: 0.0031\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1892e-04 - val_loss: 0.0036\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3737e-04 - val_loss: 0.0040\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2087e-04 - val_loss: 0.0035\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2843e-04 - val_loss: 0.0038\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5873e-04 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3503e-04 - val_loss: 0.0033\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9487e-04 - val_loss: 0.0032\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2854e-04 - val_loss: 0.0034\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1347e-04 - val_loss: 0.0030\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1817e-04 - val_loss: 0.0033\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8852e-04 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5571e-04 - val_loss: 0.0040\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7216e-04 - val_loss: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8916e-04 - val_loss: 0.0033\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3917e-04 - val_loss: 0.0036\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 2\n",
      "MAE: 0.15703534923616014\n",
      "MSE: 0.05989239048194641\n",
      "RMSE: 0.24472921869271436\n",
      "R2: 0.7628448508477479\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.1831 - val_loss: 0.6604\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0931 - val_loss: 0.4520\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0861 - val_loss: 0.5200\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0884 - val_loss: 0.5095\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0853 - val_loss: 0.5211\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0895 - val_loss: 0.4925\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0854 - val_loss: 0.4893\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0895 - val_loss: 0.4939\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0768 - val_loss: 0.4341\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0769 - val_loss: 0.4015\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0717 - val_loss: 0.4581\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0599 - val_loss: 0.3346\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0451 - val_loss: 0.1392\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0212 - val_loss: 0.0058\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5125e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8527e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0508e-04 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3765e-04 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3757e-04 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5414e-04 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4798e-04 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2060e-04 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1016e-04 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1572e-04 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6038e-04 - val_loss: 0.0019\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0096e-04 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5052e-04 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1617e-04 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8181e-04 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8612e-04 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9288e-04 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9850e-04 - val_loss: 0.0024\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1766e-04 - val_loss: 0.0014\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2190e-04 - val_loss: 0.0015\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4411e-04 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4978e-04 - val_loss: 0.0015\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1464e-04 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0929e-04 - val_loss: 0.0015\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2368e-04 - val_loss: 0.0021\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8291e-04 - val_loss: 0.0015\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4300e-04 - val_loss: 0.0016\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0109e-04 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9908e-04 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4530e-04 - val_loss: 0.0017\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9626e-04 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1778e-04 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5143e-04 - val_loss: 0.0018\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5810e-04 - val_loss: 0.0022\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000124E108EF20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000124E108EF20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 373ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000124E108EF20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000124E108EF20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 3\n",
      "MAE: 0.12800655677670347\n",
      "MSE: 0.037277231560223875\n",
      "RMSE: 0.19307312490407327\n",
      "R2: 0.8523938126444836\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.2042 - val_loss: 0.7600\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1020 - val_loss: 0.4478\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0913 - val_loss: 0.5300\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0941 - val_loss: 0.5336\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0903 - val_loss: 0.5235\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0830 - val_loss: 0.5013\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0908 - val_loss: 0.4924\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0805 - val_loss: 0.4883\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0776 - val_loss: 0.4489\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0841 - val_loss: 0.4280\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0727 - val_loss: 0.3733\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0530 - val_loss: 0.2333\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0242 - val_loss: 0.0040\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0142\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.1932e-04 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.8319e-04 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.1422e-04 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.6895e-04 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.1392e-04 - val_loss: 0.0016\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1907e-04 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0166e-04 - val_loss: 0.0018\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7660e-04 - val_loss: 0.0019\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9055e-04 - val_loss: 0.0024\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2036e-04 - val_loss: 0.0022\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5738e-04 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3734e-04 - val_loss: 0.0024\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7797e-04 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9773e-04 - val_loss: 0.0030\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4762e-04 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0021e-04 - val_loss: 0.0023\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6077e-04 - val_loss: 0.0023\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3770e-04 - val_loss: 0.0026\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6413e-04 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0844e-04 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8883e-04 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6705e-04 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0616e-04 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1819e-04 - val_loss: 0.0032\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2889e-04 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1565e-04 - val_loss: 0.0025\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0462e-04 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.4278e-04 - val_loss: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8154e-04 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2901e-04 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9694e-04 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.2036e-04 - val_loss: 0.0029\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6174e-04 - val_loss: 0.0027\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.7027e-04 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9885e-04 - val_loss: 0.0032\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 4\n",
      "MAE: 0.14842840726258338\n",
      "MSE: 0.053288768330843284\n",
      "RMSE: 0.23084360145094618\n",
      "R2: 0.7889931308477264\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.1313 - val_loss: 0.5183\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0893 - val_loss: 0.5008\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0957 - val_loss: 0.5415\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0925 - val_loss: 0.5278\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0866 - val_loss: 0.4985\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0860 - val_loss: 0.4970\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0815 - val_loss: 0.4857\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0859 - val_loss: 0.4770\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0766 - val_loss: 0.4106\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.4548\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0786 - val_loss: 0.4416\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0667 - val_loss: 0.2877\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0474 - val_loss: 0.2340\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0338 - val_loss: 0.0680\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0057\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1856e-04 - val_loss: 0.0016\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4529e-04 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8841e-04 - val_loss: 0.0016\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3708e-04 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5185e-04 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7436e-04 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4437e-04 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5877e-04 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7053e-04 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7981e-04 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2716e-04 - val_loss: 0.0017\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7037e-04 - val_loss: 0.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1374e-04 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4078e-04 - val_loss: 0.0017\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2586e-04 - val_loss: 0.0017\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2351e-04 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.9880e-04 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9146e-04 - val_loss: 0.0022\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9256e-04 - val_loss: 0.0020\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6189e-04 - val_loss: 0.0018\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7213e-04 - val_loss: 0.0017\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1516e-04 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4950e-04 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2135e-04 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3030e-04 - val_loss: 0.0017\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7629e-04 - val_loss: 0.0022\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2224e-04 - val_loss: 0.0019\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7021e-04 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6247e-04 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7457e-04 - val_loss: 0.0022\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3581e-04 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5605e-04 - val_loss: 0.0025\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3518e-04 - val_loss: 0.0023\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7248e-04 - val_loss: 0.0020\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 5\n",
      "MAE: 0.11606285376626925\n",
      "MSE: 0.03392799863663926\n",
      "RMSE: 0.18419554456240048\n",
      "R2: 0.8656557283427352\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.1761 - val_loss: 0.5357\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0918 - val_loss: 0.4676\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0896 - val_loss: 0.5562\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0891 - val_loss: 0.4842\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0935 - val_loss: 0.5235\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0783 - val_loss: 0.5027\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0811 - val_loss: 0.4649\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0835 - val_loss: 0.4636\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0788 - val_loss: 0.4444\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0731 - val_loss: 0.3862\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0650 - val_loss: 0.3875\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0495 - val_loss: 0.1805\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0239 - val_loss: 0.0196\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0078\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6139e-04 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6613e-04 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3161e-04 - val_loss: 0.0016\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7114e-04 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1190e-04 - val_loss: 0.0016\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8802e-04 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5397e-04 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7844e-04 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3141e-04 - val_loss: 0.0019\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1194e-04 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2043e-04 - val_loss: 0.0025\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0021e-04 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6851e-04 - val_loss: 0.0016\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4508e-04 - val_loss: 0.0024\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5814e-04 - val_loss: 0.0017\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9791e-04 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0364e-04 - val_loss: 0.0020\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1523e-04 - val_loss: 0.0019\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5838e-04 - val_loss: 0.0020\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7766e-04 - val_loss: 0.0024\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5171e-04 - val_loss: 0.0028\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9077e-04 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2193e-04 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4729e-04 - val_loss: 0.0024\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6833e-04 - val_loss: 0.0022\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9492e-04 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6588e-04 - val_loss: 0.0022\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0901e-04 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8251e-04 - val_loss: 0.0024\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9100e-04 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3546e-04 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3781e-04 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6937e-04 - val_loss: 0.0032\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5624e-04 - val_loss: 0.0020\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 6\n",
      "MAE: 0.12045448021810552\n",
      "MSE: 0.03325927159059159\n",
      "RMSE: 0.1823712466113877\n",
      "R2: 0.8683036784591258\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1557 - val_loss: 0.6249\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0923 - val_loss: 0.4758\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0941 - val_loss: 0.5649\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0905 - val_loss: 0.5143\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0922 - val_loss: 0.5193\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0800 - val_loss: 0.5261\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0932 - val_loss: 0.4974\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0825 - val_loss: 0.5018\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0844 - val_loss: 0.5075\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0821 - val_loss: 0.4497\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0762 - val_loss: 0.4246\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0714 - val_loss: 0.3925\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0647 - val_loss: 0.3544\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0491 - val_loss: 0.1623\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0229 - val_loss: 0.0208\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4677e-04 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7938e-04 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5462e-04 - val_loss: 0.0016\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8779e-04 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7838e-04 - val_loss: 0.0019\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0683e-04 - val_loss: 0.0023\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8067e-04 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2230e-04 - val_loss: 0.0023\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7480e-04 - val_loss: 0.0022\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8529e-04 - val_loss: 0.0023\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6200e-04 - val_loss: 0.0025\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0485e-04 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0088e-04 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4656e-04 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1636e-04 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8685e-04 - val_loss: 0.0026\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6398e-04 - val_loss: 0.0026\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4239e-04 - val_loss: 0.0034\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2448e-04 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6628e-04 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8342e-04 - val_loss: 0.0035\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1635e-04 - val_loss: 0.0033\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2352e-04 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5278e-04 - val_loss: 0.0025\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3388e-04 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0357e-04 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2908e-04 - val_loss: 0.0035\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5207e-04 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7716e-04 - val_loss: 0.0029\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5367e-04 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0280e-04 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0747e-04 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5772e-04 - val_loss: 0.0031\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 7\n",
      "MAE: 0.15074110812828204\n",
      "MSE: 0.0525349327231785\n",
      "RMSE: 0.2292050015230438\n",
      "R2: 0.7919780842705808\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.1578 - val_loss: 0.5186\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0973 - val_loss: 0.5242\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0906 - val_loss: 0.5727\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0931 - val_loss: 0.5086\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0914 - val_loss: 0.5497\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0872 - val_loss: 0.5074\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0953 - val_loss: 0.5183\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0789 - val_loss: 0.4605\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0837 - val_loss: 0.4418\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0843 - val_loss: 0.4499\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0720 - val_loss: 0.2831\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0550 - val_loss: 0.1953\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0247 - val_loss: 0.0290\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8507e-04 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8620e-04 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0734e-04 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2903e-04 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2605e-04 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0082e-04 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6063e-04 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2110e-04 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7024e-04 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1134e-04 - val_loss: 0.0017\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5943e-04 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0720e-04 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7866e-04 - val_loss: 0.0018\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9568e-04 - val_loss: 0.0020\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9905e-04 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3423e-04 - val_loss: 0.0018\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.1626e-04 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0496e-04 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3117e-04 - val_loss: 0.0022\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9171e-04 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2148e-04 - val_loss: 0.0018\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0007e-04 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2866e-04 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6001e-04 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3725e-04 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0165e-04 - val_loss: 0.0022\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5287e-04 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1232e-04 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3990e-04 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4270e-04 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7920e-04 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1652e-04 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7752e-04 - val_loss: 0.0037\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8021e-04 - val_loss: 0.0017\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3005e-04 - val_loss: 0.0028\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 8\n",
      "MAE: 0.14930800140881162\n",
      "MSE: 0.046319938492283774\n",
      "RMSE: 0.21522067394254618\n",
      "R2: 0.8165875191578477\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.1910 - val_loss: 0.5755\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0831 - val_loss: 0.4750\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0901 - val_loss: 0.5452\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0946 - val_loss: 0.5177\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0967 - val_loss: 0.5387\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0906 - val_loss: 0.4959\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0877 - val_loss: 0.5087\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0904 - val_loss: 0.5007\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0809 - val_loss: 0.4470\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0892 - val_loss: 0.5216\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0788 - val_loss: 0.4105\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0782 - val_loss: 0.4043\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0704 - val_loss: 0.3413\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0524 - val_loss: 0.1891\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0306 - val_loss: 0.0269\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8009e-04 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5026e-04 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5152e-04 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0234e-04 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3715e-04 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3239e-04 - val_loss: 0.0026\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6657e-04 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7587e-04 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6822e-04 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6711e-04 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5973e-04 - val_loss: 0.0018\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.8757e-04 - val_loss: 0.0017\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2543e-04 - val_loss: 0.0018\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7902e-04 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3500e-04 - val_loss: 0.0017\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7514e-04 - val_loss: 0.0017\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8637e-04 - val_loss: 0.0024\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6384e-04 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5255e-04 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3881e-04 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9105e-04 - val_loss: 0.0023\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3703e-04 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.9247e-04 - val_loss: 0.0017\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8992e-04 - val_loss: 0.0025\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9766e-04 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1650e-04 - val_loss: 0.0023\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2375e-04 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6585e-04 - val_loss: 0.0027\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3233e-04 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6512e-04 - val_loss: 0.0029\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7855e-04 - val_loss: 0.0020\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3440e-04 - val_loss: 0.0018\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 9\n",
      "MAE: 0.11815628770922042\n",
      "MSE: 0.03019743522232872\n",
      "RMSE: 0.17377409249461992\n",
      "R2: 0.88042759361349\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.1781 - val_loss: 0.7115\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1020 - val_loss: 0.4534\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0943 - val_loss: 0.5357\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0903 - val_loss: 0.5387\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0881 - val_loss: 0.5139\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0951 - val_loss: 0.5133\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0837 - val_loss: 0.5176\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0879 - val_loss: 0.4779\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0941 - val_loss: 0.4906\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0820 - val_loss: 0.4681\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0797 - val_loss: 0.4124\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0761 - val_loss: 0.3981\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0621 - val_loss: 0.2176\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0342 - val_loss: 0.0448\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1246e-04 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2164e-04 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2868e-04 - val_loss: 0.0020\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9081e-04 - val_loss: 0.0022\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3776e-04 - val_loss: 0.0024\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8449e-04 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8631e-04 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0687e-04 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2176e-04 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8974e-04 - val_loss: 0.0042\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4662e-04 - val_loss: 0.0033\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6508e-04 - val_loss: 0.0040\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0817e-04 - val_loss: 0.0034\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2402e-04 - val_loss: 0.0035\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7375e-04 - val_loss: 0.0035\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5134e-04 - val_loss: 0.0044\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7800e-04 - val_loss: 0.0044\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9341e-04 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8200e-04 - val_loss: 0.0035\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0601e-04 - val_loss: 0.0037\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7734e-04 - val_loss: 0.0035\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5567e-04 - val_loss: 0.0038\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8401e-04 - val_loss: 0.0045\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2506e-04 - val_loss: 0.0031\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8401e-04 - val_loss: 0.0043\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1311e-04 - val_loss: 0.0039\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1110e-04 - val_loss: 0.0035\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6865e-04 - val_loss: 0.0042\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3285e-04 - val_loss: 0.0035\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4052e-04 - val_loss: 0.0042\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4572e-04 - val_loss: 0.0043\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5497e-04 - val_loss: 0.0031\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0926e-04 - val_loss: 0.0036\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5151e-04 - val_loss: 0.0043\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 10\n",
      "MAE: 0.18184295716832913\n",
      "MSE: 0.07155887738127804\n",
      "RMSE: 0.2675049109479638\n",
      "R2: 0.7166492086563114\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.1246 - val_loss: 1.0732\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0769 - val_loss: 1.0052\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0831 - val_loss: 1.0967\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0750 - val_loss: 1.0169\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0805 - val_loss: 1.0751\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0779 - val_loss: 1.0249\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0774 - val_loss: 0.9878\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0762 - val_loss: 0.9901\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0783 - val_loss: 0.9757\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0697 - val_loss: 0.8818\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0709 - val_loss: 0.9005\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0601 - val_loss: 0.6395\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0495 - val_loss: 0.5126\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0326 - val_loss: 0.0443\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0069 - val_loss: 0.0133\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0075\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0675e-04 - val_loss: 0.0034\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5721e-04 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1545e-04 - val_loss: 0.0059\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3521e-04 - val_loss: 0.0088\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3035e-04 - val_loss: 0.0071\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9789e-04 - val_loss: 0.0084\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2241e-04 - val_loss: 0.0084\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1441e-04 - val_loss: 0.0092\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9201e-04 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2635e-04 - val_loss: 0.0119\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7368e-04 - val_loss: 0.0146\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6043e-04 - val_loss: 0.0155\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0133\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4076e-04 - val_loss: 0.0141\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0245e-04 - val_loss: 0.0151\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7501e-04 - val_loss: 0.0143\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0873e-04 - val_loss: 0.0169\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9722e-04 - val_loss: 0.0192\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5684e-04 - val_loss: 0.0213\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0163\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6416e-04 - val_loss: 0.0218\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4020e-04 - val_loss: 0.0163\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0160\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4768e-04 - val_loss: 0.0183\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1669e-04 - val_loss: 0.0188\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9011e-04 - val_loss: 0.0174\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8649e-04 - val_loss: 0.0204\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0682e-04 - val_loss: 0.0178\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5857e-04 - val_loss: 0.0213\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 1\n",
      "MAE: 0.4494466859786226\n",
      "MSE: 0.26033693548437986\n",
      "RMSE: 0.5102322368141589\n",
      "R2: 0.55989125241187\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.1853 - val_loss: 1.2474\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0888 - val_loss: 0.9714\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0803 - val_loss: 1.0592\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0828 - val_loss: 1.0737\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0810 - val_loss: 1.0324\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0788 - val_loss: 1.0109\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0817 - val_loss: 1.0297\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0760 - val_loss: 0.9592\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0766 - val_loss: 0.9095\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0766 - val_loss: 0.7942\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0613 - val_loss: 0.7389\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0487 - val_loss: 0.2847\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0186 - val_loss: 0.0525\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0263\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0171\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0175\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3138e-04 - val_loss: 0.0188\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5288e-04 - val_loss: 0.0189\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6338e-04 - val_loss: 0.0203\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8559e-04 - val_loss: 0.0225\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5071e-04 - val_loss: 0.0196\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8147e-04 - val_loss: 0.0211\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9938e-04 - val_loss: 0.0214\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9653e-04 - val_loss: 0.0217\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0929e-04 - val_loss: 0.0221\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8321e-04 - val_loss: 0.0206\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6791e-04 - val_loss: 0.0208\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3232e-04 - val_loss: 0.0236\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6408e-04 - val_loss: 0.0186\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8298e-04 - val_loss: 0.0231\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8896e-04 - val_loss: 0.0248\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5034e-04 - val_loss: 0.0186\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9300e-04 - val_loss: 0.0235\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2219e-04 - val_loss: 0.0197\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3424e-04 - val_loss: 0.0258\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9866e-04 - val_loss: 0.0184\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3011e-04 - val_loss: 0.0210\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4224e-04 - val_loss: 0.0233\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5676e-04 - val_loss: 0.0209\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0110e-04 - val_loss: 0.0210\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3603e-04 - val_loss: 0.0194\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5829e-04 - val_loss: 0.0232\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1835e-04 - val_loss: 0.0202\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2484e-04 - val_loss: 0.0259\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5601e-04 - val_loss: 0.0226\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0954e-04 - val_loss: 0.0237\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7848e-04 - val_loss: 0.0199\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8916e-04 - val_loss: 0.0226\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8540e-04 - val_loss: 0.0214\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 2\n",
      "MAE: 0.4425326722567188\n",
      "MSE: 0.2618877621900568\n",
      "RMSE: 0.5117497065852181\n",
      "R2: 0.5572695253108277\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 0.1233 - val_loss: 0.9372\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0847 - val_loss: 1.1242\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0818 - val_loss: 1.0653\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0770 - val_loss: 1.0134\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0784 - val_loss: 1.0444\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0758 - val_loss: 0.9842\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0757 - val_loss: 0.9310\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0691 - val_loss: 0.8445\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0657 - val_loss: 0.6924\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0544 - val_loss: 0.5277\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0418 - val_loss: 0.3149\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0192 - val_loss: 0.0815\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8448e-04 - val_loss: 0.0020\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9588e-04 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9991e-04 - val_loss: 0.0032\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5804e-04 - val_loss: 0.0027\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5427e-04 - val_loss: 0.0037\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0825e-04 - val_loss: 0.0049\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8723e-04 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4913e-04 - val_loss: 0.0046\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7162e-04 - val_loss: 0.0060\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2724e-04 - val_loss: 0.0061\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0810e-04 - val_loss: 0.0064\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1729e-04 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0079\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1448e-04 - val_loss: 0.0098\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1177e-04 - val_loss: 0.0086\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1754e-04 - val_loss: 0.0066\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7245e-04 - val_loss: 0.0125\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6636e-04 - val_loss: 0.0087\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8517e-04 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.1467e-04 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3566e-04 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9928e-04 - val_loss: 0.0088\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3850e-04 - val_loss: 0.0135\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9886e-04 - val_loss: 0.0090\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8906e-04 - val_loss: 0.0121\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0310e-04 - val_loss: 0.0086\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9750e-04 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5304e-04 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3674e-04 - val_loss: 0.0138\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2337e-04 - val_loss: 0.0128\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5360e-04 - val_loss: 0.0133\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1152e-04 - val_loss: 0.0123\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0663e-04 - val_loss: 0.0124\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0999e-04 - val_loss: 0.0126\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8963e-04 - val_loss: 0.0122\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7330e-04 - val_loss: 0.0151\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 3\n",
      "MAE: 0.37774889586401655\n",
      "MSE: 0.18471610661601376\n",
      "RMSE: 0.42978611729093086\n",
      "R2: 0.6877309238089\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.1550 - val_loss: 1.1265\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0906 - val_loss: 1.0240\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0853 - val_loss: 1.1035\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0796 - val_loss: 1.0583\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0791 - val_loss: 1.0447\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0878 - val_loss: 1.0316\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0774 - val_loss: 1.0199\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0784 - val_loss: 1.0072\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0707 - val_loss: 0.9482\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0693 - val_loss: 0.8414\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0708 - val_loss: 0.8604\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0581 - val_loss: 0.6604\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0467 - val_loss: 0.2274\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0133 - val_loss: 0.0168\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0057\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0225\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0721e-04 - val_loss: 0.0167\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9410e-04 - val_loss: 0.0149\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1330e-04 - val_loss: 0.0190\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7640e-04 - val_loss: 0.0179\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7335e-04 - val_loss: 0.0191\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9145e-04 - val_loss: 0.0194\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6589e-04 - val_loss: 0.0186\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5382e-04 - val_loss: 0.0215\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3903e-04 - val_loss: 0.0196\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6165e-04 - val_loss: 0.0213\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1378e-04 - val_loss: 0.0218\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5532e-04 - val_loss: 0.0218\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9414e-04 - val_loss: 0.0218\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4499e-04 - val_loss: 0.0205\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6402e-04 - val_loss: 0.0195\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0255\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8343e-04 - val_loss: 0.0230\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1311e-04 - val_loss: 0.0170\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7015e-04 - val_loss: 0.0231\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2777e-04 - val_loss: 0.0208\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0038e-04 - val_loss: 0.0213\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8220e-04 - val_loss: 0.0210\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6506e-04 - val_loss: 0.0216\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5271e-04 - val_loss: 0.0222\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8316e-04 - val_loss: 0.0220\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1597e-04 - val_loss: 0.0214\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6447e-04 - val_loss: 0.0239\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0269e-04 - val_loss: 0.0208\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0026e-04 - val_loss: 0.0240\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6640e-04 - val_loss: 0.0226\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3632e-04 - val_loss: 0.0211\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6528e-04 - val_loss: 0.0224\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9822e-04 - val_loss: 0.0235\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0657e-04 - val_loss: 0.0210\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 4\n",
      "MAE: 0.4308949533056029\n",
      "MSE: 0.25764339441121586\n",
      "RMSE: 0.5075858493015895\n",
      "R2: 0.5644447783496389\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.1541 - val_loss: 1.1664\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0897 - val_loss: 1.0199\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0802 - val_loss: 1.1190\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0818 - val_loss: 1.0751\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0730 - val_loss: 1.0297\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0770 - val_loss: 1.0726\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0801 - val_loss: 1.0459\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0786 - val_loss: 1.0021\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0766 - val_loss: 1.0218\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0708 - val_loss: 0.9638\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0731 - val_loss: 0.9271\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0762 - val_loss: 0.8122\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0623 - val_loss: 0.6731\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0456 - val_loss: 0.4026\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.1120\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0263\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0158\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0183\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5815e-04 - val_loss: 0.0185\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0577e-04 - val_loss: 0.0184\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3285e-04 - val_loss: 0.0182\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7319e-04 - val_loss: 0.0193\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0564e-04 - val_loss: 0.0203\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7650e-04 - val_loss: 0.0184\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4125e-04 - val_loss: 0.0214\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5579e-04 - val_loss: 0.0210\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3619e-04 - val_loss: 0.0190\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0160e-04 - val_loss: 0.0214\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0353e-04 - val_loss: 0.0209\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4468e-04 - val_loss: 0.0210\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7295e-04 - val_loss: 0.0209\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9076e-04 - val_loss: 0.0229\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5538e-04 - val_loss: 0.0223\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6935e-04 - val_loss: 0.0205\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0523e-04 - val_loss: 0.0227\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3954e-04 - val_loss: 0.0195\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1834e-04 - val_loss: 0.0217\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9677e-04 - val_loss: 0.0206\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4661e-04 - val_loss: 0.0202\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3588e-04 - val_loss: 0.0226\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.5380e-04 - val_loss: 0.0223\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0543e-04 - val_loss: 0.0239\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9138e-04 - val_loss: 0.0222\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9099e-04 - val_loss: 0.0244\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9862e-04 - val_loss: 0.0221\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7925e-04 - val_loss: 0.0217\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7260e-04 - val_loss: 0.0194\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0355e-04 - val_loss: 0.0264\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0227\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.9357e-04 - val_loss: 0.0208\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 5\n",
      "MAE: 0.42789696083694095\n",
      "MSE: 0.2542315090462879\n",
      "RMSE: 0.5042137533291688\n",
      "R2: 0.570212690582603\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.1299 - val_loss: 1.0551\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0817 - val_loss: 1.0326\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0812 - val_loss: 1.0700\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0760 - val_loss: 1.0735\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0734 - val_loss: 1.0403\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0767 - val_loss: 1.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0869 - val_loss: 1.0362\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0809 - val_loss: 0.9848\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0716 - val_loss: 0.9311\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0799 - val_loss: 0.8732\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0655 - val_loss: 0.7397\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0551 - val_loss: 0.4020\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0306 - val_loss: 0.1003\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0079\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7115e-04 - val_loss: 0.0147\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7431e-04 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7890e-04 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2133e-04 - val_loss: 0.0171\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8216e-04 - val_loss: 0.0173\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4430e-04 - val_loss: 0.0130\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.1062e-04 - val_loss: 0.0198\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3493e-04 - val_loss: 0.0187\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2911e-04 - val_loss: 0.0190\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9648e-04 - val_loss: 0.0246\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9582e-04 - val_loss: 0.0181\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7162e-04 - val_loss: 0.0217\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3725e-04 - val_loss: 0.0236\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8051e-04 - val_loss: 0.0234\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2677e-04 - val_loss: 0.0231\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2029e-04 - val_loss: 0.0218\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8728e-04 - val_loss: 0.0255\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8208e-04 - val_loss: 0.0252\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1950e-04 - val_loss: 0.0234\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3928e-04 - val_loss: 0.0211\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0278\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6956e-04 - val_loss: 0.0229\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4434e-04 - val_loss: 0.0241\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7759e-04 - val_loss: 0.0245\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3455e-04 - val_loss: 0.0288\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0220\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3972e-04 - val_loss: 0.0214\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1882e-04 - val_loss: 0.0267\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3550e-04 - val_loss: 0.0240\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7827e-04 - val_loss: 0.0260\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2550e-04 - val_loss: 0.0278\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0256\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3521e-04 - val_loss: 0.0234\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8019e-04 - val_loss: 0.0262\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6691e-04 - val_loss: 0.0299\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 6\n",
      "MAE: 0.5398037160029165\n",
      "MSE: 0.36639464305239094\n",
      "RMSE: 0.6053054130374111\n",
      "R2: 0.380596966862342\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.1061 - val_loss: 0.9649\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0841 - val_loss: 1.0852\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0790 - val_loss: 1.0416\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0771 - val_loss: 1.0128\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0847 - val_loss: 1.0233\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0812 - val_loss: 0.9977\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0782 - val_loss: 0.9839\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0787 - val_loss: 0.9162\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0644 - val_loss: 0.7818\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0663 - val_loss: 0.6868\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0506 - val_loss: 0.5273\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0348 - val_loss: 0.2037\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8705e-04 - val_loss: 0.0147\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4553e-04 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2145e-04 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5387e-04 - val_loss: 0.0142\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2030e-04 - val_loss: 0.0150\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3367e-04 - val_loss: 0.0103\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8496e-04 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3459e-04 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5815e-04 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6051e-04 - val_loss: 0.0156\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8534e-04 - val_loss: 0.0170\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3488e-04 - val_loss: 0.0126\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4370e-04 - val_loss: 0.0134\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6610e-04 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1028e-04 - val_loss: 0.0173\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0156\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4641e-04 - val_loss: 0.0096\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0133\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8946e-04 - val_loss: 0.0162\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9972e-04 - val_loss: 0.0161\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5643e-04 - val_loss: 0.0137\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0129e-04 - val_loss: 0.0144\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6350e-04 - val_loss: 0.0142\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6759e-04 - val_loss: 0.0122\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7186e-04 - val_loss: 0.0144\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9709e-04 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7625e-04 - val_loss: 0.0155\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9255e-04 - val_loss: 0.0155\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6706e-04 - val_loss: 0.0114\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4972e-04 - val_loss: 0.0152\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2181e-04 - val_loss: 0.0137\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7007e-04 - val_loss: 0.0108\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3321e-04 - val_loss: 0.0138\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4502e-04 - val_loss: 0.0149\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0132e-04 - val_loss: 0.0151\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8965e-04 - val_loss: 0.0128\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 7\n",
      "MAE: 0.3381983256730866\n",
      "MSE: 0.15651009914789255\n",
      "RMSE: 0.39561357300766686\n",
      "R2: 0.7354141716667557\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1247 - val_loss: 0.9700\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0796 - val_loss: 1.0757\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0786 - val_loss: 1.0620\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0829 - val_loss: 1.0373\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0786 - val_loss: 1.0028\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0821 - val_loss: 0.9962\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0719 - val_loss: 0.9144\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0713 - val_loss: 0.9408\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0719 - val_loss: 0.9647\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0726 - val_loss: 0.7479\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0590 - val_loss: 0.5101\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0388 - val_loss: 0.2871\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0196 - val_loss: 0.0205\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0171\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 9.3819e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9251e-04 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7788e-04 - val_loss: 0.0021\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9915e-04 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0089e-04 - val_loss: 0.0016\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0648e-04 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8750e-04 - val_loss: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3801e-04 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1251e-04 - val_loss: 0.0042\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5829e-04 - val_loss: 0.0038\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5929e-04 - val_loss: 0.0079\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4841e-04 - val_loss: 0.0063\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0087e-04 - val_loss: 0.0075\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3551e-04 - val_loss: 0.0045\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4570e-04 - val_loss: 0.0087\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7278e-04 - val_loss: 0.0071\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5329e-04 - val_loss: 0.0072\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6673e-04 - val_loss: 0.0093\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2090e-04 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5206e-04 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4976e-04 - val_loss: 0.0081\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0214e-04 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6614e-04 - val_loss: 0.0088\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7140e-04 - val_loss: 0.0129\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9551e-04 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2843e-04 - val_loss: 0.0116\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7096e-04 - val_loss: 0.0091\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7335e-04 - val_loss: 0.0106\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8978e-04 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1966e-04 - val_loss: 0.0116\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3286e-04 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0991e-04 - val_loss: 0.0162\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0123\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0856e-04 - val_loss: 0.0126\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 8\n",
      "MAE: 0.33820548604746226\n",
      "MSE: 0.15456940967215552\n",
      "RMSE: 0.3931531631211372\n",
      "R2: 0.7386949754952057\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.1124 - val_loss: 1.0155\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0870 - val_loss: 1.0666\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0803 - val_loss: 1.0959\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0807 - val_loss: 1.0473\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0820 - val_loss: 1.0583\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0782 - val_loss: 1.0264\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0791 - val_loss: 1.0352\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0777 - val_loss: 0.9894\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0773 - val_loss: 0.9735\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0676 - val_loss: 1.0020\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0739 - val_loss: 0.8595\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0633 - val_loss: 0.7174\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0423 - val_loss: 0.2241\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0129 - val_loss: 0.0068\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4178e-04 - val_loss: 0.0233\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5058e-04 - val_loss: 0.0147\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8589e-04 - val_loss: 0.0147\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5310e-04 - val_loss: 0.0189\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4458e-04 - val_loss: 0.0179\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6569e-04 - val_loss: 0.0202\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2020e-04 - val_loss: 0.0219\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7885e-04 - val_loss: 0.0195\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1052e-04 - val_loss: 0.0203\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6977e-04 - val_loss: 0.0212\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4465e-04 - val_loss: 0.0232\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8355e-04 - val_loss: 0.0204\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0510e-04 - val_loss: 0.0216\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0324e-04 - val_loss: 0.0198\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8887e-04 - val_loss: 0.0244\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8661e-04 - val_loss: 0.0257\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0020e-04 - val_loss: 0.0229\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8309e-04 - val_loss: 0.0217\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9603e-04 - val_loss: 0.0219\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2345e-04 - val_loss: 0.0219\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7532e-04 - val_loss: 0.0240\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0735e-04 - val_loss: 0.0203\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6994e-04 - val_loss: 0.0219\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6410e-04 - val_loss: 0.0230\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9649e-04 - val_loss: 0.0197\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9363e-04 - val_loss: 0.0239\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8185e-04 - val_loss: 0.0206\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0250\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9458e-04 - val_loss: 0.0198\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1607e-04 - val_loss: 0.0239\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9764e-04 - val_loss: 0.0210\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6010e-04 - val_loss: 0.0214\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8207e-04 - val_loss: 0.0238\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6657e-04 - val_loss: 0.0207\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2806e-04 - val_loss: 0.0235\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 9\n",
      "MAE: 0.4682101499838896\n",
      "MSE: 0.2872792543442765\n",
      "RMSE: 0.535984378824865\n",
      "R2: 0.5143443146003486\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1797 - val_loss: 1.3628\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0968 - val_loss: 0.9795\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0857 - val_loss: 1.0505\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0817 - val_loss: 1.0697\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0832 - val_loss: 1.0398\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0802 - val_loss: 1.0434\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0756 - val_loss: 1.0119\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0812 - val_loss: 1.0046\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0780 - val_loss: 0.9761\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0730 - val_loss: 0.9418\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0743 - val_loss: 0.9741\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0715 - val_loss: 0.7690\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0626 - val_loss: 0.7879\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0552 - val_loss: 0.5760\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0352 - val_loss: 0.2672\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0160 - val_loss: 0.0586\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0246\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0601e-04 - val_loss: 0.0260\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9659e-04 - val_loss: 0.0312\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5718e-04 - val_loss: 0.0320\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5267e-04 - val_loss: 0.0318\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4388e-04 - val_loss: 0.0289\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9674e-04 - val_loss: 0.0314\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0001e-04 - val_loss: 0.0303\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4419e-04 - val_loss: 0.0261\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2217e-04 - val_loss: 0.0298\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5014e-04 - val_loss: 0.0279\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7548e-04 - val_loss: 0.0271\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1863e-04 - val_loss: 0.0294\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4534e-04 - val_loss: 0.0278\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1785e-04 - val_loss: 0.0277\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0080e-04 - val_loss: 0.0288\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9712e-04 - val_loss: 0.0277\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7437e-04 - val_loss: 0.0269\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9892e-04 - val_loss: 0.0250\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9159e-04 - val_loss: 0.0307\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0150e-04 - val_loss: 0.0255\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9400e-04 - val_loss: 0.0273\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2570e-04 - val_loss: 0.0266\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0298\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5056e-04 - val_loss: 0.0254\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1292e-04 - val_loss: 0.0276\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2557e-04 - val_loss: 0.0275\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3317e-04 - val_loss: 0.0281\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6770e-04 - val_loss: 0.0265\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2389e-04 - val_loss: 0.0278\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5276e-04 - val_loss: 0.0244\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1563e-04 - val_loss: 0.0259\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1815e-04 - val_loss: 0.0258\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7935e-04 - val_loss: 0.0296\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 10\n",
      "MAE: 0.5336803608253342\n",
      "MSE: 0.3624629791257768\n",
      "RMSE: 0.6020489839919811\n",
      "R2: 0.3872435830386447\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0956 - val_loss: 0.7217\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0836 - val_loss: 0.8496\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0813 - val_loss: 0.8023\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0770 - val_loss: 0.8109\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0828 - val_loss: 0.7641\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0794 - val_loss: 0.7927\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0697 - val_loss: 0.7201\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0709 - val_loss: 0.7553\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0691 - val_loss: 0.6686\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0632 - val_loss: 0.6042\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0573 - val_loss: 0.4674\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0389 - val_loss: 0.1530\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0119 - val_loss: 0.0045\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3102e-04 - val_loss: 0.0049\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3652e-04 - val_loss: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2325e-04 - val_loss: 0.0031\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3361e-04 - val_loss: 0.0056\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6134e-04 - val_loss: 0.0032\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6358e-04 - val_loss: 0.0043\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5427e-04 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1250e-04 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5153e-04 - val_loss: 0.0066\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0813e-04 - val_loss: 0.0052\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1292e-04 - val_loss: 0.0057\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4048e-04 - val_loss: 0.0059\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9497e-04 - val_loss: 0.0066\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8953e-04 - val_loss: 0.0065\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9251e-04 - val_loss: 0.0066\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8793e-04 - val_loss: 0.0078\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8777e-04 - val_loss: 0.0083\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9540e-04 - val_loss: 0.0075\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4392e-04 - val_loss: 0.0077\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1611e-04 - val_loss: 0.0068\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3310e-04 - val_loss: 0.0090\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7749e-04 - val_loss: 0.0091\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4787e-04 - val_loss: 0.0069\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9182e-04 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2016e-04 - val_loss: 0.0085\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1489e-04 - val_loss: 0.0083\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5688e-04 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9323e-04 - val_loss: 0.0066\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2242e-04 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7095e-04 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2039e-04 - val_loss: 0.0099\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0459e-04 - val_loss: 0.0071\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4692e-04 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7032e-04 - val_loss: 0.0086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 1\n",
      "MAE: 0.2945618238605437\n",
      "MSE: 0.12120750523931226\n",
      "RMSE: 0.34814868266203775\n",
      "R2: 0.6273436858165073\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.1659 - val_loss: 1.1607\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0900 - val_loss: 0.7565\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0855 - val_loss: 0.8009\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0804 - val_loss: 0.8298\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0822 - val_loss: 0.8048\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0740 - val_loss: 0.7924\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0782 - val_loss: 0.7904\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0768 - val_loss: 0.7915\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0730 - val_loss: 0.7607\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0752 - val_loss: 0.7643\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0794 - val_loss: 0.7406\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0669 - val_loss: 0.6308\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0646 - val_loss: 0.5542\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0558 - val_loss: 0.3744\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0362 - val_loss: 0.1671\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3469e-04 - val_loss: 0.0106\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0023e-04 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9374e-04 - val_loss: 0.0124\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0563e-04 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4086e-04 - val_loss: 0.0143\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0847e-04 - val_loss: 0.0149\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5629e-04 - val_loss: 0.0158\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2309e-04 - val_loss: 0.0165\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5895e-04 - val_loss: 0.0151\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5388e-04 - val_loss: 0.0166\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9160e-04 - val_loss: 0.0167\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9394e-04 - val_loss: 0.0167\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2074e-04 - val_loss: 0.0150\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2990e-04 - val_loss: 0.0176\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2534e-04 - val_loss: 0.0160\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5725e-04 - val_loss: 0.0175\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5465e-04 - val_loss: 0.0175\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7183e-04 - val_loss: 0.0167\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7352e-04 - val_loss: 0.0165\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3366e-04 - val_loss: 0.0163\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5595e-04 - val_loss: 0.0177\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7797e-04 - val_loss: 0.0180\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9185e-04 - val_loss: 0.0153\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9545e-04 - val_loss: 0.0160\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6445e-04 - val_loss: 0.0156\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7585e-04 - val_loss: 0.0168\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2686e-04 - val_loss: 0.0169\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3143e-04 - val_loss: 0.0145\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0403e-04 - val_loss: 0.0199\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4829e-04 - val_loss: 0.0142\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6457e-04 - val_loss: 0.0180\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2897e-04 - val_loss: 0.0171\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 2\n",
      "MAE: 0.4346330361288102\n",
      "MSE: 0.24095339813477756\n",
      "RMSE: 0.49087004200172735\n",
      "R2: 0.25918114508167767\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.1154 - val_loss: 0.7450\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0794 - val_loss: 0.8297\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0846 - val_loss: 0.8050\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0741 - val_loss: 0.7853\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0779 - val_loss: 0.7771\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0810 - val_loss: 0.8064\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0770 - val_loss: 0.7587\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0688 - val_loss: 0.7247\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0710 - val_loss: 0.6699\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0616 - val_loss: 0.5856\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0549 - val_loss: 0.4462\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0402 - val_loss: 0.2480\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0205 - val_loss: 0.0289\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2537e-04 - val_loss: 0.0049\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5386e-04 - val_loss: 0.0065\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1443e-04 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1205e-04 - val_loss: 0.0055\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4653e-04 - val_loss: 0.0074\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6707e-04 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6717e-04 - val_loss: 0.0068\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5137e-04 - val_loss: 0.0064\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6064e-04 - val_loss: 0.0079\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4295e-04 - val_loss: 0.0079\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9798e-04 - val_loss: 0.0078\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3686e-04 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4132e-04 - val_loss: 0.0051\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.1278e-04 - val_loss: 0.0072\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2679e-04 - val_loss: 0.0098\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4751e-04 - val_loss: 0.0099\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9067e-04 - val_loss: 0.0090\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6018e-04 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1150e-04 - val_loss: 0.0092\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7724e-04 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2207e-04 - val_loss: 0.0077\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8349e-04 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0631e-04 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1964e-04 - val_loss: 0.0077\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0575e-04 - val_loss: 0.0117\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0670e-04 - val_loss: 0.0070\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8222e-04 - val_loss: 0.0127\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8741e-04 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9787e-04 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5246e-04 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1506e-04 - val_loss: 0.0099\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8644e-04 - val_loss: 0.0111\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1102e-04 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7663e-04 - val_loss: 0.0118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 3\n",
      "MAE: 0.36253836115852733\n",
      "MSE: 0.16654270129703916\n",
      "RMSE: 0.4080964362709373\n",
      "R2: 0.48795918951570405\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.1756 - val_loss: 0.8450\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0808 - val_loss: 0.7721\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0781 - val_loss: 0.8639\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0735 - val_loss: 0.7859\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0794 - val_loss: 0.8219\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0694 - val_loss: 0.7602\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0770 - val_loss: 0.7919\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0778 - val_loss: 0.7891\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0762 - val_loss: 0.7301\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0724 - val_loss: 0.6984\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0654 - val_loss: 0.6394\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0661 - val_loss: 0.5230\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0461 - val_loss: 0.2805\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0241 - val_loss: 0.0849\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1340e-04 - val_loss: 0.0059\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1008e-04 - val_loss: 0.0056\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5279e-04 - val_loss: 0.0039\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4700e-04 - val_loss: 0.0056\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6221e-04 - val_loss: 0.0045\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0758e-04 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4830e-04 - val_loss: 0.0061\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7920e-04 - val_loss: 0.0061\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7129e-04 - val_loss: 0.0058\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1246e-04 - val_loss: 0.0070\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7752e-04 - val_loss: 0.0078\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3030e-04 - val_loss: 0.0078\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3939e-04 - val_loss: 0.0082\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0022e-04 - val_loss: 0.0073\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2498e-04 - val_loss: 0.0067\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4594e-04 - val_loss: 0.0067\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7914e-04 - val_loss: 0.0064\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8261e-04 - val_loss: 0.0077\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0582e-04 - val_loss: 0.0067\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5569e-04 - val_loss: 0.0093\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0185e-04 - val_loss: 0.0068\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1382e-04 - val_loss: 0.0101\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.6341e-04 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2999e-04 - val_loss: 0.0081\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2554e-04 - val_loss: 0.0077\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9993e-04 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1054e-04 - val_loss: 0.0069\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0425e-04 - val_loss: 0.0077\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9346e-04 - val_loss: 0.0088\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1014e-04 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8711e-04 - val_loss: 0.0075\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6684e-04 - val_loss: 0.0091\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6104e-04 - val_loss: 0.0074\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2306e-04 - val_loss: 0.0096\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 4\n",
      "MAE: 0.32145696389870565\n",
      "MSE: 0.13479277947947252\n",
      "RMSE: 0.36714136171163353\n",
      "R2: 0.5855753298428867\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.1715 - val_loss: 0.8525\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0780 - val_loss: 0.7524\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0749 - val_loss: 0.8350\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0782 - val_loss: 0.8127\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0763 - val_loss: 0.7799\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0769 - val_loss: 0.7993\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0842 - val_loss: 0.7682\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0813 - val_loss: 0.7820\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0753 - val_loss: 0.7423\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0776 - val_loss: 0.7391\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0729 - val_loss: 0.7155\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0676 - val_loss: 0.6219\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0627 - val_loss: 0.5251\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0478 - val_loss: 0.4162\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0418 - val_loss: 0.2116\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0219 - val_loss: 0.0401\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4168e-04 - val_loss: 0.0016\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2461e-04 - val_loss: 0.0040\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9331e-04 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8417e-04 - val_loss: 0.0036\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0240e-04 - val_loss: 0.0044\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3665e-04 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7932e-04 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5290e-04 - val_loss: 0.0057\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2487e-04 - val_loss: 0.0046\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5574e-04 - val_loss: 0.0049\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9207e-04 - val_loss: 0.0052\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2759e-04 - val_loss: 0.0056\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7893e-04 - val_loss: 0.0058\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8144e-04 - val_loss: 0.0063\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3502e-04 - val_loss: 0.0058\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0133e-04 - val_loss: 0.0062\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2211e-04 - val_loss: 0.0063\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4300e-04 - val_loss: 0.0056\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7369e-04 - val_loss: 0.0064\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1640e-04 - val_loss: 0.0061\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2083e-04 - val_loss: 0.0076\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8319e-04 - val_loss: 0.0064\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0799e-04 - val_loss: 0.0064\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6697e-04 - val_loss: 0.0052\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6663e-04 - val_loss: 0.0060\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6137e-04 - val_loss: 0.0067\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1250e-04 - val_loss: 0.0072\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0220e-04 - val_loss: 0.0055\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5343e-04 - val_loss: 0.0055\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3691e-04 - val_loss: 0.0054\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1029e-04 - val_loss: 0.0072\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9117e-04 - val_loss: 0.0068\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1318e-04 - val_loss: 0.0067\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 5\n",
      "MAE: 0.256390712300285\n",
      "MSE: 0.09470358898852282\n",
      "RMSE: 0.307739482336152\n",
      "R2: 0.708830815858053\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.2042 - val_loss: 1.2542\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1158 - val_loss: 0.8518\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0798 - val_loss: 0.7639\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0742 - val_loss: 0.8226\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0769 - val_loss: 0.8292\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0775 - val_loss: 0.8076\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0816 - val_loss: 0.8103\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0753 - val_loss: 0.7953\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0765 - val_loss: 0.7722\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0740 - val_loss: 0.7809\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0779 - val_loss: 0.7503\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0721 - val_loss: 0.7545\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0749 - val_loss: 0.7113\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0660 - val_loss: 0.6437\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0599 - val_loss: 0.5186\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0535 - val_loss: 0.3902\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0332 - val_loss: 0.1069\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0135\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8829e-04 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0520e-04 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7284e-04 - val_loss: 0.0130\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6202e-04 - val_loss: 0.0153\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2974e-04 - val_loss: 0.0158\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8585e-04 - val_loss: 0.0156\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6957e-04 - val_loss: 0.0174\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6804e-04 - val_loss: 0.0173\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6608e-04 - val_loss: 0.0160\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1074e-04 - val_loss: 0.0173\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1095e-04 - val_loss: 0.0182\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.1179e-04 - val_loss: 0.0165\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3952e-04 - val_loss: 0.0164\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3616e-04 - val_loss: 0.0161\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0748e-04 - val_loss: 0.0164\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0020e-04 - val_loss: 0.0174\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7850e-04 - val_loss: 0.0166\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7860e-04 - val_loss: 0.0162\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6843e-04 - val_loss: 0.0171\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3424e-04 - val_loss: 0.0199\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7835e-04 - val_loss: 0.0159\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4713e-04 - val_loss: 0.0182\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1040e-04 - val_loss: 0.0178\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7668e-04 - val_loss: 0.0165\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8532e-04 - val_loss: 0.0171\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9820e-04 - val_loss: 0.0169\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9011e-04 - val_loss: 0.0136\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4665e-04 - val_loss: 0.0170\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9067e-04 - val_loss: 0.0171\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5925e-04 - val_loss: 0.0143\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 6\n",
      "MAE: 0.3815474275682793\n",
      "MSE: 0.20150282804633074\n",
      "RMSE: 0.4488906637994722\n",
      "R2: 0.38047317244063916\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.1021 - val_loss: 0.7022\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0811 - val_loss: 0.8260\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0840 - val_loss: 0.8082\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0781 - val_loss: 0.7717\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0732 - val_loss: 0.7836\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0755 - val_loss: 0.7348\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0701 - val_loss: 0.7699\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0718 - val_loss: 0.6728\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0626 - val_loss: 0.6856\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0677 - val_loss: 0.5723\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0532 - val_loss: 0.4598\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0370 - val_loss: 0.2582\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0174 - val_loss: 0.0254\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6318e-04 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0906e-04 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7235e-04 - val_loss: 0.0024\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9039e-04 - val_loss: 0.0023\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0572e-04 - val_loss: 0.0022\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7271e-04 - val_loss: 0.0035\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8520e-04 - val_loss: 0.0030\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1919e-04 - val_loss: 0.0041\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6623e-04 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9573e-04 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1445e-04 - val_loss: 0.0051\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0715e-04 - val_loss: 0.0040\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6814e-04 - val_loss: 0.0043\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0489e-04 - val_loss: 0.0052\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9404e-04 - val_loss: 0.0050\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2084e-04 - val_loss: 0.0060\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6625e-04 - val_loss: 0.0062\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1747e-04 - val_loss: 0.0055\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2100e-04 - val_loss: 0.0084\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9230e-04 - val_loss: 0.0047\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4538e-04 - val_loss: 0.0078\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1892e-04 - val_loss: 0.0070\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9585e-04 - val_loss: 0.0062\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5010e-04 - val_loss: 0.0057\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5836e-04 - val_loss: 0.0078\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5948e-04 - val_loss: 0.0051\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4204e-04 - val_loss: 0.0074\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7561e-04 - val_loss: 0.0081\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5317e-04 - val_loss: 0.0079\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2484e-04 - val_loss: 0.0063\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5599e-04 - val_loss: 0.0081\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7903e-04 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4805e-04 - val_loss: 0.0065\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4848e-04 - val_loss: 0.0078\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6918e-04 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2918e-04 - val_loss: 0.0078\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 7\n",
      "MAE: 0.2838172365407475\n",
      "MSE: 0.1099459079598285\n",
      "RMSE: 0.3315809221891822\n",
      "R2: 0.6619678233705745\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.1693 - val_loss: 1.0983\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0872 - val_loss: 0.7545\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0778 - val_loss: 0.8238\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0801 - val_loss: 0.8393\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0762 - val_loss: 0.8304\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0754 - val_loss: 0.8160\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0854 - val_loss: 0.8077\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0760 - val_loss: 0.8179\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0766 - val_loss: 0.7810\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0825 - val_loss: 0.8140\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0752 - val_loss: 0.7765\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0748 - val_loss: 0.7848\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0836 - val_loss: 0.7625\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0671 - val_loss: 0.6382\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0695 - val_loss: 0.6216\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0524 - val_loss: 0.4080\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0393 - val_loss: 0.1724\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8570e-04 - val_loss: 0.0100\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0904e-04 - val_loss: 0.0094\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1507e-04 - val_loss: 0.0078\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6431e-04 - val_loss: 0.0104\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0331e-04 - val_loss: 0.0103\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3711e-04 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7181e-04 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3584e-04 - val_loss: 0.0098\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8382e-04 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1884e-04 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2841e-04 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6121e-04 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2419e-04 - val_loss: 0.0108\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8216e-04 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9750e-04 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8542e-04 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4868e-04 - val_loss: 0.0096\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7694e-04 - val_loss: 0.0124\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8283e-04 - val_loss: 0.0122\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4900e-04 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6846e-04 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1677e-04 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1207e-04 - val_loss: 0.0136\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1367e-04 - val_loss: 0.0127\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8599e-04 - val_loss: 0.0097\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3997e-04 - val_loss: 0.0141\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2218e-04 - val_loss: 0.0131\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6900e-04 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1998e-04 - val_loss: 0.0134\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4697e-04 - val_loss: 0.0111\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.1971e-04 - val_loss: 0.0117\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 8\n",
      "MAE: 0.34685999448182153\n",
      "MSE: 0.16435580951517786\n",
      "RMSE: 0.4054082010951158\n",
      "R2: 0.494682857570232\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.1997 - val_loss: 0.9736\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0897 - val_loss: 0.7119\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0801 - val_loss: 0.8394\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0823 - val_loss: 0.8078\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0742 - val_loss: 0.7900\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0801 - val_loss: 0.7621\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0705 - val_loss: 0.7937\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0724 - val_loss: 0.7370\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0755 - val_loss: 0.7588\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0669 - val_loss: 0.7212\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0665 - val_loss: 0.6835\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0634 - val_loss: 0.5893\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0587 - val_loss: 0.4904\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0378 - val_loss: 0.3776\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0285 - val_loss: 0.0808\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5758e-04 - val_loss: 0.0029\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6485e-04 - val_loss: 0.0023\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5994e-04 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7612e-04 - val_loss: 0.0022\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1681e-04 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6675e-04 - val_loss: 0.0031\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9702e-04 - val_loss: 0.0017\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5688e-04 - val_loss: 0.0025\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3420e-04 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6083e-04 - val_loss: 0.0024\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9451e-04 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2461e-04 - val_loss: 0.0041\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5831e-04 - val_loss: 0.0027\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6149e-04 - val_loss: 0.0032\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5463e-04 - val_loss: 0.0034\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4709e-04 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9063e-04 - val_loss: 0.0041\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8023e-04 - val_loss: 0.0046\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6453e-04 - val_loss: 0.0048\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5511e-04 - val_loss: 0.0039\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3388e-04 - val_loss: 0.0040\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9158e-04 - val_loss: 0.0039\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1474e-04 - val_loss: 0.0047\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5523e-04 - val_loss: 0.0051\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0788e-04 - val_loss: 0.0049\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0323e-04 - val_loss: 0.0044\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8070e-04 - val_loss: 0.0064\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9560e-04 - val_loss: 0.0051\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7859e-04 - val_loss: 0.0056\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9073e-04 - val_loss: 0.0056\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7311e-04 - val_loss: 0.0043\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9837e-04 - val_loss: 0.0081\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8958e-04 - val_loss: 0.0039\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 9\n",
      "MAE: 0.20570345393946912\n",
      "MSE: 0.05519631016436431\n",
      "RMSE: 0.2349389498664798\n",
      "R2: 0.8302971960212455\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.1205 - val_loss: 0.7497\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0816 - val_loss: 0.8146\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0813 - val_loss: 0.8173\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0776 - val_loss: 0.8068\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0721 - val_loss: 0.7711\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0739 - val_loss: 0.7731\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0707 - val_loss: 0.7260\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0712 - val_loss: 0.7221\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0655 - val_loss: 0.6133\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0606 - val_loss: 0.4584\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0466 - val_loss: 0.2702\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0279 - val_loss: 0.0844\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6428e-04 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2308e-04 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6746e-04 - val_loss: 0.0061\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3459e-04 - val_loss: 0.0059\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6755e-04 - val_loss: 0.0040\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1856e-04 - val_loss: 0.0064\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.2406e-04 - val_loss: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7806e-04 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2796e-04 - val_loss: 0.0074\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5167e-04 - val_loss: 0.0083\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6400e-04 - val_loss: 0.0068\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7331e-04 - val_loss: 0.0079\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2696e-04 - val_loss: 0.0089\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6769e-04 - val_loss: 0.0088\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6442e-04 - val_loss: 0.0083\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9183e-04 - val_loss: 0.0076\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6466e-04 - val_loss: 0.0086\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5934e-04 - val_loss: 0.0101\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7319e-04 - val_loss: 0.0089\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4272e-04 - val_loss: 0.0096\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3310e-04 - val_loss: 0.0082\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.9828e-04 - val_loss: 0.0084\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8991e-04 - val_loss: 0.0102\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1317e-04 - val_loss: 0.0090\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0376e-04 - val_loss: 0.0080\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6099e-04 - val_loss: 0.0092\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5239e-04 - val_loss: 0.0122\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3789e-04 - val_loss: 0.0093\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.2481e-04 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9518e-04 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1290e-04 - val_loss: 0.0091\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0727e-04 - val_loss: 0.0081\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0256e-04 - val_loss: 0.0127\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1804e-04 - val_loss: 0.0101\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1560e-04 - val_loss: 0.0110\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8130e-04 - val_loss: 0.0122\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6738e-04 - val_loss: 0.0087\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 10\n",
      "MAE: 0.2946328100610952\n",
      "MSE: 0.12209738405171579\n",
      "RMSE: 0.3494243609877763\n",
      "R2: 0.6246077252202923\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.1398 - val_loss: 0.2941\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0826 - val_loss: 0.2027\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0768 - val_loss: 0.2597\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0744 - val_loss: 0.2342\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0758 - val_loss: 0.2362\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0762 - val_loss: 0.2306\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0732 - val_loss: 0.2379\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0770 - val_loss: 0.2353\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0735 - val_loss: 0.2260\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0732 - val_loss: 0.2259\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0678 - val_loss: 0.2241\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0782 - val_loss: 0.2201\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0699 - val_loss: 0.2178\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0687 - val_loss: 0.1898\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0668 - val_loss: 0.1861\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0628 - val_loss: 0.1902\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0508 - val_loss: 0.1489\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0387 - val_loss: 0.0634\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0143 - val_loss: 0.0156\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 9.2588e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.5955e-04 - val_loss: 9.8308e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2908e-04 - val_loss: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7279e-04 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5075e-04 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.1328e-04 - val_loss: 9.7348e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.2016e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8658e-04 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0386e-04 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0817e-04 - val_loss: 9.4367e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8512e-04 - val_loss: 9.2008e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3266e-04 - val_loss: 9.3271e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4989e-04 - val_loss: 9.4833e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9967e-04 - val_loss: 9.3569e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5635e-04 - val_loss: 9.8612e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3803e-04 - val_loss: 9.9334e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3435e-04 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4954e-04 - val_loss: 9.2584e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.6389e-04 - val_loss: 0.0012\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.7251e-04 - val_loss: 9.1787e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.1477e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6104e-04 - val_loss: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4612e-04 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4196e-04 - val_loss: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 9.1645e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7477e-04 - val_loss: 9.4572e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 1\n",
      "MAE: 0.05620773815717849\n",
      "MSE: 0.0166825107480887\n",
      "RMSE: 0.1291607941601812\n",
      "R2: 0.851332120906217\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.2091 - val_loss: 0.3996\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0888 - val_loss: 0.1903\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0769 - val_loss: 0.2276\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0726 - val_loss: 0.2446\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0742 - val_loss: 0.2208\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0787 - val_loss: 0.2377\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0738 - val_loss: 0.2288\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0793 - val_loss: 0.2237\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0715 - val_loss: 0.2204\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0820 - val_loss: 0.2231\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0651 - val_loss: 0.1969\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0690 - val_loss: 0.2086\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0595 - val_loss: 0.1587\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0580 - val_loss: 0.1814\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0533 - val_loss: 0.1744\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0399 - val_loss: 0.0671\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0179 - val_loss: 0.0101\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0295e-04 - val_loss: 9.1924e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 9.4512e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.0055e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0795e-04 - val_loss: 9.2707e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 9.5585e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6891e-04 - val_loss: 0.0016\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6129e-04 - val_loss: 8.9673e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7939e-04 - val_loss: 9.2941e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.7698e-04 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 9.8256e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3889e-04 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5199e-04 - val_loss: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8753e-04 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2628e-04 - val_loss: 9.7332e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9888e-04 - val_loss: 9.8865e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3157e-04 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3469e-04 - val_loss: 0.0015\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4604e-04 - val_loss: 9.9606e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9417e-04 - val_loss: 9.3460e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4487e-04 - val_loss: 8.9886e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7500e-04 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4915e-04 - val_loss: 9.6609e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8215e-04 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0097e-04 - val_loss: 9.8034e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1574e-04 - val_loss: 0.0013\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 2\n",
      "MAE: 0.10738904358910732\n",
      "MSE: 0.0231182149304022\n",
      "RMSE: 0.15204675244937724\n",
      "R2: 0.7939796932226829\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.1588 - val_loss: 0.3376\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0916 - val_loss: 0.1899\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0829 - val_loss: 0.2529\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0735 - val_loss: 0.2313\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0759 - val_loss: 0.2304\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0694 - val_loss: 0.2289\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0761 - val_loss: 0.2329\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0785 - val_loss: 0.2287\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0755 - val_loss: 0.2182\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0664 - val_loss: 0.2068\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0630 - val_loss: 0.2066\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0624 - val_loss: 0.1628\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0586 - val_loss: 0.1490\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0465 - val_loss: 0.0887\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0311 - val_loss: 0.0172\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.1163e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.3667e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.6496e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1526e-04 - val_loss: 0.0020\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.4390e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9415e-04 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9503e-04 - val_loss: 9.0644e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0827e-04 - val_loss: 9.7185e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2678e-04 - val_loss: 9.1385e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9713e-04 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5293e-04 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7453e-04 - val_loss: 8.8604e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0490e-04 - val_loss: 9.7951e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 8.8422e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1519e-04 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1835e-04 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6228e-04 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.9964e-04 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 9.0468e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0703e-04 - val_loss: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9962e-04 - val_loss: 9.6324e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8201e-04 - val_loss: 0.0014\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8956e-04 - val_loss: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9723e-04 - val_loss: 8.8700e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4696e-04 - val_loss: 0.0014\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9679e-04 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4070e-04 - val_loss: 9.2863e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6778e-04 - val_loss: 9.1656e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1851e-04 - val_loss: 8.8914e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3200e-04 - val_loss: 9.9681e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3523e-04 - val_loss: 9.6020e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 3\n",
      "MAE: 0.06764152089103322\n",
      "MSE: 0.016937979292348145\n",
      "RMSE: 0.1301459922254548\n",
      "R2: 0.8490554871774134\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.1728 - val_loss: 0.3303\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0699 - val_loss: 0.1796\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0792 - val_loss: 0.2422\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0767 - val_loss: 0.2315\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0699 - val_loss: 0.2173\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0674 - val_loss: 0.2343\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0741 - val_loss: 0.2098\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0711 - val_loss: 0.2159\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0682 - val_loss: 0.2148\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0620 - val_loss: 0.2009\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0661 - val_loss: 0.1938\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0637 - val_loss: 0.2009\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0496 - val_loss: 0.1266\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0386 - val_loss: 0.0697\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0186 - val_loss: 0.0221\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0055 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3701e-04 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0959e-04 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9659e-04 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0593e-04 - val_loss: 9.1497e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5956e-04 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6309e-04 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.6469e-04 - val_loss: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8907e-04 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0800e-04 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 9.2006e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6415e-04 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7044e-04 - val_loss: 9.2226e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4171e-04 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.9204e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2913e-04 - val_loss: 9.6342e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3242e-04 - val_loss: 9.5659e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4915e-04 - val_loss: 9.0581e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3510e-04 - val_loss: 9.0895e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6654e-04 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.3207e-04 - val_loss: 9.2021e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0926e-04 - val_loss: 9.6454e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9451e-04 - val_loss: 9.1101e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 9.0546e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.1357e-04 - val_loss: 9.2170e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2413e-04 - val_loss: 9.5390e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1521e-04 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 4\n",
      "MAE: 0.07924267815761878\n",
      "MSE: 0.01855036153022395\n",
      "RMSE: 0.13619971193150135\n",
      "R2: 0.8346865800498728\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.1826 - val_loss: 0.3933\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0909 - val_loss: 0.2040\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0749 - val_loss: 0.2254\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0771 - val_loss: 0.2445\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0760 - val_loss: 0.2350\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0699 - val_loss: 0.2314\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0758 - val_loss: 0.2271\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0747 - val_loss: 0.2231\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0687 - val_loss: 0.2210\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0648 - val_loss: 0.2066\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0722 - val_loss: 0.2221\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0643 - val_loss: 0.1776\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0618 - val_loss: 0.2049\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0584 - val_loss: 0.1596\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0466 - val_loss: 0.1092\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0268 - val_loss: 0.0192\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0083 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4412e-04 - val_loss: 9.1731e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1676e-04 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9581e-04 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 9.1788e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4354e-04 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4398e-04 - val_loss: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8550e-04 - val_loss: 9.4360e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1064e-04 - val_loss: 9.8565e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1979e-04 - val_loss: 9.3105e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.8503e-04 - val_loss: 9.4160e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.5284e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4765e-04 - val_loss: 9.4791e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1997e-04 - val_loss: 9.3851e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8892e-04 - val_loss: 9.2271e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8079e-04 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4485e-04 - val_loss: 0.0014\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.2210e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0854e-04 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 9.3028e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 9.7956e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8647e-04 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2330e-04 - val_loss: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8600e-04 - val_loss: 9.4829e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 5\n",
      "MAE: 0.07166236345885221\n",
      "MSE: 0.016727837687304865\n",
      "RMSE: 0.1293361422314152\n",
      "R2: 0.8509281853103804\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.1487 - val_loss: 0.2452\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0819 - val_loss: 0.2105\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0721 - val_loss: 0.2521\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0732 - val_loss: 0.2170\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0724 - val_loss: 0.2250\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0755 - val_loss: 0.2234\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0680 - val_loss: 0.2031\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0695 - val_loss: 0.2022\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0729 - val_loss: 0.2177\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0665 - val_loss: 0.1969\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0638 - val_loss: 0.1766\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0552 - val_loss: 0.0909\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0491 - val_loss: 0.0868\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0363 - val_loss: 0.0713\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0222 - val_loss: 0.0156\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 9.5456e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.9147e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3088e-04 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8537e-04 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 9.2309e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9367e-04 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0765e-04 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.5322e-04 - val_loss: 9.1664e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4504e-04 - val_loss: 9.1361e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2743e-04 - val_loss: 0.0015\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 9.6215e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7067e-04 - val_loss: 9.8277e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7374e-04 - val_loss: 9.5051e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 9.5444e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7638e-04 - val_loss: 9.7842e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9735e-04 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0520e-04 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5255e-04 - val_loss: 9.2069e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 9.6959e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 6\n",
      "MAE: 0.07574503851718589\n",
      "MSE: 0.017996602294161196\n",
      "RMSE: 0.13415141555034443\n",
      "R2: 0.8396214613994009\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.1519 - val_loss: 0.3132\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0823 - val_loss: 0.1971\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0754 - val_loss: 0.2455\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0765 - val_loss: 0.2336\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0729 - val_loss: 0.2347\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0712 - val_loss: 0.2343\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0705 - val_loss: 0.2296\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0753 - val_loss: 0.2238\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0704 - val_loss: 0.2284\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0701 - val_loss: 0.2187\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0718 - val_loss: 0.2091\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0664 - val_loss: 0.1919\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0667 - val_loss: 0.2066\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0593 - val_loss: 0.1646\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0581 - val_loss: 0.1094\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0447 - val_loss: 0.0774\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0265 - val_loss: 0.0281\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0072 - val_loss: 0.0020\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 9.9345e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0493e-04 - val_loss: 9.0789e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 8.9621e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7361e-04 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6846e-04 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1813e-04 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9799e-04 - val_loss: 9.0382e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2068e-04 - val_loss: 9.0985e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9911e-04 - val_loss: 9.0732e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8810e-04 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7335e-04 - val_loss: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 8.9593e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3317e-04 - val_loss: 9.6465e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3138e-04 - val_loss: 9.8003e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5481e-04 - val_loss: 9.0356e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8298e-04 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4584e-04 - val_loss: 9.0932e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2237e-04 - val_loss: 9.0557e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7292e-04 - val_loss: 9.0923e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2671e-04 - val_loss: 9.2343e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1623e-04 - val_loss: 0.0012\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2984e-04 - val_loss: 9.3986e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6311e-04 - val_loss: 9.0265e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3553e-04 - val_loss: 9.3821e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3399e-04 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3339e-04 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9251e-04 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0913e-04 - val_loss: 9.1446e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 7\n",
      "MAE: 0.053550652988621404\n",
      "MSE: 0.016131111737508554\n",
      "RMSE: 0.12700831365508541\n",
      "R2: 0.8562459688680265\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.1584 - val_loss: 0.2488\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0757 - val_loss: 0.1985\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0758 - val_loss: 0.2583\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0788 - val_loss: 0.2153\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0757 - val_loss: 0.2214\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0742 - val_loss: 0.2232\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0733 - val_loss: 0.2074\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0728 - val_loss: 0.2167\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0637 - val_loss: 0.2018\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0656 - val_loss: 0.1633\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0569 - val_loss: 0.1698\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0550 - val_loss: 0.1777\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0494 - val_loss: 0.1054\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0357 - val_loss: 0.0674\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0171 - val_loss: 0.0083\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0062\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 9.3332e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 9.9304e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1646e-04 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.2678e-04 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6269e-04 - val_loss: 9.4340e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6133e-04 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0676e-04 - val_loss: 9.4575e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9395e-04 - val_loss: 9.2202e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 9.9974e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7345e-04 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8449e-04 - val_loss: 9.5361e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0261e-04 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4969e-04 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7711e-04 - val_loss: 9.2824e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3288e-04 - val_loss: 9.1682e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0858e-04 - val_loss: 9.3150e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0171e-04 - val_loss: 9.2850e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0664e-04 - val_loss: 9.3291e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9835e-04 - val_loss: 0.0014\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 9.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 9.2494e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1846e-04 - val_loss: 0.0012\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.5098e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.1530e-04 - val_loss: 9.6499e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.6751e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4760e-04 - val_loss: 9.1648e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1782e-04 - val_loss: 9.1096e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 8\n",
      "MAE: 0.06123685836791983\n",
      "MSE: 0.016069364353786735\n",
      "RMSE: 0.1267649965636679\n",
      "R2: 0.8567962369131745\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.1686 - val_loss: 0.2805\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0688 - val_loss: 0.1868\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0727 - val_loss: 0.2413\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0704 - val_loss: 0.2309\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0691 - val_loss: 0.2104\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0703 - val_loss: 0.2137\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0731 - val_loss: 0.2124\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0657 - val_loss: 0.1931\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0589 - val_loss: 0.1942\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0658 - val_loss: 0.1498\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0457 - val_loss: 0.1055\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0303 - val_loss: 0.0543\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0136 - val_loss: 0.0054\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.1959e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.1666e-04 - val_loss: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.5842e-04 - val_loss: 9.0786e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9931e-04 - val_loss: 9.1978e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8868e-04 - val_loss: 9.3327e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 9.4038e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9428e-04 - val_loss: 0.0020\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9981e-04 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 9.2529e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7323e-04 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5267e-04 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9472e-04 - val_loss: 9.4723e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4911e-04 - val_loss: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1101e-04 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2397e-04 - val_loss: 9.1853e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.0254e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8318e-04 - val_loss: 9.0564e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0625e-04 - val_loss: 9.0349e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9590e-04 - val_loss: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3279e-04 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5131e-04 - val_loss: 9.6196e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0955e-04 - val_loss: 9.2400e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0727e-04 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6742e-04 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1855e-04 - val_loss: 9.2702e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0359e-04 - val_loss: 0.0014\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3796e-04 - val_loss: 0.0014\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7644e-04 - val_loss: 0.0011\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 9\n",
      "MAE: 0.08287289416203732\n",
      "MSE: 0.019037945692141293\n",
      "RMSE: 0.1379780623582651\n",
      "R2: 0.830341424555801\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1583 - val_loss: 0.2691\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0762 - val_loss: 0.2044\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0802 - val_loss: 0.2540\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0728 - val_loss: 0.2199\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0705 - val_loss: 0.2345\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0756 - val_loss: 0.2186\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0660 - val_loss: 0.2165\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0769 - val_loss: 0.2308\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0735 - val_loss: 0.1982\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0725 - val_loss: 0.2044\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0680 - val_loss: 0.1831\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0552 - val_loss: 0.1671\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0514 - val_loss: 0.1609\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0366 - val_loss: 0.0952\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0223 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 9.7075e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6205e-04 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0939e-04 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.2519e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4233e-04 - val_loss: 9.3341e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.1755e-04 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8444e-04 - val_loss: 9.3714e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1511e-04 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6662e-04 - val_loss: 9.3944e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8861e-04 - val_loss: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1101e-04 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7701e-04 - val_loss: 9.8400e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2310e-04 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7072e-04 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7240e-04 - val_loss: 9.3061e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4679e-04 - val_loss: 9.5472e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1144e-04 - val_loss: 9.0704e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1517e-04 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 9.6969e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 9.8373e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 9.7884e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7126e-04 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.4555e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9604e-04 - val_loss: 0.0012\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.0574e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3489e-04 - val_loss: 9.1423e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2901e-04 - val_loss: 9.0729e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 10\n",
      "MAE: 0.10529919921374706\n",
      "MSE: 0.02111240142544924\n",
      "RMSE: 0.14530107165967235\n",
      "R2: 0.8118547028145807\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.1483 - val_loss: 0.2069\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0825 - val_loss: 0.1640\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0761 - val_loss: 0.2202\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0835 - val_loss: 0.1931\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0755 - val_loss: 0.1946\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0778 - val_loss: 0.1885\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0718 - val_loss: 0.1849\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0735 - val_loss: 0.1808\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0741 - val_loss: 0.1885\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0658 - val_loss: 0.1539\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0702 - val_loss: 0.1736\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0562 - val_loss: 0.1321\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0555 - val_loss: 0.1390\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0448 - val_loss: 0.0983\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0274 - val_loss: 0.0169\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 8.8933e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 8.6925e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2358e-04 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 8.4294e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0713e-04 - val_loss: 8.3430e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.2522e-04 - val_loss: 8.3959e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0467e-04 - val_loss: 0.0013\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3410e-04 - val_loss: 0.0023\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 8.1552e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9632e-04 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3769e-04 - val_loss: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 8.5739e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1184e-04 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4090e-04 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4444e-04 - val_loss: 8.9620e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9357e-04 - val_loss: 9.6644e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9344e-04 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 8.7838e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8730e-04 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1951e-04 - val_loss: 8.8432e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2308e-04 - val_loss: 8.3902e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3703e-04 - val_loss: 8.5532e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 8.1497e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 8.2905e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 1\n",
      "MAE: 0.053190276661857175\n",
      "MSE: 0.013264847525686645\n",
      "RMSE: 0.11517311980530286\n",
      "R2: 0.8894942514595441\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.1747 - val_loss: 0.3104\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0761 - val_loss: 0.1588\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0808 - val_loss: 0.1983\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0773 - val_loss: 0.2061\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0728 - val_loss: 0.1949\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0745 - val_loss: 0.1893\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0831 - val_loss: 0.1954\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0759 - val_loss: 0.1917\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0684 - val_loss: 0.1813\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0682 - val_loss: 0.1807\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0651 - val_loss: 0.1846\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0671 - val_loss: 0.1234\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0563 - val_loss: 0.1187\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0494 - val_loss: 0.0852\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0300 - val_loss: 0.0493\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - val_loss: 0.0034\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 9.3141e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4353e-04 - val_loss: 9.3839e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 8.9202e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1856e-04 - val_loss: 8.8049e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 9.6971e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4464e-04 - val_loss: 9.5780e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0656e-04 - val_loss: 8.7061e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 8.7802e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7618e-04 - val_loss: 9.5382e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 8.6841e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 8.5809e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1768e-04 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7672e-04 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 9.5183e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 8.5784e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6614e-04 - val_loss: 8.6073e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.8827e-04 - val_loss: 9.4910e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.2944e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6492e-04 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 8.7424e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 8.6018e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8935e-04 - val_loss: 8.5682e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8554e-04 - val_loss: 9.6749e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 8.7677e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 2\n",
      "MAE: 0.07041480267634148\n",
      "MSE: 0.014028323075708891\n",
      "RMSE: 0.11844122202894097\n",
      "R2: 0.8831339493916787\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.1676 - val_loss: 0.2582\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0779 - val_loss: 0.1602\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0790 - val_loss: 0.2122\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0812 - val_loss: 0.1921\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0779 - val_loss: 0.2056\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0702 - val_loss: 0.1807\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0690 - val_loss: 0.1980\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0761 - val_loss: 0.1838\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0704 - val_loss: 0.1757\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0653 - val_loss: 0.1701\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0651 - val_loss: 0.1151\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0599 - val_loss: 0.0957\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0453 - val_loss: 0.0437\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0242 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 9.3510e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 8.5810e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5346e-04 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 9.3491e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3377e-04 - val_loss: 9.7783e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8878e-04 - val_loss: 8.4231e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.9510e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3215e-04 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 8.3979e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 9.2901e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4568e-04 - val_loss: 8.4008e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3287e-04 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0388e-04 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0034e-04 - val_loss: 8.5529e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 8.5112e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7769e-04 - val_loss: 8.7370e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 8.4005e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8931e-04 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0192e-04 - val_loss: 0.0017\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6388e-04 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8937e-04 - val_loss: 9.0710e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9598e-04 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 8.8065e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 3\n",
      "MAE: 0.1092696705802542\n",
      "MSE: 0.018810515809556325\n",
      "RMSE: 0.13715143385891496\n",
      "R2: 0.8432948342646328\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.1646 - val_loss: 0.2708\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0719 - val_loss: 0.1508\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0785 - val_loss: 0.2104\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0746 - val_loss: 0.1958\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0712 - val_loss: 0.1869\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0749 - val_loss: 0.1950\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0725 - val_loss: 0.1819\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0696 - val_loss: 0.1824\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0694 - val_loss: 0.1710\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0706 - val_loss: 0.2081\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0609 - val_loss: 0.1281\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0550 - val_loss: 0.1502\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0460 - val_loss: 0.0839\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0265 - val_loss: 0.0073\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 9.5428e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9962e-04 - val_loss: 0.0018\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 9.0239e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3234e-04 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 9.7820e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6877e-04 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0822e-04 - val_loss: 8.7503e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3986e-04 - val_loss: 8.7332e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.8980e-04 - val_loss: 8.9116e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9873e-04 - val_loss: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5553e-04 - val_loss: 8.6815e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3456e-04 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 9.6755e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0769e-04 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 9.9001e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5327e-04 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3529e-04 - val_loss: 8.8766e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1416e-04 - val_loss: 0.0018\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 9.3342e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 9.1402e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 9.6004e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 8.7859e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.0675e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 9.2024e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 9.0136e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6686e-04 - val_loss: 8.6755e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 4\n",
      "MAE: 0.07356179190463702\n",
      "MSE: 0.016498584962350887\n",
      "RMSE: 0.1284468176419754\n",
      "R2: 0.8625548859425343\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.1309 - val_loss: 0.1781\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0766 - val_loss: 0.1837\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0708 - val_loss: 0.2110\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0740 - val_loss: 0.1839\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0773 - val_loss: 0.1990\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0695 - val_loss: 0.1878\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0706 - val_loss: 0.1753\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0684 - val_loss: 0.1600\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0650 - val_loss: 0.1860\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0651 - val_loss: 0.1429\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0555 - val_loss: 0.1122\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0524 - val_loss: 0.0843\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0388 - val_loss: 0.0614\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0252 - val_loss: 0.0331\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0111 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 8.4987e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2110e-04 - val_loss: 8.5232e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.3258e-04 - val_loss: 9.1521e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 9.1277e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.3932e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8814e-04 - val_loss: 9.3645e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 8.5761e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 8.9713e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 9.0008e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9563e-04 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4538e-04 - val_loss: 9.0855e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2813e-04 - val_loss: 8.1341e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 9.2045e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4336e-04 - val_loss: 8.7131e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1874e-04 - val_loss: 9.5577e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 8.7004e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6676e-04 - val_loss: 8.2837e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9720e-04 - val_loss: 8.1198e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4887e-04 - val_loss: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0902e-04 - val_loss: 9.7550e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6401e-04 - val_loss: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1809e-04 - val_loss: 8.6823e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 8.1462e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5904e-04 - val_loss: 9.7558e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7671e-04 - val_loss: 8.0317e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7894e-04 - val_loss: 8.7660e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 9.5027e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6902e-04 - val_loss: 9.0542e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6021e-04 - val_loss: 8.3363e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2012e-04 - val_loss: 8.0885e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 5\n",
      "MAE: 0.05458269431942797\n",
      "MSE: 0.012941529774095389\n",
      "RMSE: 0.11376084464390808\n",
      "R2: 0.8921877215568689\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.2225 - val_loss: 0.4466\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1191 - val_loss: 0.2053\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0758 - val_loss: 0.1752\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0793 - val_loss: 0.2110\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0721 - val_loss: 0.1994\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0728 - val_loss: 0.1888\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0705 - val_loss: 0.1851\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0728 - val_loss: 0.2005\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0719 - val_loss: 0.1732\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0717 - val_loss: 0.1882\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0742 - val_loss: 0.1783\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0730 - val_loss: 0.1686\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0736 - val_loss: 0.1751\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0649 - val_loss: 0.1440\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0663 - val_loss: 0.1447\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0532 - val_loss: 0.1669\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0417 - val_loss: 0.0952\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0265 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0023\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 9.2216e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.8344e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6218e-04 - val_loss: 8.7084e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 8.7883e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2794e-04 - val_loss: 9.9868e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.7360e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 9.9880e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3108e-04 - val_loss: 8.7536e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 8.6164e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 8.8187e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7361e-04 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6809e-04 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3337e-04 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6676e-04 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2569e-04 - val_loss: 8.6594e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7757e-04 - val_loss: 8.8999e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 9.2097e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3839e-04 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4042e-04 - val_loss: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 6\n",
      "MAE: 0.0707582864605012\n",
      "MSE: 0.01614013235665087\n",
      "RMSE: 0.12704382061576577\n",
      "R2: 0.8655410547192542\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.1614 - val_loss: 0.2183\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0861 - val_loss: 0.1694\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0793 - val_loss: 0.2345\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0799 - val_loss: 0.1878\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0800 - val_loss: 0.1997\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0785 - val_loss: 0.2088\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0728 - val_loss: 0.1975\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0726 - val_loss: 0.1834\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0744 - val_loss: 0.1914\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0723 - val_loss: 0.1840\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0743 - val_loss: 0.1898\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0654 - val_loss: 0.1526\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0662 - val_loss: 0.1927\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0684 - val_loss: 0.1564\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0618 - val_loss: 0.1619\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0539 - val_loss: 0.0938\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0409 - val_loss: 0.0792\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0302 - val_loss: 0.0220\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0122 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1546e-04 - val_loss: 8.7699e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7977e-04 - val_loss: 0.0019\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8363e-04 - val_loss: 9.8018e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8318e-04 - val_loss: 8.5650e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4870e-04 - val_loss: 8.5727e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4896e-04 - val_loss: 8.5037e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4096e-04 - val_loss: 8.5077e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7355e-04 - val_loss: 8.7960e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3534e-04 - val_loss: 8.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 9.5451e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1513e-04 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 9.2058e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3542e-04 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 8.5544e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8049e-04 - val_loss: 8.8586e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4902e-04 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2094e-04 - val_loss: 0.0014\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.8979e-04 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9688e-04 - val_loss: 9.6510e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 8.9019e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7315e-04 - val_loss: 8.7375e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0964e-04 - val_loss: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1536e-04 - val_loss: 9.9726e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 8.5514e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 7\n",
      "MAE: 0.06368285945204433\n",
      "MSE: 0.013682223607762835\n",
      "RMSE: 0.11697103747408089\n",
      "R2: 0.8860172076199222\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.2452 - val_loss: 0.4192\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1137 - val_loss: 0.1697\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0771 - val_loss: 0.1931\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0835 - val_loss: 0.2075\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0758 - val_loss: 0.2006\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0809 - val_loss: 0.1866\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0785 - val_loss: 0.1991\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0702 - val_loss: 0.1911\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0741 - val_loss: 0.1851\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0692 - val_loss: 0.1899\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0695 - val_loss: 0.1827\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0711 - val_loss: 0.1788\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0680 - val_loss: 0.1608\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0719 - val_loss: 0.1593\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0643 - val_loss: 0.1329\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0580 - val_loss: 0.1087\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0475 - val_loss: 0.0634\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0328 - val_loss: 0.0419\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.0020\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 9.1838e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9301e-04 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6642e-04 - val_loss: 9.4537e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8930e-04 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 8.9726e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.5539e-04 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.1163e-04 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2912e-04 - val_loss: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4753e-04 - val_loss: 9.3195e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2006e-04 - val_loss: 9.2625e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3541e-04 - val_loss: 8.8914e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.5638e-04 - val_loss: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5099e-04 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 8.9596e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7528e-04 - val_loss: 9.9206e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 9.2134e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2715e-04 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.4666e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 8\n",
      "MAE: 0.057119727525554664\n",
      "MSE: 0.01514661499800402\n",
      "RMSE: 0.12307158485208526\n",
      "R2: 0.8738177709945529\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.1568 - val_loss: 0.2626\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0738 - val_loss: 0.1501\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0786 - val_loss: 0.2080\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0748 - val_loss: 0.1996\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0756 - val_loss: 0.1778\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0729 - val_loss: 0.1979\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0680 - val_loss: 0.1760\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0747 - val_loss: 0.1806\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0744 - val_loss: 0.1685\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0660 - val_loss: 0.1609\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0672 - val_loss: 0.1446\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0542 - val_loss: 0.1009\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0437 - val_loss: 0.0947\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0253 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0505e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5482e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4422e-04 - val_loss: 9.9457e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 8.8367e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.1899e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.9676e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9401e-04 - val_loss: 0.0020\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 9.3265e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 8.9329e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3219e-04 - val_loss: 9.7563e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 8.7189e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4566e-04 - val_loss: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2480e-04 - val_loss: 9.0796e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 8.8272e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4036e-04 - val_loss: 9.9493e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 8.6630e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 9.0602e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 8.7171e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8214e-04 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5015e-04 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7774e-04 - val_loss: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8635e-04 - val_loss: 8.8948e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 9.5986e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 8.7344e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9588e-04 - val_loss: 0.0016\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.1455e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7173e-04 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 8.9493e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5135e-04 - val_loss: 0.0012\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 598ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 9\n",
      "MAE: 0.10795923608248349\n",
      "MSE: 0.01891159959217503\n",
      "RMSE: 0.13751945168657062\n",
      "R2: 0.842452733438223\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.1532 - val_loss: 0.3071\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0813 - val_loss: 0.1537\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0770 - val_loss: 0.2097\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0723 - val_loss: 0.2028\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0713 - val_loss: 0.1989\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0789 - val_loss: 0.1913\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0731 - val_loss: 0.1891\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0748 - val_loss: 0.1950\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0737 - val_loss: 0.1823\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0741 - val_loss: 0.1868\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0745 - val_loss: 0.1698\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0701 - val_loss: 0.1651\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0671 - val_loss: 0.1589\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0626 - val_loss: 0.1214\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0601 - val_loss: 0.1153\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0488 - val_loss: 0.0777\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0265 - val_loss: 0.0189\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 9.2518e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 9.0508e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9214e-04 - val_loss: 8.7677e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9071e-04 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.9157e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8311e-04 - val_loss: 9.6799e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 8.5689e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 9.9027e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2484e-04 - val_loss: 9.3417e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5316e-04 - val_loss: 9.0348e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0986e-04 - val_loss: 8.6010e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 9.6508e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4710e-04 - val_loss: 9.0506e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8015e-04 - val_loss: 0.0015\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 8.5242e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.2026e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3132e-04 - val_loss: 9.4220e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6762e-04 - val_loss: 8.6080e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4633e-04 - val_loss: 9.4146e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9797e-04 - val_loss: 8.5410e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5457e-04 - val_loss: 0.0014\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1338e-04 - val_loss: 0.0016\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2784e-04 - val_loss: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0998e-04 - val_loss: 8.5281e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 10\n",
      "MAE: 0.06480732745811582\n",
      "MSE: 0.013644978939365613\n",
      "RMSE: 0.11681172432322713\n",
      "R2: 0.8863274825742635\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.2371 - val_loss: 0.8538\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1074 - val_loss: 0.5047\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0905 - val_loss: 0.4621\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0891 - val_loss: 0.5207\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0863 - val_loss: 0.5028\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0895 - val_loss: 0.4894\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.5017\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0851 - val_loss: 0.4748\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0828 - val_loss: 0.4833\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0827 - val_loss: 0.4554\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0785 - val_loss: 0.4563\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0813 - val_loss: 0.4277\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0761 - val_loss: 0.3864\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0638 - val_loss: 0.3076\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0566 - val_loss: 0.2101\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0325 - val_loss: 0.0451\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0072\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4995e-04 - val_loss: 0.0098\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5820e-04 - val_loss: 0.0106\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2782e-04 - val_loss: 0.0098\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6846e-04 - val_loss: 0.0091\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7562e-04 - val_loss: 0.0092\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8543e-04 - val_loss: 0.0090\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9563e-04 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4338e-04 - val_loss: 0.0092\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2335e-04 - val_loss: 0.0090\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5944e-04 - val_loss: 0.0090\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1495e-04 - val_loss: 0.0090\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4601e-04 - val_loss: 0.0089\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3338e-04 - val_loss: 0.0089\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8256e-04 - val_loss: 0.0093\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4547e-04 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6235e-04 - val_loss: 0.0089\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1065e-04 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2371e-04 - val_loss: 0.0092\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3024e-04 - val_loss: 0.0097\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7555e-04 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6831e-04 - val_loss: 0.0092\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1000e-04 - val_loss: 0.0090\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7041e-04 - val_loss: 0.0091\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5378e-04 - val_loss: 0.0087\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9758e-04 - val_loss: 0.0089\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1245e-04 - val_loss: 0.0092\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7225e-04 - val_loss: 0.0098\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4540e-04 - val_loss: 0.0091\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3602e-04 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3748e-04 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9719e-04 - val_loss: 0.0089\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3045e-04 - val_loss: 0.0089\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 1\n",
      "MAE: 0.28010470124541725\n",
      "MSE: 0.19567108026638544\n",
      "RMSE: 0.4423472394696111\n",
      "R2: 0.7611587290950207\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.2346 - val_loss: 0.9358\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1391 - val_loss: 0.6543\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0971 - val_loss: 0.4515\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0985 - val_loss: 0.5001\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0853 - val_loss: 0.5255\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0887 - val_loss: 0.4959\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0900 - val_loss: 0.4904\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0859 - val_loss: 0.5049\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0834 - val_loss: 0.4860\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0864 - val_loss: 0.5029\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0821 - val_loss: 0.4707\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0872 - val_loss: 0.4601\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0854 - val_loss: 0.4698\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0777 - val_loss: 0.4269\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0825 - val_loss: 0.4611\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0730 - val_loss: 0.3812\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0673 - val_loss: 0.3207\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0542 - val_loss: 0.2241\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0282 - val_loss: 0.0563\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2499e-04 - val_loss: 0.0097\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4917e-04 - val_loss: 0.0097\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1939e-04 - val_loss: 0.0094\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5239e-04 - val_loss: 0.0088\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4808e-04 - val_loss: 0.0090\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9905e-04 - val_loss: 0.0100\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1131e-04 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9648e-04 - val_loss: 0.0093\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6981e-04 - val_loss: 0.0101\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4587e-04 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4236e-04 - val_loss: 0.0097\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6577e-04 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1007e-04 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6180e-04 - val_loss: 0.0101\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9996e-04 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9965e-04 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2794e-04 - val_loss: 0.0096\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4740e-04 - val_loss: 0.0101\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8129e-04 - val_loss: 0.0102\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7591e-04 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8264e-04 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4590e-04 - val_loss: 0.0100\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7881e-04 - val_loss: 0.0097\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4437e-04 - val_loss: 0.0106\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9473e-04 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6525e-04 - val_loss: 0.0098\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9898e-04 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7344e-04 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8439e-04 - val_loss: 0.0089\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 2\n",
      "MAE: 0.32637232014390266\n",
      "MSE: 0.19724987990761061\n",
      "RMSE: 0.4441282246239374\n",
      "R2: 0.7592316046967642\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1377 - val_loss: 0.4548\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0926 - val_loss: 0.4843\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0915 - val_loss: 0.5020\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0825 - val_loss: 0.4613\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0799 - val_loss: 0.4680\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0838 - val_loss: 0.4450\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0721 - val_loss: 0.3683\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0710 - val_loss: 0.2932\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0595 - val_loss: 0.2124\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0382 - val_loss: 0.0937\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0125 - val_loss: 0.0054\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0097\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9784e-04 - val_loss: 0.0036\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0031e-04 - val_loss: 0.0033\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0072e-04 - val_loss: 0.0037\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8594e-04 - val_loss: 0.0038\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4362e-04 - val_loss: 0.0041\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1224e-04 - val_loss: 0.0040\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8268e-04 - val_loss: 0.0042\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0645e-04 - val_loss: 0.0042\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6496e-04 - val_loss: 0.0051\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.3298e-04 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9587e-04 - val_loss: 0.0051\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1046e-04 - val_loss: 0.0047\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7622e-04 - val_loss: 0.0049\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7052e-04 - val_loss: 0.0047\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2147e-04 - val_loss: 0.0047\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8086e-04 - val_loss: 0.0053\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8858e-04 - val_loss: 0.0051\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6353e-04 - val_loss: 0.0049\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6484e-04 - val_loss: 0.0056\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0517e-04 - val_loss: 0.0053\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1612e-04 - val_loss: 0.0054\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0486e-04 - val_loss: 0.0050\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5101e-04 - val_loss: 0.0054\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9541e-04 - val_loss: 0.0051\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0922e-04 - val_loss: 0.0050\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.9673e-04 - val_loss: 0.0051\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6092e-04 - val_loss: 0.0050\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8086e-04 - val_loss: 0.0054\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4430e-04 - val_loss: 0.0049\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8786e-04 - val_loss: 0.0053\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9284e-04 - val_loss: 0.0055\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0172e-04 - val_loss: 0.0050\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8446e-04 - val_loss: 0.0058\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1962e-04 - val_loss: 0.0052\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2567e-04 - val_loss: 0.0050\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7679e-04 - val_loss: 0.0057\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9322e-04 - val_loss: 0.0049\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 3\n",
      "MAE: 0.24496449955174163\n",
      "MSE: 0.10847518401559238\n",
      "RMSE: 0.32935571046452555\n",
      "R2: 0.8675923351745997\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.2029 - val_loss: 0.6186\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0840 - val_loss: 0.4224\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0926 - val_loss: 0.5107\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0844 - val_loss: 0.5069\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0874 - val_loss: 0.4682\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0827 - val_loss: 0.4906\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0844 - val_loss: 0.4736\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0811 - val_loss: 0.4631\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0787 - val_loss: 0.4361\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0786 - val_loss: 0.4335\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0707 - val_loss: 0.3784\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0635 - val_loss: 0.2684\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0598 - val_loss: 0.2888\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0522 - val_loss: 0.1717\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0307 - val_loss: 0.0652\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0106 - val_loss: 0.0041\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2192e-04 - val_loss: 0.0033\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4125e-04 - val_loss: 0.0035\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1391e-04 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2501e-04 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2221e-04 - val_loss: 0.0039\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9916e-04 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7104e-04 - val_loss: 0.0038\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4418e-04 - val_loss: 0.0039\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5183e-04 - val_loss: 0.0043\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5435e-04 - val_loss: 0.0044\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7976e-04 - val_loss: 0.0040\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6505e-04 - val_loss: 0.0041\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0190e-04 - val_loss: 0.0043\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2417e-04 - val_loss: 0.0047\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0969e-04 - val_loss: 0.0044\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0280e-04 - val_loss: 0.0045\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1253e-04 - val_loss: 0.0045\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0061e-04 - val_loss: 0.0044\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4760e-04 - val_loss: 0.0045\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6057e-04 - val_loss: 0.0048\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3353e-04 - val_loss: 0.0045\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9801e-04 - val_loss: 0.0045\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7049e-04 - val_loss: 0.0050\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0647e-04 - val_loss: 0.0049\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6123e-04 - val_loss: 0.0047\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9714e-04 - val_loss: 0.0046\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6497e-04 - val_loss: 0.0047\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1884e-04 - val_loss: 0.0046\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3158e-04 - val_loss: 0.0052\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4187e-04 - val_loss: 0.0049\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7302e-04 - val_loss: 0.0049\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4693e-04 - val_loss: 0.0050\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4176e-04 - val_loss: 0.0049\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 4\n",
      "MAE: 0.21386307575663568\n",
      "MSE: 0.10830600351595206\n",
      "RMSE: 0.3290987747104994\n",
      "R2: 0.867798841345524\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1627 - val_loss: 0.6461\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0929 - val_loss: 0.4319\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0996 - val_loss: 0.5024\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0871 - val_loss: 0.5127\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0901 - val_loss: 0.4879\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0841 - val_loss: 0.4823\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0824 - val_loss: 0.4868\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0769 - val_loss: 0.4535\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0831 - val_loss: 0.4584\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0779 - val_loss: 0.4117\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0782 - val_loss: 0.3986\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0631 - val_loss: 0.2585\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0543 - val_loss: 0.2194\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0279 - val_loss: 0.0527\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0090 - val_loss: 0.0108\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0068\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5522e-04 - val_loss: 0.0072\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9996e-04 - val_loss: 0.0078\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5760e-04 - val_loss: 0.0081\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2224e-04 - val_loss: 0.0078\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2936e-04 - val_loss: 0.0077\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9657e-04 - val_loss: 0.0080\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4331e-04 - val_loss: 0.0081\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2604e-04 - val_loss: 0.0083\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4260e-04 - val_loss: 0.0085\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0042e-04 - val_loss: 0.0080\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3539e-04 - val_loss: 0.0078\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8924e-04 - val_loss: 0.0080\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4900e-04 - val_loss: 0.0083\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0676e-04 - val_loss: 0.0090\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4750e-04 - val_loss: 0.0078\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6982e-04 - val_loss: 0.0080\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9592e-04 - val_loss: 0.0081\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0960e-04 - val_loss: 0.0078\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4237e-04 - val_loss: 0.0079\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9051e-04 - val_loss: 0.0082\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5553e-04 - val_loss: 0.0079\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7871e-04 - val_loss: 0.0080\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4324e-04 - val_loss: 0.0083\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9131e-04 - val_loss: 0.0077\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7623e-04 - val_loss: 0.0080\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0915e-04 - val_loss: 0.0081\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2242e-04 - val_loss: 0.0078\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.6735e-04 - val_loss: 0.0078\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5710e-04 - val_loss: 0.0081\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0240e-04 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1566e-04 - val_loss: 0.0078\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4592e-04 - val_loss: 0.0082\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8853e-04 - val_loss: 0.0081\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3299e-04 - val_loss: 0.0074\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 5\n",
      "MAE: 0.2969461050189907\n",
      "MSE: 0.16447403605922947\n",
      "RMSE: 0.4055539866148889\n",
      "R2: 0.7992386624033666\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.2462 - val_loss: 0.7041\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0913 - val_loss: 0.4000\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0890 - val_loss: 0.5244\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0862 - val_loss: 0.4970\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0911 - val_loss: 0.4861\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0917 - val_loss: 0.4868\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0790 - val_loss: 0.4796\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0831 - val_loss: 0.4557\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0873 - val_loss: 0.4443\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0776 - val_loss: 0.4316\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0844 - val_loss: 0.4179\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0738 - val_loss: 0.3794\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0623 - val_loss: 0.2221\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0514 - val_loss: 0.1778\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0275 - val_loss: 0.0415\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8137e-04 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4588e-04 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4719e-04 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7479e-04 - val_loss: 0.0027\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1256e-04 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1723e-04 - val_loss: 0.0030\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3443e-04 - val_loss: 0.0031\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5241e-04 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9988e-04 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0713e-04 - val_loss: 0.0034\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1989e-04 - val_loss: 0.0035\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6033e-04 - val_loss: 0.0037\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2859e-04 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4040e-04 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9160e-04 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2739e-04 - val_loss: 0.0037\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8221e-04 - val_loss: 0.0038\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7429e-04 - val_loss: 0.0038\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1398e-04 - val_loss: 0.0042\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3286e-04 - val_loss: 0.0041\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9115e-04 - val_loss: 0.0050\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.3994e-04 - val_loss: 0.0043\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7833e-04 - val_loss: 0.0039\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3872e-04 - val_loss: 0.0039\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1823e-04 - val_loss: 0.0040\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2053e-04 - val_loss: 0.0038\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2162e-04 - val_loss: 0.0041\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1894e-04 - val_loss: 0.0038\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7115e-04 - val_loss: 0.0044\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6809e-04 - val_loss: 0.0047\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9779e-04 - val_loss: 0.0040\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 6\n",
      "MAE: 0.19387794400824862\n",
      "MSE: 0.08929886597205063\n",
      "RMSE: 0.2988291585037354\n",
      "R2: 0.8909994537256\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1624 - val_loss: 0.5498\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0805 - val_loss: 0.4425\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0901 - val_loss: 0.5233\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0906 - val_loss: 0.4891\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0901 - val_loss: 0.4879\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0826 - val_loss: 0.4771\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0903 - val_loss: 0.4604\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.4610\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0767 - val_loss: 0.4290\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0772 - val_loss: 0.3930\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0661 - val_loss: 0.2635\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0490 - val_loss: 0.1609\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0227 - val_loss: 0.0348\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0091\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0236e-04 - val_loss: 0.0049\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9191e-04 - val_loss: 0.0052\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1963e-04 - val_loss: 0.0053\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7600e-04 - val_loss: 0.0055\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6355e-04 - val_loss: 0.0050\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6827e-04 - val_loss: 0.0055\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9691e-04 - val_loss: 0.0051\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8952e-04 - val_loss: 0.0050\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0356e-04 - val_loss: 0.0052\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1035e-04 - val_loss: 0.0055\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3807e-04 - val_loss: 0.0054\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0840e-04 - val_loss: 0.0051\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3307e-04 - val_loss: 0.0050\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3214e-04 - val_loss: 0.0055\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7092e-04 - val_loss: 0.0055\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2331e-04 - val_loss: 0.0054\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9073e-04 - val_loss: 0.0058\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5755e-04 - val_loss: 0.0054\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3316e-04 - val_loss: 0.0050\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7035e-04 - val_loss: 0.0056\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3113e-04 - val_loss: 0.0058\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0345e-04 - val_loss: 0.0051\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3688e-04 - val_loss: 0.0056\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6233e-04 - val_loss: 0.0053\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2944e-04 - val_loss: 0.0050\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7389e-04 - val_loss: 0.0056\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0480e-04 - val_loss: 0.0051\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5339e-04 - val_loss: 0.0052\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7362e-04 - val_loss: 0.0052\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5009e-04 - val_loss: 0.0050\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9878e-04 - val_loss: 0.0057\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0272e-04 - val_loss: 0.0051\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1766e-04 - val_loss: 0.0063\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 7\n",
      "MAE: 0.23568154163047936\n",
      "MSE: 0.14016900397532248\n",
      "RMSE: 0.37439151162295664\n",
      "R2: 0.828906024306841\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.2588 - val_loss: 0.8780\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1268 - val_loss: 0.4982\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0917 - val_loss: 0.4669\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0966 - val_loss: 0.5282\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0909 - val_loss: 0.4965\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0904 - val_loss: 0.4940\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0846 - val_loss: 0.5150\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0856 - val_loss: 0.4607\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0851 - val_loss: 0.4771\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0767 - val_loss: 0.4783\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0750 - val_loss: 0.4390\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.4592\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0760 - val_loss: 0.4258\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0733 - val_loss: 0.4025\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0747 - val_loss: 0.3689\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0596 - val_loss: 0.2602\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0502 - val_loss: 0.1830\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0244 - val_loss: 0.0321\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4589e-04 - val_loss: 0.0037\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4446e-04 - val_loss: 0.0048\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8049e-04 - val_loss: 0.0049\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9927e-04 - val_loss: 0.0055\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0302e-04 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6628e-04 - val_loss: 0.0050\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.1577e-04 - val_loss: 0.0053\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8433e-04 - val_loss: 0.0049\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4144e-04 - val_loss: 0.0049\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.6054e-04 - val_loss: 0.0058\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1550e-04 - val_loss: 0.0049\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6473e-04 - val_loss: 0.0060\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2640e-04 - val_loss: 0.0049\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4980e-04 - val_loss: 0.0053\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1307e-04 - val_loss: 0.0053\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5415e-04 - val_loss: 0.0053\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0697e-04 - val_loss: 0.0052\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5567e-04 - val_loss: 0.0055\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9904e-04 - val_loss: 0.0056\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6070e-04 - val_loss: 0.0052\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3304e-04 - val_loss: 0.0055\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0252e-04 - val_loss: 0.0055\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1041e-04 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6060e-04 - val_loss: 0.0062\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0512e-04 - val_loss: 0.0055\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6662e-04 - val_loss: 0.0053\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8273e-04 - val_loss: 0.0056\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6376e-04 - val_loss: 0.0053\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3703e-04 - val_loss: 0.0053\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.7084e-04 - val_loss: 0.0059\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 8\n",
      "MAE: 0.22630452640721052\n",
      "MSE: 0.13084863085532256\n",
      "RMSE: 0.3617300524636052\n",
      "R2: 0.8402827170621465\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.2673 - val_loss: 0.8131\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1175 - val_loss: 0.4365\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0943 - val_loss: 0.4988\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0919 - val_loss: 0.5192\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0797 - val_loss: 0.4972\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0895 - val_loss: 0.4847\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0834 - val_loss: 0.4944\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0897 - val_loss: 0.4739\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0832 - val_loss: 0.4808\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0873 - val_loss: 0.4651\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0878 - val_loss: 0.4642\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0817 - val_loss: 0.4325\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0784 - val_loss: 0.4465\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0767 - val_loss: 0.3954\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0645 - val_loss: 0.3066\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0618 - val_loss: 0.3082\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0429 - val_loss: 0.1360\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0216 - val_loss: 0.0287\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5863e-04 - val_loss: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6264e-04 - val_loss: 0.0026\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.2310e-04 - val_loss: 0.0024\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8226e-04 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8962e-04 - val_loss: 0.0026\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1611e-04 - val_loss: 0.0027\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6377e-04 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8446e-04 - val_loss: 0.0030\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3459e-04 - val_loss: 0.0030\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0645e-04 - val_loss: 0.0031\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3959e-04 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.3970e-04 - val_loss: 0.0034\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6800e-04 - val_loss: 0.0033\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8907e-04 - val_loss: 0.0037\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3834e-04 - val_loss: 0.0039\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9135e-04 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9913e-04 - val_loss: 0.0038\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5005e-04 - val_loss: 0.0037\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7647e-04 - val_loss: 0.0039\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3067e-04 - val_loss: 0.0040\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7499e-04 - val_loss: 0.0039\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3468e-04 - val_loss: 0.0041\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.2933e-04 - val_loss: 0.0045\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3681e-04 - val_loss: 0.0038\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0470e-04 - val_loss: 0.0040\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4059e-04 - val_loss: 0.0051\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7071e-04 - val_loss: 0.0040\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7129e-04 - val_loss: 0.0045\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 9\n",
      "MAE: 0.1980750943793624\n",
      "MSE: 0.09888481607670307\n",
      "RMSE: 0.3144595619101176\n",
      "R2: 0.8792985907124763\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 0.1616 - val_loss: 0.6313\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0897 - val_loss: 0.4238\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0892 - val_loss: 0.5196\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0863 - val_loss: 0.5018\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0935 - val_loss: 0.4939\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0855 - val_loss: 0.5049\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0815 - val_loss: 0.4796\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0911 - val_loss: 0.4941\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0856 - val_loss: 0.4667\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0834 - val_loss: 0.4679\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0748 - val_loss: 0.4194\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0804 - val_loss: 0.4772\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0756 - val_loss: 0.3495\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0545 - val_loss: 0.2374\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0388 - val_loss: 0.1186\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0101 - val_loss: 0.0149\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6200e-04 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7158e-04 - val_loss: 0.0097\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.5289e-04 - val_loss: 0.0096\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.1249e-04 - val_loss: 0.0099\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8158e-04 - val_loss: 0.0098\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5329e-04 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8887e-04 - val_loss: 0.0092\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7861e-04 - val_loss: 0.0089\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0149e-04 - val_loss: 0.0092\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4322e-04 - val_loss: 0.0100\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8927e-04 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8085e-04 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9804e-04 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5939e-04 - val_loss: 0.0090\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.6549e-04 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6710e-04 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8064e-04 - val_loss: 0.0090\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4040e-04 - val_loss: 0.0086\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2115e-04 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7838e-04 - val_loss: 0.0090\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2272e-04 - val_loss: 0.0087\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4538e-04 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5864e-04 - val_loss: 0.0090\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6753e-04 - val_loss: 0.0091\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.3923e-04 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5251e-04 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.7727e-04 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9216e-04 - val_loss: 0.0084\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0549e-04 - val_loss: 0.0087\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8190e-04 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0964e-04 - val_loss: 0.0089\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0081e-04 - val_loss: 0.0086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 10\n",
      "MAE: 0.28469385866258956\n",
      "MSE: 0.19008815832604314\n",
      "RMSE: 0.4359910071618945\n",
      "R2: 0.767973390565583\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.2118 - val_loss: 0.7459\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1132 - val_loss: 0.4419\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0923 - val_loss: 0.4525\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0857 - val_loss: 0.5114\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0948 - val_loss: 0.4664\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0832 - val_loss: 0.4859\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0765 - val_loss: 0.4537\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0904 - val_loss: 0.4577\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0846 - val_loss: 0.4578\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0793 - val_loss: 0.4407\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0853 - val_loss: 0.4327\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0763 - val_loss: 0.3748\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0743 - val_loss: 0.3819\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0624 - val_loss: 0.2801\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0498 - val_loss: 0.1109\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0220 - val_loss: 0.0215\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6831e-04 - val_loss: 0.0063\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6882e-04 - val_loss: 0.0052\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6578e-04 - val_loss: 0.0052\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.0577e-04 - val_loss: 0.0059\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5113e-04 - val_loss: 0.0053\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8399e-04 - val_loss: 0.0055\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6495e-04 - val_loss: 0.0055\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9661e-04 - val_loss: 0.0053\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4141e-04 - val_loss: 0.0053\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6057e-04 - val_loss: 0.0059\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2517e-04 - val_loss: 0.0054\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3172e-04 - val_loss: 0.0053\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6271e-04 - val_loss: 0.0052\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9556e-04 - val_loss: 0.0055\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8086e-04 - val_loss: 0.0054\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2918e-04 - val_loss: 0.0053\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0004e-04 - val_loss: 0.0052\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9729e-04 - val_loss: 0.0054\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0535e-04 - val_loss: 0.0056\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2468e-04 - val_loss: 0.0056\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6091e-04 - val_loss: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5259e-04 - val_loss: 0.0054\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6955e-04 - val_loss: 0.0052\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5471e-04 - val_loss: 0.0054\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1472e-04 - val_loss: 0.0052\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1002e-04 - val_loss: 0.0055\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6024e-04 - val_loss: 0.0052\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6935e-04 - val_loss: 0.0054\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4981e-04 - val_loss: 0.0051\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0605e-04 - val_loss: 0.0055\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4618e-04 - val_loss: 0.0053\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4569e-04 - val_loss: 0.0051\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 1\n",
      "MAE: 0.2580865672377288\n",
      "MSE: 0.11809456026602494\n",
      "RMSE: 0.3436488909716208\n",
      "R2: 0.8503243120461739\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.1445 - val_loss: 0.4425\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0875 - val_loss: 0.4520\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0817 - val_loss: 0.5011\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0863 - val_loss: 0.4372\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0870 - val_loss: 0.4735\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0824 - val_loss: 0.4305\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0850 - val_loss: 0.4538\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0803 - val_loss: 0.3885\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0729 - val_loss: 0.3430\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0695 - val_loss: 0.3160\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0518 - val_loss: 0.1908\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0283 - val_loss: 0.0185\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5146e-04 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0043e-04 - val_loss: 0.0027\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1572e-04 - val_loss: 0.0022\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0729e-04 - val_loss: 0.0023\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7079e-04 - val_loss: 0.0023\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4350e-04 - val_loss: 0.0024\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4214e-04 - val_loss: 0.0024\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9248e-04 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4811e-04 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9071e-04 - val_loss: 0.0027\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.9027e-04 - val_loss: 0.0026\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3714e-04 - val_loss: 0.0027\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4663e-04 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5260e-04 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5818e-04 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.0644e-04 - val_loss: 0.0028\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1693e-04 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1268e-04 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7888e-04 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.6203e-04 - val_loss: 0.0029\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7272e-04 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6902e-04 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2761e-04 - val_loss: 0.0031\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6466e-04 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4229e-04 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4240e-04 - val_loss: 0.0032\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3867e-04 - val_loss: 0.0030\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8372e-04 - val_loss: 0.0030\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1902e-04 - val_loss: 0.0030\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3970e-04 - val_loss: 0.0033\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3843e-04 - val_loss: 0.0030\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0420e-04 - val_loss: 0.0031\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8380e-04 - val_loss: 0.0030\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7601e-04 - val_loss: 0.0031\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9843e-04 - val_loss: 0.0031\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 2\n",
      "MAE: 0.17683306678396746\n",
      "MSE: 0.07110889048228948\n",
      "RMSE: 0.2666625029551202\n",
      "R2: 0.9098750011973925\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.1732 - val_loss: 0.6459\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0974 - val_loss: 0.4254\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0928 - val_loss: 0.4714\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0897 - val_loss: 0.4829\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0914 - val_loss: 0.4571\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0826 - val_loss: 0.4597\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0861 - val_loss: 0.4399\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0782 - val_loss: 0.4291\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0814 - val_loss: 0.3957\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0681 - val_loss: 0.3476\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0682 - val_loss: 0.2367\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0449 - val_loss: 0.1066\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0175 - val_loss: 0.0054\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0100\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4787e-04 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9064e-04 - val_loss: 0.0037\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3999e-04 - val_loss: 0.0038\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0273e-04 - val_loss: 0.0040\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7383e-04 - val_loss: 0.0041\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4139e-04 - val_loss: 0.0042\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4816e-04 - val_loss: 0.0043\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7066e-04 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5407e-04 - val_loss: 0.0044\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9403e-04 - val_loss: 0.0046\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1439e-04 - val_loss: 0.0045\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3106e-04 - val_loss: 0.0045\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4271e-04 - val_loss: 0.0045\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7631e-04 - val_loss: 0.0047\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1315e-04 - val_loss: 0.0050\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4992e-04 - val_loss: 0.0046\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7094e-04 - val_loss: 0.0049\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.1833e-04 - val_loss: 0.0046\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9117e-04 - val_loss: 0.0047\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4505e-04 - val_loss: 0.0047\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8527e-04 - val_loss: 0.0051\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5833e-04 - val_loss: 0.0051\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4088e-04 - val_loss: 0.0047\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2172e-04 - val_loss: 0.0047\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.0798e-04 - val_loss: 0.0051\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3100e-04 - val_loss: 0.0053\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9131e-04 - val_loss: 0.0048\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5616e-04 - val_loss: 0.0050\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6832e-04 - val_loss: 0.0054\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9698e-04 - val_loss: 0.0048\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0815e-04 - val_loss: 0.0050\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7211e-04 - val_loss: 0.0049\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6908e-04 - val_loss: 0.0049\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8624e-04 - val_loss: 0.0052\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3536e-04 - val_loss: 0.0050\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 3\n",
      "MAE: 0.21334232424126318\n",
      "MSE: 0.11510993263279941\n",
      "RMSE: 0.33927854726286394\n",
      "R2: 0.8541070958872138\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.1607 - val_loss: 0.6252\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0960 - val_loss: 0.4148\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0920 - val_loss: 0.4738\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0843 - val_loss: 0.4994\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0845 - val_loss: 0.4512\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0842 - val_loss: 0.4402\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0854 - val_loss: 0.4654\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0838 - val_loss: 0.4483\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0741 - val_loss: 0.4239\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0853 - val_loss: 0.4401\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0698 - val_loss: 0.3740\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0727 - val_loss: 0.2949\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0567 - val_loss: 0.2952\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0446 - val_loss: 0.0655\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0109 - val_loss: 0.0043\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0059\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.4270e-04 - val_loss: 0.0042\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9134e-04 - val_loss: 0.0043\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5069e-04 - val_loss: 0.0042\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1247e-04 - val_loss: 0.0044\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2746e-04 - val_loss: 0.0046\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9658e-04 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6657e-04 - val_loss: 0.0050\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6218e-04 - val_loss: 0.0051\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3254e-04 - val_loss: 0.0051\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4396e-04 - val_loss: 0.0052\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3129e-04 - val_loss: 0.0054\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6902e-04 - val_loss: 0.0053\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4828e-04 - val_loss: 0.0053\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7564e-04 - val_loss: 0.0055\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9592e-04 - val_loss: 0.0054\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2632e-04 - val_loss: 0.0057\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5195e-04 - val_loss: 0.0059\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3461e-04 - val_loss: 0.0055\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4924e-04 - val_loss: 0.0055\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3520e-04 - val_loss: 0.0055\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5199e-04 - val_loss: 0.0056\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3155e-04 - val_loss: 0.0061\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3167e-04 - val_loss: 0.0056\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2412e-04 - val_loss: 0.0057\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4730e-04 - val_loss: 0.0055\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.3403e-04 - val_loss: 0.0066\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2798e-04 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2528e-04 - val_loss: 0.0056\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0800e-04 - val_loss: 0.0058\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2966e-04 - val_loss: 0.0055\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4581e-04 - val_loss: 0.0057\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.8234e-04 - val_loss: 0.0059\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6700e-04 - val_loss: 0.0055\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4866e-04 - val_loss: 0.0056\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 4\n",
      "MAE: 0.2405546532302605\n",
      "MSE: 0.12945718023616065\n",
      "RMSE: 0.35980158453814604\n",
      "R2: 0.8359230732663617\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.1701 - val_loss: 0.6042\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0901 - val_loss: 0.4286\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0952 - val_loss: 0.4956\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0895 - val_loss: 0.4757\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0803 - val_loss: 0.4794\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0887 - val_loss: 0.4714\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0797 - val_loss: 0.4570\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0937 - val_loss: 0.4598\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0912 - val_loss: 0.4589\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0798 - val_loss: 0.4062\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0828 - val_loss: 0.4112\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0768 - val_loss: 0.4295\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0681 - val_loss: 0.2894\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0580 - val_loss: 0.2480\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0330 - val_loss: 0.0668\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0165 - val_loss: 0.0231\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2603e-04 - val_loss: 0.0045\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3008e-04 - val_loss: 0.0049\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8674e-04 - val_loss: 0.0051\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0441e-04 - val_loss: 0.0056\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0183e-04 - val_loss: 0.0055\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8750e-04 - val_loss: 0.0055\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3600e-04 - val_loss: 0.0058\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5819e-04 - val_loss: 0.0058\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9706e-04 - val_loss: 0.0060\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3739e-04 - val_loss: 0.0059\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2154e-04 - val_loss: 0.0067\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6637e-04 - val_loss: 0.0064\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1658e-04 - val_loss: 0.0065\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5887e-04 - val_loss: 0.0060\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5967e-04 - val_loss: 0.0061\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3132e-04 - val_loss: 0.0063\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6644e-04 - val_loss: 0.0063\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7997e-04 - val_loss: 0.0062\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5360e-04 - val_loss: 0.0062\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6525e-04 - val_loss: 0.0062\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5667e-04 - val_loss: 0.0064\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4796e-04 - val_loss: 0.0063\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6913e-04 - val_loss: 0.0063\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1746e-04 - val_loss: 0.0067\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.1640e-04 - val_loss: 0.0064\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8816e-04 - val_loss: 0.0062\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7721e-04 - val_loss: 0.0061\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9529e-04 - val_loss: 0.0065\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2580e-04 - val_loss: 0.0062\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2766e-04 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4197e-04 - val_loss: 0.0061\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3858e-04 - val_loss: 0.0062\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4196e-04 - val_loss: 0.0067\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 5\n",
      "MAE: 0.24737172830300283\n",
      "MSE: 0.15545678435738652\n",
      "RMSE: 0.3942800836428167\n",
      "R2: 0.8029705932824791\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.1184 - val_loss: 0.4200\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0930 - val_loss: 0.4687\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0853 - val_loss: 0.4767\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0830 - val_loss: 0.4499\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0796 - val_loss: 0.4472\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0819 - val_loss: 0.4409\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0788 - val_loss: 0.3901\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0685 - val_loss: 0.3516\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0565 - val_loss: 0.1954\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0277 - val_loss: 0.0169\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6861e-04 - val_loss: 0.0022\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4178e-04 - val_loss: 0.0027\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9205e-04 - val_loss: 0.0022\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5437e-04 - val_loss: 0.0023\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8359e-04 - val_loss: 0.0020\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6583e-04 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2854e-04 - val_loss: 0.0027\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0233e-04 - val_loss: 0.0022\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8102e-04 - val_loss: 0.0022\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5587e-04 - val_loss: 0.0023\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5973e-04 - val_loss: 0.0023\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4232e-04 - val_loss: 0.0024\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8629e-04 - val_loss: 0.0024\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0385e-04 - val_loss: 0.0024\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4225e-04 - val_loss: 0.0025\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7548e-04 - val_loss: 0.0025\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5763e-04 - val_loss: 0.0026\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5341e-04 - val_loss: 0.0027\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1059e-04 - val_loss: 0.0027\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4638e-04 - val_loss: 0.0027\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2762e-04 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7320e-04 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8127e-04 - val_loss: 0.0030\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0839e-04 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6606e-04 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.9349e-04 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8775e-04 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.9621e-04 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0957e-04 - val_loss: 0.0031\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0291e-04 - val_loss: 0.0032\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6166e-04 - val_loss: 0.0032\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0655e-04 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7207e-04 - val_loss: 0.0030\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8156e-04 - val_loss: 0.0029\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3634e-04 - val_loss: 0.0036\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8935e-04 - val_loss: 0.0030\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0537e-04 - val_loss: 0.0031\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9147e-04 - val_loss: 0.0030\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 6\n",
      "MAE: 0.17688410868410193\n",
      "MSE: 0.07007525343601216\n",
      "RMSE: 0.26471730853121817\n",
      "R2: 0.9111850559166583\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.1411 - val_loss: 0.5913\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0903 - val_loss: 0.4279\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0892 - val_loss: 0.4980\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0952 - val_loss: 0.4821\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0835 - val_loss: 0.4811\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0855 - val_loss: 0.4518\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0799 - val_loss: 0.4528\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0888 - val_loss: 0.4470\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0774 - val_loss: 0.3977\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0776 - val_loss: 0.3770\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0572 - val_loss: 0.1788\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0444 - val_loss: 0.0727\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0099 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4514e-04 - val_loss: 0.0034\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1003e-04 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3962e-04 - val_loss: 0.0029\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2096e-04 - val_loss: 0.0032\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1302e-04 - val_loss: 0.0032\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3253e-04 - val_loss: 0.0035\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2608e-04 - val_loss: 0.0033\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9817e-04 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8367e-04 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4674e-04 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6768e-04 - val_loss: 0.0037\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4975e-04 - val_loss: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2560e-04 - val_loss: 0.0040\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8686e-04 - val_loss: 0.0038\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9799e-04 - val_loss: 0.0038\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8853e-04 - val_loss: 0.0045\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7443e-04 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5629e-04 - val_loss: 0.0043\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3567e-04 - val_loss: 0.0041\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7172e-04 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9648e-04 - val_loss: 0.0049\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7043e-04 - val_loss: 0.0039\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8877e-04 - val_loss: 0.0042\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2021e-04 - val_loss: 0.0041\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3603e-04 - val_loss: 0.0041\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1102e-04 - val_loss: 0.0043\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6069e-04 - val_loss: 0.0040\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0431e-04 - val_loss: 0.0041\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9676e-04 - val_loss: 0.0041\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6423e-04 - val_loss: 0.0042\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3554e-04 - val_loss: 0.0041\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5232e-04 - val_loss: 0.0040\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7297e-04 - val_loss: 0.0043\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5147e-04 - val_loss: 0.0040\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9654e-04 - val_loss: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1926e-04 - val_loss: 0.0042\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 7\n",
      "MAE: 0.20283681212878604\n",
      "MSE: 0.0968331406125541\n",
      "RMSE: 0.3111802381459242\n",
      "R2: 0.8772715110224826\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.1133 - val_loss: 0.3797\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0973 - val_loss: 0.4866\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0799 - val_loss: 0.4636\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0776 - val_loss: 0.4439\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0790 - val_loss: 0.4297\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0746 - val_loss: 0.4166\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0660 - val_loss: 0.3130\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0680 - val_loss: 0.2505\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0530 - val_loss: 0.1785\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0307 - val_loss: 0.0626\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0094 - val_loss: 0.0036\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9154e-04 - val_loss: 0.0022\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8780e-04 - val_loss: 0.0022\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5724e-04 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6227e-04 - val_loss: 0.0024\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5317e-04 - val_loss: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2238e-04 - val_loss: 0.0026\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3399e-04 - val_loss: 0.0026\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2323e-04 - val_loss: 0.0027\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.9161e-04 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3378e-04 - val_loss: 0.0027\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7438e-04 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3909e-04 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6005e-04 - val_loss: 0.0029\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6139e-04 - val_loss: 0.0031\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.4733e-04 - val_loss: 0.0030\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.3995e-04 - val_loss: 0.0030\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4739e-04 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6619e-04 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3092e-04 - val_loss: 0.0034\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3268e-04 - val_loss: 0.0031\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5594e-04 - val_loss: 0.0034\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8024e-04 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9817e-04 - val_loss: 0.0034\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5543e-04 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0945e-04 - val_loss: 0.0032\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6146e-04 - val_loss: 0.0034\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2235e-04 - val_loss: 0.0036\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5952e-04 - val_loss: 0.0033\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1414e-04 - val_loss: 0.0033\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4072e-04 - val_loss: 0.0034\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4668e-04 - val_loss: 0.0034\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6297e-04 - val_loss: 0.0038\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0220e-04 - val_loss: 0.0034\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7620e-04 - val_loss: 0.0035\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7282e-04 - val_loss: 0.0037\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5325e-04 - val_loss: 0.0034\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7526e-04 - val_loss: 0.0036\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 8\n",
      "MAE: 0.17867207292650586\n",
      "MSE: 0.08198262610965677\n",
      "RMSE: 0.2863260835300493\n",
      "R2: 0.8960933853720067\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0951 - val_loss: 0.3901\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0967 - val_loss: 0.5082\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0944 - val_loss: 0.4611\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0908 - val_loss: 0.4609\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0897 - val_loss: 0.4480\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0834 - val_loss: 0.4123\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0745 - val_loss: 0.4114\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0731 - val_loss: 0.3221\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0685 - val_loss: 0.3242\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0451 - val_loss: 0.1530\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0203 - val_loss: 0.0147\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0080\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3994e-04 - val_loss: 0.0027\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7093e-04 - val_loss: 0.0027\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0255e-04 - val_loss: 0.0026\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7732e-04 - val_loss: 0.0027\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7406e-04 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7666e-04 - val_loss: 0.0027\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0984e-04 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2424e-04 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1458e-04 - val_loss: 0.0030\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7594e-04 - val_loss: 0.0032\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9563e-04 - val_loss: 0.0030\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2535e-04 - val_loss: 0.0030\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8652e-04 - val_loss: 0.0031\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9167e-04 - val_loss: 0.0031\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7229e-04 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7374e-04 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9377e-04 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2615e-04 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.5624e-04 - val_loss: 0.0035\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7511e-04 - val_loss: 0.0033\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3455e-04 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8998e-04 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4993e-04 - val_loss: 0.0032\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0510e-04 - val_loss: 0.0033\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8846e-04 - val_loss: 0.0032\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2234e-04 - val_loss: 0.0032\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2043e-04 - val_loss: 0.0037\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8978e-04 - val_loss: 0.0032\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8501e-04 - val_loss: 0.0035\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.4095e-04 - val_loss: 0.0032\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.2012e-04 - val_loss: 0.0032\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.4829e-04 - val_loss: 0.0032\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3329e-04 - val_loss: 0.0033\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1445e-04 - val_loss: 0.0034\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0227e-04 - val_loss: 0.0040\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3751e-04 - val_loss: 0.0036\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3894e-04 - val_loss: 0.0033\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 9\n",
      "MAE: 0.19887450796658862\n",
      "MSE: 0.07502991588472113\n",
      "RMSE: 0.27391589199007993\n",
      "R2: 0.904905405872499\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.1622 - val_loss: 0.4888\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0839 - val_loss: 0.4500\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0947 - val_loss: 0.4842\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0926 - val_loss: 0.4944\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0860 - val_loss: 0.4622\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0942 - val_loss: 0.4561\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0900 - val_loss: 0.4579\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0875 - val_loss: 0.4362\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0827 - val_loss: 0.4243\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0764 - val_loss: 0.4035\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0760 - val_loss: 0.3967\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0637 - val_loss: 0.2873\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0577 - val_loss: 0.1740\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0324 - val_loss: 0.0706\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0101 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5069e-04 - val_loss: 0.0044\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8540e-04 - val_loss: 0.0031\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5250e-04 - val_loss: 0.0031\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2704e-04 - val_loss: 0.0032\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7615e-04 - val_loss: 0.0035\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1600e-04 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7410e-04 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4057e-04 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.9155e-04 - val_loss: 0.0039\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0985e-04 - val_loss: 0.0043\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8155e-04 - val_loss: 0.0043\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7479e-04 - val_loss: 0.0040\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7105e-04 - val_loss: 0.0041\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0386e-04 - val_loss: 0.0046\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3678e-04 - val_loss: 0.0043\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8156e-04 - val_loss: 0.0041\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8380e-04 - val_loss: 0.0051\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1236e-04 - val_loss: 0.0042\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0212e-04 - val_loss: 0.0043\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9836e-04 - val_loss: 0.0047\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2334e-04 - val_loss: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9308e-04 - val_loss: 0.0044\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4456e-04 - val_loss: 0.0042\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8629e-04 - val_loss: 0.0046\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5018e-04 - val_loss: 0.0044\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5450e-04 - val_loss: 0.0042\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9564e-04 - val_loss: 0.0045\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3515e-04 - val_loss: 0.0042\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8319e-04 - val_loss: 0.0049\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1801e-04 - val_loss: 0.0047\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5175e-04 - val_loss: 0.0043\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6462e-04 - val_loss: 0.0043\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0805e-04 - val_loss: 0.0045\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4293e-04 - val_loss: 0.0044\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 10\n",
      "MAE: 0.2061215713375903\n",
      "MSE: 0.10079635523840365\n",
      "RMSE: 0.3174844173158797\n",
      "R2: 0.8722484441318786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_step = 3\n",
    "\n",
    "all_actuals = []\n",
    "all_predictions = []\n",
    "x_ticks = None\n",
    "\n",
    "for col in target_cols:\n",
    "    df_col = preprocess_data(df, col)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    split = int(len(df_col) * 0.8)  # 80% training, 20% testing\n",
    "    train = df_col[:split]\n",
    "    test = df_col[split:]\n",
    "\n",
    "    # Normalize data with MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    # Create training and testing datasets with the specified time step\n",
    "    X_train, y_train = create_dataset(train, time_step)\n",
    "    X_test, y_test = create_dataset(test, time_step)\n",
    "\n",
    "    # Reshape data to be 3D [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], time_step, 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], time_step, 1))\n",
    "\n",
    "    # Initialize lists to store results for each iteration\n",
    "    all_actuals_col = []\n",
    "    all_predictions_col = []\n",
    "\n",
    "    for iteration in range(10):\n",
    "        # Build LSTM model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(32, activation='sigmoid', return_sequences=True, input_shape=(time_step, 1)))\n",
    "        model.add(LSTM(16, return_sequences=True))\n",
    "        model.add(LSTM(8))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        # Compile the model with Adam optimizer and learning rate of 0.001\n",
    "        adam_optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(loss='mean_squared_error', optimizer=adam_optimizer)\n",
    "        \n",
    "        # Train LSTM model\n",
    "        model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "        # Predict using the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Inverse transform the normalized data back to original scale\n",
    "        y_test_inverse = scaler.inverse_transform([y_test])\n",
    "        y_pred_inverse = scaler.inverse_transform(y_pred)\n",
    "        \n",
    "        all_actuals_col.append(y_test_inverse.flatten())\n",
    "        all_predictions_col.append(y_pred_inverse.flatten())\n",
    "\n",
    "        # Print evaluation results for each iteration\n",
    "        print(f'Hasil Evaluasi Prediksi Harga {col} - Iterasi {iteration + 1}')\n",
    "        mae = mean_absolute_error(y_test_inverse[0], y_pred_inverse[:, 0])\n",
    "        print('MAE:', mae)\n",
    "\n",
    "        mse = mean_squared_error(y_test_inverse[0], y_pred_inverse[:, 0])\n",
    "        print('MSE:', mse)\n",
    "\n",
    "        rmse = np.sqrt(mse)\n",
    "        print('RMSE:', rmse)\n",
    "\n",
    "        r2 = r2_score(y_test_inverse[0], y_pred_inverse[:, 0])\n",
    "        print('R2:', r2)\n",
    "        print()\n",
    "\n",
    "    # Store results for each column\n",
    "    all_actuals.append(all_actuals_col)\n",
    "    all_predictions.append(all_predictions_col)\n",
    "\n",
    "    # Set x_ticks only once with the appropriate indices for plotting\n",
    "    if x_ticks is None:\n",
    "        x_ticks = df_col.index[split + 1 + time_step:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 1\n",
      "MAE: 0.226393376393373\n",
      "MSE: 0.06529494899431199\n",
      "RMSE: 0.25552876353614673\n",
      "R2: 0.7414524075090564\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 2\n",
      "MAE: 0.1622760283055687\n",
      "MSE: 0.03630766879346862\n",
      "RMSE: 0.19054571313327576\n",
      "R2: 0.8562329781997743\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 3\n",
      "MAE: 0.18827381805815055\n",
      "MSE: 0.04726128829243071\n",
      "RMSE: 0.21739661518163228\n",
      "R2: 0.8128600681334044\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 4\n",
      "MAE: 0.1799461546101177\n",
      "MSE: 0.043016785278665384\n",
      "RMSE: 0.20740488248511746\n",
      "R2: 0.8296669736051459\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 5\n",
      "MAE: 0.1799746691710748\n",
      "MSE: 0.043028178150091544\n",
      "RMSE: 0.20743234595908985\n",
      "R2: 0.8296218613947197\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 6\n",
      "MAE: 0.18004237943637044\n",
      "MSE: 0.04305524060785299\n",
      "RMSE: 0.2074975677155108\n",
      "R2: 0.8295147025193568\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 7\n",
      "MAE: 0.28528714700721747\n",
      "MSE: 0.09204190465472493\n",
      "RMSE: 0.3033840876755486\n",
      "R2: 0.6355428218676893\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 8\n",
      "MAE: 0.20769168555237488\n",
      "MSE: 0.05442557191370253\n",
      "RMSE: 0.23329288869080972\n",
      "R2: 0.7844917439256087\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 9\n",
      "MAE: 0.1047296008898301\n",
      "MSE: 0.01764972690745944\n",
      "RMSE: 0.13285227475455375\n",
      "R2: 0.9301125972172245\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras - Iterasi 10\n",
      "MAE: 0.2922092956178742\n",
      "MSE: 0.09537693718893744\n",
      "RMSE: 0.3088315676690734\n",
      "R2: 0.6223371352735435\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 1\n",
      "MAE: 0.37210126846529684\n",
      "MSE: 0.14690447633780632\n",
      "RMSE: 0.383281197474917\n",
      "R2: 0.7516528149345093\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 2\n",
      "MAE: 0.36593754314608734\n",
      "MSE: 0.14044485934208403\n",
      "RMSE: 0.37475973548673025\n",
      "R2: 0.7625730247026576\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 3\n",
      "MAE: 0.23763626199189564\n",
      "MSE: 0.05890762010435735\n",
      "RMSE: 0.2427089205290101\n",
      "R2: 0.900414595957009\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 4\n",
      "MAE: 0.4160043151902522\n",
      "MSE: 0.18448527094587874\n",
      "RMSE: 0.4295174861933781\n",
      "R2: 0.6881211596296174\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 5\n",
      "MAE: 0.05896018420277205\n",
      "MSE: 0.010097813228595612\n",
      "RMSE: 0.10048787602788513\n",
      "R2: 0.9829292915154457\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 6\n",
      "MAE: 0.2376369413248383\n",
      "MSE: 0.058907968195655004\n",
      "RMSE: 0.2427096376241681\n",
      "R2: 0.9004140074964251\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 7\n",
      "MAE: 0.2148404423824649\n",
      "MSE: 0.05617120764507987\n",
      "RMSE: 0.23700465743330842\n",
      "R2: 0.9050405974811355\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 8\n",
      "MAE: 0.07577968419541736\n",
      "MSE: 0.010001573302181063\n",
      "RMSE: 0.10000786620151968\n",
      "R2: 0.9830919884965847\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 9\n",
      "MAE: 0.15134065305868893\n",
      "MSE: 0.02424570807141361\n",
      "RMSE: 0.15571033386199393\n",
      "R2: 0.9590117775879808\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah I - Iterasi 10\n",
      "MAE: 0.06423801212462697\n",
      "MSE: 0.010159085171654576\n",
      "RMSE: 0.10079228726273938\n",
      "R2: 0.9828257091402757\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 1\n",
      "MAE: 0.13592889390518023\n",
      "MSE: 0.020861777744353837\n",
      "RMSE: 0.1444360680174929\n",
      "R2: 0.9358598035148353\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 2\n",
      "MAE: 0.14031601498376717\n",
      "MSE: 0.02191940145761896\n",
      "RMSE: 0.1480520228082648\n",
      "R2: 0.9326081059074943\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 3\n",
      "MAE: 0.13729832116639626\n",
      "MSE: 0.021115993058759528\n",
      "RMSE: 0.14531343041425843\n",
      "R2: 0.9350782104782623\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 4\n",
      "MAE: 0.12381050914378135\n",
      "MSE: 0.023789672696974653\n",
      "RMSE: 0.1542390115923162\n",
      "R2: 0.9268578977400579\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 5\n",
      "MAE: 0.0852397004871709\n",
      "MSE: 0.011812776413892483\n",
      "RMSE: 0.10868659721369735\n",
      "R2: 0.9636812447382417\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 6\n",
      "MAE: 0.13729832402329048\n",
      "MSE: 0.02111599377703431\n",
      "RMSE: 0.1453134328857257\n",
      "R2: 0.9350782082699038\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 7\n",
      "MAE: 0.1298532246901251\n",
      "MSE: 0.019237488608221158\n",
      "RMSE: 0.13869927400033916\n",
      "R2: 0.9408537319142721\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 8\n",
      "MAE: 0.1359338297236706\n",
      "MSE: 0.026945578344487207\n",
      "RMSE: 0.1641510838967785\n",
      "R2: 0.9171549658614513\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 9\n",
      "MAE: 0.3599938465559395\n",
      "MSE: 0.1380509909488722\n",
      "RMSE: 0.37155213759157973\n",
      "R2: 0.575557855474286\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Bawah II - Iterasi 10\n",
      "MAE: 0.22650205077297145\n",
      "MSE: 0.053929232480993544\n",
      "RMSE: 0.23222668339575783\n",
      "R2: 0.8341928664942648\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 1\n",
      "MAE: 0.11521192532277022\n",
      "MSE: 0.019132158087132412\n",
      "RMSE: 0.1383190445568954\n",
      "R2: 0.8295018412844831\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 2\n",
      "MAE: 0.09535027306983691\n",
      "MSE: 0.016082987844292906\n",
      "RMSE: 0.1268187204015752\n",
      "R2: 0.8566748298018596\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 3\n",
      "MAE: 0.14833900035856018\n",
      "MSE: 0.027259918667464078\n",
      "RMSE: 0.1651057802363808\n",
      "R2: 0.7570704821499834\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 4\n",
      "MAE: 0.1510401262250569\n",
      "MSE: 0.028601731000315704\n",
      "RMSE: 0.16912046298516245\n",
      "R2: 0.7451127860526027\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 5\n",
      "MAE: 0.06392605849407887\n",
      "MSE: 0.011429900480996794\n",
      "RMSE: 0.10691071265779119\n",
      "R2: 0.8981412876981071\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 6\n",
      "MAE: 0.04293943547608251\n",
      "MSE: 0.012400557512606084\n",
      "RMSE: 0.11135779053396347\n",
      "R2: 0.88949117954617\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 7\n",
      "MAE: 0.06802413785147693\n",
      "MSE: 0.013330831451411911\n",
      "RMSE: 0.11545921986317036\n",
      "R2: 0.8812009494035443\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 8\n",
      "MAE: 0.05804412032966179\n",
      "MSE: 0.011062119286749368\n",
      "RMSE: 0.10517660997935505\n",
      "R2: 0.9014188069483559\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 9\n",
      "MAE: 0.16089523589296065\n",
      "MSE: 0.031085913791067295\n",
      "RMSE: 0.17631197858077396\n",
      "R2: 0.7229747402656622\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium I - Iterasi 10\n",
      "MAE: 0.17177213763988122\n",
      "MSE: 0.03451421414670447\n",
      "RMSE: 0.18578001546642328\n",
      "R2: 0.6924230954643883\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 1\n",
      "MAE: 0.09291011554621839\n",
      "MSE: 0.01621989715773731\n",
      "RMSE: 0.12735736004541437\n",
      "R2: 0.8648765563875419\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 2\n",
      "MAE: 0.09124560856194873\n",
      "MSE: 0.01558957407215199\n",
      "RMSE: 0.12485821587765857\n",
      "R2: 0.8701276023765783\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 3\n",
      "MAE: 0.06656502879016148\n",
      "MSE: 0.011024424113647147\n",
      "RMSE: 0.10499725764822217\n",
      "R2: 0.9081585946203352\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 4\n",
      "MAE: 0.10944120662843601\n",
      "MSE: 0.016593962632936235\n",
      "RMSE: 0.12881755560845048\n",
      "R2: 0.8617603211454893\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 5\n",
      "MAE: 0.06259968800250297\n",
      "MSE: 0.009539067661110753\n",
      "RMSE: 0.09766815069975858\n",
      "R2: 0.9205326853378563\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 6\n",
      "MAE: 0.19546686276138472\n",
      "MSE: 0.043496499602080116\n",
      "RMSE: 0.20855814441560444\n",
      "R2: 0.6376427819385211\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 7\n",
      "MAE: 0.19901187623899003\n",
      "MSE: 0.04659953966935518\n",
      "RMSE: 0.21586926522632902\n",
      "R2: 0.6117922197875998\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 8\n",
      "MAE: 0.06027824524630753\n",
      "MSE: 0.008648945280680474\n",
      "RMSE: 0.09299970580964476\n",
      "R2: 0.9279480468602247\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 9\n",
      "MAE: 0.06298204273739559\n",
      "MSE: 0.00967554221588595\n",
      "RMSE: 0.09836433406416144\n",
      "R2: 0.9193957538501061\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Medium II - Iterasi 10\n",
      "MAE: 0.1558705139561583\n",
      "MSE: 0.029152378496098204\n",
      "RMSE: 0.1707406761615351\n",
      "R2: 0.7571396579412049\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 1\n",
      "MAE: 0.1817816186569572\n",
      "MSE: 0.05364105523402674\n",
      "RMSE: 0.23160538688473276\n",
      "R2: 0.9345243160750307\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 2\n",
      "MAE: 0.2525914690854269\n",
      "MSE: 0.08530432095641702\n",
      "RMSE: 0.2920690345730218\n",
      "R2: 0.8958753005135986\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 3\n",
      "MAE: 0.2780637386246929\n",
      "MSE: 0.10789980778330478\n",
      "RMSE: 0.32848106152913104\n",
      "R2: 0.8682946545484234\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 4\n",
      "MAE: 0.36723323157668214\n",
      "MSE: 0.16982176919327646\n",
      "RMSE: 0.4120943692812078\n",
      "R2: 0.792711078580261\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 5\n",
      "MAE: 0.2820714657241714\n",
      "MSE: 0.11181069129392501\n",
      "RMSE: 0.33438105702016824\n",
      "R2: 0.8635209271955298\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 6\n",
      "MAE: 0.27657795266734364\n",
      "MSE: 0.10554638557477695\n",
      "RMSE: 0.32487903221780406\n",
      "R2: 0.8711673036414602\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 7\n",
      "MAE: 0.2907519561721863\n",
      "MSE: 0.11975131246225588\n",
      "RMSE: 0.3460510258072585\n",
      "R2: 0.8538283959893997\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 8\n",
      "MAE: 0.10456537941536913\n",
      "MSE: 0.028413716669922588\n",
      "RMSE: 0.16856368728146223\n",
      "R2: 0.9653174695446083\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 9\n",
      "MAE: 0.2722532783520903\n",
      "MSE: 0.10627912709993635\n",
      "RMSE: 0.32600479613026606\n",
      "R2: 0.8702729000490864\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super I - Iterasi 10\n",
      "MAE: 0.28496768672002465\n",
      "MSE: 0.11388447619962014\n",
      "RMSE: 0.33746774097626003\n",
      "R2: 0.8609896107547687\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 1\n",
      "MAE: 0.3942111843360502\n",
      "MSE: 0.19793064565037907\n",
      "RMSE: 0.4448939712452609\n",
      "R2: 0.7491382711605853\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 2\n",
      "MAE: 0.2349178107509003\n",
      "MSE: 0.07545330047478453\n",
      "RMSE: 0.2746876416491731\n",
      "R2: 0.9043687987701563\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 3\n",
      "MAE: 0.2595659737345204\n",
      "MSE: 0.09322948233670139\n",
      "RMSE: 0.3053350329338273\n",
      "R2: 0.8818388681503107\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 4\n",
      "MAE: 0.20042332394704576\n",
      "MSE: 0.0646963884672739\n",
      "RMSE: 0.2543548475403484\n",
      "R2: 0.9180023497258994\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 5\n",
      "MAE: 0.268438961224704\n",
      "MSE: 0.10350652019827428\n",
      "RMSE: 0.3217242922103867\n",
      "R2: 0.8688135204239347\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 6\n",
      "MAE: 0.2669478510436551\n",
      "MSE: 0.10198925287922266\n",
      "RMSE: 0.3193575627399837\n",
      "R2: 0.8707365389717605\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 7\n",
      "MAE: 0.21277788969531566\n",
      "MSE: 0.06404289635449235\n",
      "RMSE: 0.2530669799766306\n",
      "R2: 0.9188306002510096\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 8\n",
      "MAE: 0.27309550249437786\n",
      "MSE: 0.11038685224303207\n",
      "RMSE: 0.3322451688783933\n",
      "R2: 0.8600932336484044\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 9\n",
      "MAE: 0.3124209170988487\n",
      "MSE: 0.134480287122182\n",
      "RMSE: 0.3667155397882424\n",
      "R2: 0.8295566752109625\n",
      "\n",
      "Hasil Evaluasi Prediksi Harga Beras Kualitas Super II - Iterasi 10\n",
      "MAE: 0.25956596660197173\n",
      "MSE: 0.09322947719625291\n",
      "RMSE: 0.30533502451610905\n",
      "R2: 0.8818388746654301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "time_step = 3\n",
    "\n",
    "all_actuals = []\n",
    "all_predictions = []\n",
    "x_ticks = None\n",
    "\n",
    "for col in target_cols:\n",
    "    df_col = preprocess_data(df, col)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    split = int(len(df_col) * 0.8)  # 80% training, 20% testing\n",
    "    train = df_col[:split]\n",
    "    test = df_col[split:]\n",
    "\n",
    "    # Normalize data with MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    # Create training and testing datasets with the specified time step\n",
    "    X_train, y_train = create_dataset(train, time_step)\n",
    "    X_test, y_test = create_dataset(test, time_step)\n",
    "\n",
    "    # Initialize lists to store results for each iteration\n",
    "    all_actuals_col = []\n",
    "    all_predictions_col = []\n",
    "\n",
    "    for iteration in range(10):\n",
    "        # Introduce randomness by resampling the training data\n",
    "        X_train_resampled, y_train_resampled = resample(X_train, y_train)\n",
    "\n",
    "        # Build SVR model\n",
    "        svr = SVR(kernel='linear')\n",
    "        svr.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Predict using the test set\n",
    "        y_pred = svr.predict(X_test)\n",
    "\n",
    "        # Reshape y_pred to 2D array for inverse_transform\n",
    "        y_pred = y_pred.reshape(-1, 1)\n",
    "\n",
    "        # Inverse transform the normalized data back to original scale\n",
    "        y_test_inverse = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "        y_pred_inverse = scaler.inverse_transform(y_pred)\n",
    "        \n",
    "        # Flatten the arrays to 1D for metric calculations\n",
    "        y_test_inverse = y_test_inverse.flatten()\n",
    "        y_pred_inverse = y_pred_inverse.flatten()\n",
    "\n",
    "        all_actuals_col.append(y_test_inverse)\n",
    "        all_predictions_col.append(y_pred_inverse)\n",
    "\n",
    "        if x_ticks is None:\n",
    "            x_ticks = df_col.index[split + time_step:]\n",
    "\n",
    "        print(f'Hasil Evaluasi Prediksi Harga {col} - Iterasi {iteration + 1}')\n",
    "        mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "        print('MAE:', mae)\n",
    "\n",
    "        mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "        print('MSE:', mse)\n",
    "\n",
    "        rmse = np.sqrt(mse)\n",
    "        print('RMSE:', rmse)\n",
    "\n",
    "        r2 = r2_score(y_test_inverse, y_pred_inverse)\n",
    "        print('R2:', r2)\n",
    "        print()\n",
    "\n",
    "    # Store results for each column\n",
    "    all_actuals.append(all_actuals_col)\n",
    "    all_predictions.append(all_predictions_col)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
